#!/usr/bin/env python3
"""
è¯¦ç»†VQVAEè¯Šæ–­è„šæœ¬

æ·±å…¥æ£€æŸ¥ï¼š
1. é‡åŒ–è¿‡ç¨‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
2. ç›´é€šä¼°è®¡å™¨æ˜¯å¦æœ‰æ•ˆ
3. æƒé‡åŠ è½½æ˜¯å¦æ­£ç¡®
4. codebookæ˜¯å¦æœ‰æ„ä¹‰çš„åˆ†å¸ƒ
5. è·ç¦»è®¡ç®—æ˜¯å¦æ­£ç¡®
"""

import sys
import os
sys.path.insert(0, 'src')

import torch
import numpy as np
from addict import Dict as AddictDict
from dataset.data_interface import DataInterface
from model.VAR.multi_scale_gene_vqvae import MultiScaleGeneVQVAE
from main import DATASETS

def detailed_quantization_analysis():
    """è¯¦ç»†åˆ†æé‡åŒ–è¿‡ç¨‹"""
    print("ğŸ”¬ è¯¦ç»†é‡åŒ–è¿‡ç¨‹åˆ†æ")
    print("=" * 60)
    
    # 1. åŠ è½½VQVAE
    stage1_ckpt = "logs/PRAD/TWO_STAGE_VAR_ST/stage1-best-epoch=epoch=143-val_mse=val_mse=0.5353.ckpt"
    checkpoint = torch.load(stage1_ckpt, map_location='cpu')
    
    vqvae = MultiScaleGeneVQVAE()
    
    # æ£€æŸ¥æƒé‡åŠ è½½
    print("ğŸ” æ£€æŸ¥æƒé‡åŠ è½½...")
    if 'state_dict' in checkpoint:
        state_dict = {}
        stage1_keys_found = []
        all_keys = list(checkpoint['state_dict'].keys())
        
        for key, value in checkpoint['state_dict'].items():
            if key.startswith('model.stage1_vqvae.'):
                new_key = key.replace('model.stage1_vqvae.', '')
                state_dict[new_key] = value
                stage1_keys_found.append(key)
        
        print(f"   æ€»é”®æ•°: {len(all_keys)}")
        print(f"   Stage1é”®æ•°: {len(stage1_keys_found)}")
        print(f"   Stage1é”®ç¤ºä¾‹: {stage1_keys_found[:3]}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰codebookæƒé‡
        codebook_keys = [k for k in state_dict.keys() if 'embedding' in k]
        print(f"   Codebookç›¸å…³é”®: {codebook_keys}")
        
        missing_keys, unexpected_keys = vqvae.load_state_dict(state_dict, strict=False)
        print(f"   ç¼ºå¤±é”®: {len(missing_keys)}")
        print(f"   å¤šä½™é”®: {len(unexpected_keys)}")
        if missing_keys:
            print(f"   ç¼ºå¤±é”®ç¤ºä¾‹: {missing_keys[:3]}")
        if unexpected_keys:
            print(f"   å¤šä½™é”®ç¤ºä¾‹: {unexpected_keys[:3]}")
    
    vqvae.cuda()
    vqvae.eval()
    
    # 2. æ£€æŸ¥codebookæƒé‡
    print(f"\nğŸ§® æ£€æŸ¥Codebookæƒé‡...")
    codebook_weight = vqvae.shared_quantizer.embedding.weight
    print(f"   Codebookå½¢çŠ¶: {codebook_weight.shape}")
    print(f"   CodebookèŒƒå›´: [{codebook_weight.min().item():.6f}, {codebook_weight.max().item():.6f}]")
    print(f"   Codebookå‡å€¼: {codebook_weight.mean().item():.6f}")
    print(f"   Codebookæ ‡å‡†å·®: {codebook_weight.std().item():.6f}")
    
    # æ£€æŸ¥codebookæ˜¯å¦æœ‰æ„ä¹‰çš„åˆ†å¸ƒ
    if torch.allclose(codebook_weight, torch.zeros_like(codebook_weight)):
        print("   âŒ Codebookå…¨ä¸º0ï¼")
    elif torch.allclose(codebook_weight, codebook_weight[0:1].expand_as(codebook_weight)):
        print("   âŒ Codebookæ‰€æœ‰å‘é‡ç›¸åŒï¼")
    else:
        print("   âœ… Codebookæœ‰æ­£å¸¸åˆ†å¸ƒ")
    
    # 3. å‡†å¤‡æµ‹è¯•æ•°æ®
    dataset_info = DATASETS['PRAD']
    config = AddictDict({
        'data_path': dataset_info['path'],
        'slide_test': dataset_info['test_slides'],
        'encoder_name': dataset_info['recommended_encoder'],
        'use_augmented': False,
        'expr_name': 'PRAD',
        'MODEL': AddictDict({'model_name': 'TWO_STAGE_VAR_ST'}),
        'DATA': {
            'normalize': True,
            'test_dataloader': {
                'batch_size': 4,
                'num_workers': 0,
                'shuffle': False,
                'persistent_workers': False
            }
        }
    })
    
    data_interface = DataInterface(config)
    data_interface.setup(stage='test')
    dataloader = data_interface.test_dataloader()
    batch = next(iter(dataloader))
    gene_expression = batch['target_genes'].cuda()[:2]  # åªå–2ä¸ªæ ·æœ¬æ–¹ä¾¿è°ƒè¯•
    
    print(f"\nğŸ“Š æµ‹è¯•æ•°æ®:")
    print(f"   æ‰¹æ¬¡å¤§å°: {gene_expression.shape[0]}")
    print(f"   åŸºå› è¡¨è¾¾èŒƒå›´: [{gene_expression.min().item():.4f}, {gene_expression.max().item():.4f}]")
    
    # 4. é€æ­¥åˆ†æç¼–ç è¿‡ç¨‹
    print(f"\nğŸ”¬ é€æ­¥åˆ†æç¼–ç è¿‡ç¨‹...")
    
    with torch.no_grad():
        # Step 1: å¤šå°ºåº¦åˆ†è§£
        decomposed = vqvae.decomposer(gene_expression)
        print(f"   å¤šå°ºåº¦åˆ†è§£:")
        for scale, features in decomposed.items():
            print(f"     {scale}: {features.shape}, èŒƒå›´[{features.min().item():.4f}, {features.max().item():.4f}]")
        
        # Step 2: ç¼–ç åˆ°128ç»´
        encoded = {}
        for scale in ['global', 'pathway', 'module', 'individual']:
            encoded[scale] = vqvae.encoders[scale](decomposed[scale])
            print(f"   {scale}ç¼–ç : {encoded[scale].shape}, èŒƒå›´[{encoded[scale].min().item():.4f}, {encoded[scale].max().item():.4f}]")
        
        # Step 3: è¯¦ç»†åˆ†æé‡åŒ–è¿‡ç¨‹
        print(f"\nğŸ¯ è¯¦ç»†é‡åŒ–è¿‡ç¨‹åˆ†æ...")
        
        for scale in ['global', 'pathway', 'module', 'individual']:
            print(f"\n   --- {scale.upper()}å°ºåº¦é‡åŒ– ---")
            x = encoded[scale]
            print(f"   è¾“å…¥ç‰¹å¾: {x.shape}")
            print(f"   è¾“å…¥èŒƒå›´: [{x.min().item():.6f}, {x.max().item():.6f}]")
            
            # æ‰‹åŠ¨æ‰§è¡Œé‡åŒ–æ­¥éª¤
            input_shape = x.shape
            
            # å¤„ç†ç»´åº¦
            if x.dim() == 2:
                x = x.unsqueeze(1)
                squeeze_output = True
            else:
                squeeze_output = False
            
            B, N, D = x.shape
            flat_x = x.view(-1, D)  # [B*N, D]
            print(f"   å±•å¹³å: {flat_x.shape}")
            
            # è®¡ç®—è·ç¦»
            distances = torch.cdist(flat_x, codebook_weight)  # [B*N, vocab_size]
            print(f"   è·ç¦»çŸ©é˜µ: {distances.shape}")
            print(f"   è·ç¦»èŒƒå›´: [{distances.min().item():.6f}, {distances.max().item():.6f}]")
            
            # è·å–æœ€è¿‘çš„tokens
            tokens_flat = torch.argmin(distances, dim=1)  # [B*N]
            tokens = tokens_flat.view(B, N)  # [B, N]
            print(f"   é€‰ä¸­tokens: {tokens.flatten()[:10].tolist()}")
            
            # è·å–é‡åŒ–ç‰¹å¾
            quantized = vqvae.shared_quantizer.embedding(tokens)  # [B, N, embed_dim]
            print(f"   é‡åŒ–ç‰¹å¾: {quantized.shape}")
            print(f"   é‡åŒ–èŒƒå›´: [{quantized.min().item():.6f}, {quantized.max().item():.6f}]")
            
            # ğŸ” å…³é”®æ£€æŸ¥ï¼šé‡åŒ–å‰åçš„å·®å¼‚
            quantization_error = torch.nn.functional.mse_loss(quantized, x)
            print(f"   âš ï¸ é‡åŒ–è¯¯å·®: {quantization_error.item():.8f}")
            
            if quantization_error.item() < 1e-6:
                print(f"   âŒ é‡åŒ–è¯¯å·®è¿‡å°ï¼Œå¯èƒ½æ²¡æœ‰çœŸæ­£é‡åŒ–ï¼")
                
                # è¯¦ç»†æ£€æŸ¥æ˜¯å¦è¾“å…¥ç‰¹å¾ä¸codebookæŸäº›å‘é‡å®Œå…¨åŒ¹é…
                for i in range(min(3, flat_x.shape[0])):
                    input_vec = flat_x[i]  # [128]
                    selected_token = tokens_flat[i].item()
                    codebook_vec = codebook_weight[selected_token]  # [128]
                    vec_diff = torch.nn.functional.mse_loss(input_vec, codebook_vec)
                    print(f"     æ ·æœ¬{i}: token={selected_token}, å‘é‡å·®å¼‚={vec_diff.item():.8f}")
                    
                    if vec_diff.item() < 1e-6:
                        print(f"     âŒ è¾“å…¥å‘é‡ä¸codebookå‘é‡å‡ ä¹å®Œå…¨ç›¸åŒï¼")
            else:
                print(f"   âœ… æœ‰æ­£å¸¸çš„é‡åŒ–è¯¯å·®")
            
            # æ£€æŸ¥ç›´é€šä¼°è®¡å™¨
            quantized_with_grad = x + (quantized - x).detach()
            straight_through_diff = torch.nn.functional.mse_loss(quantized_with_grad, quantized)
            print(f"   ç›´é€šä¼°è®¡å™¨å·®å¼‚: {straight_through_diff.item():.8f}")

def check_training_vs_inference_consistency():
    """æ£€æŸ¥è®­ç»ƒæ¨¡å¼vsæ¨ç†æ¨¡å¼çš„ä¸€è‡´æ€§"""
    print(f"\nğŸ”„ æ£€æŸ¥è®­ç»ƒvsæ¨ç†æ¨¡å¼ä¸€è‡´æ€§")
    print("=" * 50)
    
    # åŠ è½½æ¨¡å‹
    stage1_ckpt = "logs/PRAD/TWO_STAGE_VAR_ST/stage1-best-epoch=epoch=143-val_mse=val_mse=0.5353.ckpt"
    checkpoint = torch.load(stage1_ckpt, map_location='cpu')
    
    vqvae = MultiScaleGeneVQVAE()
    if 'state_dict' in checkpoint:
        state_dict = {}
        for key, value in checkpoint['state_dict'].items():
            if key.startswith('model.stage1_vqvae.'):
                new_key = key.replace('model.stage1_vqvae.', '')
                state_dict[new_key] = value
        vqvae.load_state_dict(state_dict, strict=False)
    
    vqvae.cuda()
    
    # å‡†å¤‡æ•°æ®
    dataset_info = DATASETS['PRAD']
    config = AddictDict({
        'data_path': dataset_info['path'],
        'slide_test': dataset_info['test_slides'],
        'encoder_name': dataset_info['recommended_encoder'],
        'use_augmented': False,
        'expr_name': 'PRAD',
        'MODEL': AddictDict({'model_name': 'TWO_STAGE_VAR_ST'}),
        'DATA': {
            'normalize': True,
            'test_dataloader': {
                'batch_size': 2,
                'num_workers': 0,
                'shuffle': False,
                'persistent_workers': False
            }
        }
    })
    
    data_interface = DataInterface(config)
    data_interface.setup(stage='test')
    dataloader = data_interface.test_dataloader()
    batch = next(iter(dataloader))
    gene_expression = batch['target_genes'].cuda()[:2]
    
    # æµ‹è¯•è®­ç»ƒæ¨¡å¼
    print("ğŸ“ è®­ç»ƒæ¨¡å¼æµ‹è¯•:")
    vqvae.train()
    with torch.no_grad():  # å³ä½¿åœ¨è®­ç»ƒæ¨¡å¼ä¹Ÿç”¨no_gradï¼Œå› ä¸ºåªæ˜¯æµ‹è¯•
        train_result = vqvae(gene_expression)
        train_recon = train_result['final_reconstruction']
        train_tokens = train_result['tokens']
        print(f"   é‡å»ºèŒƒå›´: [{train_recon.min().item():.4f}, {train_recon.max().item():.4f}]")
        print(f"   VQæŸå¤±: {train_result['total_vq_loss'].item():.6f}")
    
    # æµ‹è¯•æ¨ç†æ¨¡å¼
    print("ğŸ” æ¨ç†æ¨¡å¼æµ‹è¯•:")
    vqvae.eval()
    with torch.no_grad():
        eval_result = vqvae(gene_expression)
        eval_recon = eval_result['final_reconstruction']
        eval_tokens = eval_result['tokens']
        print(f"   é‡å»ºèŒƒå›´: [{eval_recon.min().item():.4f}, {eval_recon.max().item():.4f}]")
        print(f"   VQæŸå¤±: {eval_result['total_vq_loss'].item():.6f}")
    
    # å¯¹æ¯”å·®å¼‚
    mode_diff = torch.nn.functional.mse_loss(train_recon, eval_recon)
    print(f"ğŸ“Š è®­ç»ƒvsæ¨ç†æ¨¡å¼å·®å¼‚: {mode_diff.item():.8f}")
    
    if mode_diff.item() < 1e-6:
        print("   âœ… è®­ç»ƒå’Œæ¨ç†æ¨¡å¼ç»“æœä¸€è‡´")
    else:
        print("   âš ï¸ è®­ç»ƒå’Œæ¨ç†æ¨¡å¼æœ‰å·®å¼‚")
    
    # æ£€æŸ¥tokensæ˜¯å¦ç›¸åŒ
    tokens_same = True
    for scale in ['global', 'pathway', 'module', 'individual']:
        scale_diff = torch.allclose(train_tokens[scale], eval_tokens[scale])
        print(f"   {scale} tokensç›¸åŒ: {scale_diff}")
        if not scale_diff:
            tokens_same = False
    
    if tokens_same:
        print("   âœ… æ‰€æœ‰å°ºåº¦tokensåœ¨è®­ç»ƒå’Œæ¨ç†æ¨¡å¼ä¸‹ç›¸åŒ")
    else:
        print("   âŒ ä¸åŒæ¨¡å¼ä¸‹tokensæœ‰å·®å¼‚")

def test_random_input_quantization():
    """ç”¨éšæœºè¾“å…¥æµ‹è¯•é‡åŒ–æ˜¯å¦å·¥ä½œ"""
    print(f"\nğŸ² éšæœºè¾“å…¥é‡åŒ–æµ‹è¯•")
    print("=" * 40)
    
    # åŠ è½½æ¨¡å‹
    stage1_ckpt = "logs/PRAD/TWO_STAGE_VAR_ST/stage1-best-epoch=epoch=143-val_mse=val_mse=0.5353.ckpt"
    checkpoint = torch.load(stage1_ckpt, map_location='cpu')
    
    vqvae = MultiScaleGeneVQVAE()
    if 'state_dict' in checkpoint:
        state_dict = {}
        for key, value in checkpoint['state_dict'].items():
            if key.startswith('model.stage1_vqvae.'):
                new_key = key.replace('model.stage1_vqvae.', '')
                state_dict[new_key] = value
        vqvae.load_state_dict(state_dict, strict=False)
    
    vqvae.cuda()
    vqvae.eval()
    
    # åˆ›å»ºéšæœºè¾“å…¥
    random_gene_expression = torch.randn(2, 200).cuda() * 2.0  # éšæœºåŸºå› è¡¨è¾¾
    print(f"éšæœºè¾“å…¥èŒƒå›´: [{random_gene_expression.min().item():.4f}, {random_gene_expression.max().item():.4f}]")
    
    with torch.no_grad():
        # ç¼–ç 
        encode_result = vqvae.encode(random_gene_expression)
        tokens = encode_result['tokens']
        vq_loss = encode_result['vq_loss']
        
        print(f"VQæŸå¤±: {vq_loss.item():.6f}")
        
        # è§£ç 
        decode_result = vqvae.decode_from_tokens(tokens)
        reconstructed = decode_result['final_reconstruction']
        
        # è®¡ç®—é‡å»ºè¯¯å·®
        recon_error = torch.nn.functional.mse_loss(reconstructed, random_gene_expression)
        print(f"é‡å»ºè¯¯å·®: {recon_error.item():.6f}")
        
        print(f"é‡å»ºèŒƒå›´: [{reconstructed.min().item():.4f}, {reconstructed.max().item():.4f}]")
        
        # å¦‚æœé‡å»ºè¯¯å·®ä¸º0ï¼Œè¯´æ˜æœ‰é—®é¢˜
        if recon_error.item() < 1e-6:
            print("âŒ éšæœºè¾“å…¥çš„é‡å»ºè¯¯å·®ä¹Ÿä¸º0ï¼Œé‡åŒ–è¿‡ç¨‹æœ‰é—®é¢˜ï¼")
        else:
            print("âœ… éšæœºè¾“å…¥æœ‰æ­£å¸¸çš„é‡å»ºè¯¯å·®")

if __name__ == "__main__":
    detailed_quantization_analysis()
    check_training_vs_inference_consistency()
    test_random_input_quantization() 