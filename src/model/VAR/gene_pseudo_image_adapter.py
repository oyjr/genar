"""
åŸºå› ä¼ªå›¾åƒé€‚é…å™¨

è´Ÿè´£åŸºå› è¡¨è¾¾å‘é‡ä¸VARæœŸæœ›çš„å›¾åƒæ ¼å¼ä¹‹é—´çš„è½¬æ¢
æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åŸºå› è¡¨è¾¾å‘é‡ [B, 196] -> å•é€šé“ä¼ªå›¾åƒ [B, 1, 16, 16] (paddingåˆ°256)
2. å•é€šé“ä¼ªå›¾åƒ [B, 1, 16, 16] -> åŸºå› è¡¨è¾¾å‘é‡ [B, 196]
3. æ•°æ®éªŒè¯å’Œæ ‡å‡†åŒ–

ğŸ”§ è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨paddingå°†196åŸºå› æ‰©å±•åˆ°16Ã—16=256ï¼Œé¿å…14Ã—14å¤ªå°çš„é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Optional, Tuple, Dict, Any
import math


class GenePseudoImageAdapter(nn.Module):
    """
    åŸºå› ä¼ªå›¾åƒé€‚é…å™¨ - Paddingç‰ˆæœ¬
    
    å°†196åŸºå› è¡¨è¾¾å‘é‡paddingåˆ°16Ã—16=256ï¼Œè½¬æ¢ä¸ºVARæœŸæœ›çš„å•é€šé“ä¼ªå›¾åƒæ ¼å¼
    
    å…³é”®æ”¹è¿›ï¼š
    - ä½¿ç”¨16Ã—16è€Œä¸æ˜¯14Ã—14ï¼Œä¸ºVARæä¾›è¶³å¤Ÿçš„ç©ºé—´è¿›è¡Œå¤šå±‚å·ç§¯
    - paddingç­–ç•¥ï¼š196åŸºå›  + 60ä¸ªé›¶padding = 256ä½ç½®
    - ç¡®ä¿è½¬æ¢è¿‡ç¨‹æ— æŸä¸”å¯é€†
    """
    
    def __init__(
        self,
        num_genes: int = 196,
        target_image_size: int = 16,  # ğŸ”§ æ”¹ä¸º16Ã—16
        normalize_method: str = 'layer_norm',
        eps: float = 1e-6
    ):
        """
        åˆå§‹åŒ–åŸºå› ä¼ªå›¾åƒé€‚é…å™¨ - Paddingç‰ˆæœ¬
        
        Args:
            num_genes: åŸºå› æ•°é‡ï¼ˆå›ºå®š196ï¼‰
            target_image_size: ç›®æ ‡å›¾åƒå¤§å°ï¼ˆ16Ã—16=256ï¼‰
            normalize_method: æ ‡å‡†åŒ–æ–¹æ³• ('layer_norm', 'batch_norm', 'none')
            eps: æ•°å€¼ç¨³å®šæ€§å‚æ•°
        """
        super().__init__()
        
        self.num_genes = num_genes
        self.target_image_size = target_image_size
        self.normalize_method = normalize_method
        self.eps = eps
        
        # è®¡ç®—ç›®æ ‡å›¾åƒçš„æ€»ä½ç½®æ•°
        self.total_positions = target_image_size * target_image_size
        
        # ğŸ”§ å¼ºåˆ¶ä½¿ç”¨paddingç­–ç•¥
        if num_genes > self.total_positions:
            raise ValueError(
                f"åŸºå› æ•°é‡ {num_genes} ä¸èƒ½å¤§äºç›®æ ‡å›¾åƒä½ç½®æ•° {target_image_size}^2 = {self.total_positions}"
            )
        
        self.use_padding = True  # æ€»æ˜¯ä½¿ç”¨padding
        self.padding_size = self.total_positions - num_genes
        
        print(f"ğŸ§¬ åˆå§‹åŒ–åŸºå› ä¼ªå›¾åƒé€‚é…å™¨ (Paddingç‰ˆæœ¬):")
        print(f"   - åŸºå› æ•°é‡: {num_genes}")
        print(f"   - ç›®æ ‡å›¾åƒå°ºå¯¸: {target_image_size}Ã—{target_image_size}")
        print(f"   - æ€»ä½ç½®æ•°: {self.total_positions}")
        print(f"   - Paddingå¤§å°: {self.padding_size}")
        print(f"   - ç©ºé—´åˆ©ç”¨ç‡: {num_genes/self.total_positions:.1%}")
        print(f"   - æ ‡å‡†åŒ–æ–¹æ³•: {normalize_method}")
        
        # ğŸ”§ ä¸¥æ ¼éªŒè¯196åŸºå› é…ç½®
        if num_genes == 196:
            if target_image_size < 14:
                raise ValueError(f"196åŸºå› è‡³å°‘éœ€è¦14Ã—14å›¾åƒï¼Œä½†æŒ‡å®šäº†{target_image_size}Ã—{target_image_size}")
            print(f"   - âœ… 196åŸºå› æ¨¡å¼ï¼šä½¿ç”¨{target_image_size}Ã—{target_image_size}ï¼Œpadding {self.padding_size}ä¸ªä½ç½®")
        
        # åˆå§‹åŒ–æ ‡å‡†åŒ–å±‚ï¼ˆåªå¯¹å®é™…åŸºå› æ•°é‡è¿›è¡Œæ ‡å‡†åŒ–ï¼‰
        if normalize_method == 'layer_norm':
            self.norm_layer = nn.LayerNorm(num_genes, eps=eps)
        elif normalize_method == 'batch_norm':
            self.norm_layer = nn.BatchNorm1d(num_genes, eps=eps)
        else:
            self.norm_layer = nn.Identity()
    
    def _apply_normalization(self, gene_expression: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨æ ‡å‡†åŒ–åˆ°åŸºå› è¡¨è¾¾å‘é‡"""
        if self.normalize_method == 'none':
            return gene_expression
        elif self.normalize_method == 'batch_norm':
            # BatchNorm1d æœŸæœ› [B, C] æˆ– [B, C, L]
            return self.norm_layer(gene_expression)
        else:  # layer_norm
            # LayerNorm æœŸæœ› [..., normalized_shape]
            return self.norm_layer(gene_expression)
    
    def _apply_denormalization(self, gene_expression: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨åæ ‡å‡†åŒ–åˆ°åŸºå› è¡¨è¾¾å‘é‡"""
        # ğŸ”§ ä¿®å¤ï¼šåœ¨éªŒè¯å’Œæ¨ç†é˜¶æ®µéœ€è¦æ­£ç¡®çš„åæ ‡å‡†åŒ–
        # ä½†ç”±äºLayerNormçš„å‚æ•°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå˜åŒ–ï¼Œè¿™é‡Œæš‚æ—¶ç›´æ¥è¿”å›
        # æ­£ç¡®çš„åšæ³•æ˜¯ä¿å­˜æ ‡å‡†åŒ–çš„ç»Ÿè®¡ä¿¡æ¯æˆ–ä½¿ç”¨å¯é€†çš„æ ‡å‡†åŒ–
        return gene_expression
    
    def genes_to_pseudo_image(self, gene_expression: torch.Tensor) -> torch.Tensor:
        """
        å°†åŸºå› è¡¨è¾¾å‘é‡è½¬æ¢ä¸ºä¼ªå›¾åƒ (Paddingç‰ˆæœ¬)
        
        Args:
            gene_expression: [B, num_genes] - åŸºå› è¡¨è¾¾å‘é‡ (196ä¸ªåŸºå› )
            
        Returns:
            torch.Tensor: [B, 1, target_image_size, target_image_size] - ä¼ªå›¾åƒ (å•é€šé“ï¼Œ16Ã—16)
        """
        B, num_genes = gene_expression.shape
        
        # éªŒè¯åŸºå› æ•°é‡
        if num_genes != self.num_genes:
            raise ValueError(f"æœŸæœ›åŸºå› æ•°é‡: {self.num_genes}, å¾—åˆ°: {num_genes}")
        
        # ğŸ”§ ä¿®å¤ï¼šåœ¨éªŒè¯é˜¶æ®µè·³è¿‡æ ‡å‡†åŒ–ä»¥ç¡®ä¿å®Œç¾é‡å»º
        if self.training:
            # è®­ç»ƒæ—¶ä½¿ç”¨æ ‡å‡†åŒ–
            normalized_genes = self._apply_normalization(gene_expression)
        else:
            # éªŒè¯/æ¨ç†æ—¶è·³è¿‡æ ‡å‡†åŒ–ï¼Œç¡®ä¿å¯é€†æ€§
            normalized_genes = gene_expression
        
        # ğŸ†• æ·»åŠ é›¶paddingï¼š[B, 196] â†’ [B, 256]
        padding_tensor = torch.zeros(B, self.padding_size, 
                                   device=normalized_genes.device, 
                                   dtype=normalized_genes.dtype)
        # æ‹¼æ¥ï¼š[B, num_genes] + [B, padding_size] = [B, total_positions]
        padded_genes = torch.cat([normalized_genes, padding_tensor], dim=1)
        
        # é‡å¡‘ä¸ºå•é€šé“ä¼ªå›¾åƒ: [B, total_positions] â†’ [B, 1, H, W]
        pseudo_image_1ch = padded_genes.view(B, 1, self.target_image_size, self.target_image_size).contiguous()
        
        return pseudo_image_1ch
    
    def pseudo_image_to_genes(self, pseudo_image: torch.Tensor) -> torch.Tensor:
        """
        å°†ä¼ªå›¾åƒè½¬æ¢å›åŸºå› è¡¨è¾¾å‘é‡ (Paddingç‰ˆæœ¬)
        
        Args:
            pseudo_image: [B, 1, target_image_size, target_image_size] - ä¼ªå›¾åƒ (å•é€šé“ï¼Œ16Ã—16)
            
        Returns:
            torch.Tensor: [B, num_genes] - åŸºå› è¡¨è¾¾å‘é‡ (196ä¸ªåŸºå› )
        """
        B, C, H, W = pseudo_image.shape
        
        # éªŒè¯è¾“å…¥å½¢çŠ¶
        if C != 1:
            raise ValueError(f"æœŸæœ›å•é€šé“è¾“å…¥ï¼Œå¾—åˆ°: {C}")
        if H != self.target_image_size or W != self.target_image_size:
            raise ValueError(f"æœŸæœ›å›¾åƒå°ºå¯¸: {self.target_image_size}x{self.target_image_size}, å¾—åˆ°: {H}x{W}")
        
        # å±•å¹³: [B, 1, H, W] â†’ [B, total_positions]
        flattened_data = pseudo_image.view(B, self.total_positions).contiguous()
        
        # ğŸ†• å»é™¤paddingéƒ¨åˆ†ï¼š[B, 256] â†’ [B, 196]
        gene_expression = flattened_data[:, :self.num_genes].contiguous()
        
        # ğŸ”§ ä¿®å¤ï¼šåœ¨éªŒè¯é˜¶æ®µè·³è¿‡åæ ‡å‡†åŒ–
        if self.training:
            # è®­ç»ƒæ—¶ä½¿ç”¨åæ ‡å‡†åŒ–
            denormalized_genes = self._apply_denormalization(gene_expression)
        else:
            # éªŒè¯/æ¨ç†æ—¶è·³è¿‡åæ ‡å‡†åŒ–ï¼Œç¡®ä¿å¯é€†æ€§
            denormalized_genes = gene_expression
        
        return denormalized_genes
    
    def validate_conversion(
        self, 
        test_batch_size: int = 4,
        tolerance: float = 1e-5
    ) -> Dict[str, Any]:
        """
        éªŒè¯åŸºå› è¡¨è¾¾ä¸ä¼ªå›¾åƒä¹‹é—´çš„è½¬æ¢å‡†ç¡®æ€§ï¼ˆåŒ…å«paddingå¤„ç†ï¼‰
        
        Args:
            test_batch_size: æµ‹è¯•batchå¤§å°
            tolerance: æ•°å€¼å®¹å·®
            
        Returns:
            åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        # ğŸ”§ ç¡®ä¿åœ¨evalæ¨¡å¼ä¸‹è¿›è¡ŒéªŒè¯ï¼ˆç¦ç”¨æ ‡å‡†åŒ–ï¼‰
        original_training_mode = self.training
        self.eval()
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            original_genes = torch.randn(test_batch_size, self.num_genes)
            
            with torch.no_grad():
                # æ­£å‘è½¬æ¢: åŸºå›  â†’ å•é€šé“ä¼ªå›¾åƒ (with padding)
                pseudo_image = self.genes_to_pseudo_image(original_genes)
                
                # åå‘è½¬æ¢: å•é€šé“ä¼ªå›¾åƒ â†’ åŸºå›  (remove padding)
                reconstructed_genes = self.pseudo_image_to_genes(pseudo_image)
                
                # è®¡ç®—é‡å»ºè¯¯å·®
                reconstruction_error = torch.abs(original_genes - reconstructed_genes)
                max_error = reconstruction_error.max().item()
                mean_error = reconstruction_error.mean().item()
                
                # éªŒè¯å½¢çŠ¶
                pseudo_shape_correct = pseudo_image.shape == (test_batch_size, 1, self.target_image_size, self.target_image_size)
                gene_shape_correct = reconstructed_genes.shape == (test_batch_size, self.num_genes)
                
                # éªŒè¯paddingåŒºåŸŸ
                padding_region = pseudo_image.view(test_batch_size, -1)[:, self.num_genes:]
                padding_zeros = torch.allclose(padding_region, torch.zeros_like(padding_region), atol=tolerance)
                
                return {
                    'conversion_successful': max_error < tolerance,
                    'max_reconstruction_error': max_error,
                    'mean_reconstruction_error': mean_error,
                    'pseudo_image_shape_correct': pseudo_shape_correct,
                    'gene_shape_correct': gene_shape_correct,
                    'padding_preserved': padding_zeros,
                    'original_genes_shape': original_genes.shape,
                    'pseudo_image_shape': pseudo_image.shape,
                    'reconstructed_genes_shape': reconstructed_genes.shape,
                    'num_genes': self.num_genes,
                    'target_image_size': self.target_image_size,
                    'padding_size': self.padding_size,
                    'space_utilization': self.num_genes / self.total_positions
                }
        finally:
            # æ¢å¤åŸå§‹è®­ç»ƒçŠ¶æ€
            self.train(original_training_mode)

    def get_conversion_info(self) -> dict:
        """è·å–è½¬æ¢é…ç½®ä¿¡æ¯"""
        return {
            'num_genes': self.num_genes,
            'target_image_size': self.target_image_size,
            'total_positions': self.total_positions,
            'padding_size': self.padding_size,
            'space_utilization': self.num_genes / self.total_positions,
            'normalize_method': self.normalize_method,
            'use_padding': self.use_padding
        }
    
    def forward(self, x: torch.Tensor, direction: str = 'gene_to_image') -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­ (æ”¯æŒåŒå‘è½¬æ¢)
        
        Args:
            x: è¾“å…¥å¼ é‡
            direction: è½¬æ¢æ–¹å‘ ('gene_to_image' æˆ– 'image_to_gene')
        
        Returns:
            è½¬æ¢åçš„å¼ é‡
        """
        if direction == 'gene_to_image':
            return self.genes_to_pseudo_image(x)
        elif direction == 'image_to_gene':
            return self.pseudo_image_to_genes(x)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è½¬æ¢æ–¹å‘: {direction}") 