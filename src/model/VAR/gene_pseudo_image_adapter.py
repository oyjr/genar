"""
åŸºå› ä¼ªå›¾åƒé€‚é…å™¨

è´Ÿè´£åŸºå› è¡¨è¾¾å‘é‡ä¸VARæœŸæœ›çš„å›¾åƒæ ¼å¼ä¹‹é—´çš„è½¬æ¢
æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åŸºå› è¡¨è¾¾å‘é‡ [B, 196] -> 14Ã—14 -> æ’å€¼ä¸Šé‡‡æ · -> [B, 1, 224, 224] (VQVAEæ ‡å‡†è¾“å…¥)
2. ä¼ªå›¾åƒ [B, 1, 224, 224] -> ä¸‹é‡‡æ · -> 14Ã—14 -> åŸºå› è¡¨è¾¾å‘é‡ [B, 196]
3. æ•°æ®éªŒè¯å’Œæ ‡å‡†åŒ–

ğŸ”§ æ–°è§£å†³æ–¹æ¡ˆï¼š14Ã—14â†’224Ã—224æ’å€¼ä¸Šé‡‡æ ·
- 196åŸºå› å®Œç¾åŒ¹é…14Ã—14ï¼ˆ100%ç©ºé—´åˆ©ç”¨ç‡ï¼‰
- ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼æ‰©å±•åˆ°224Ã—224ï¼ˆVQVAEæ ‡å‡†è¾“å…¥ï¼‰
- æ¯ä¸ªåŸºå› å€¼å¤åˆ¶åˆ°16Ã—16åŒºåŸŸï¼Œä¿æŒä¿¡æ¯å¯†åº¦
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Optional, Tuple, Dict, Any
import math


class GenePseudoImageAdapter(nn.Module):
    """
    åŸºå› ä¼ªå›¾åƒé€‚é…å™¨ - æ’å€¼ä¸Šé‡‡æ ·ç‰ˆæœ¬
    
    å°†196åŸºå› è¡¨è¾¾å‘é‡é€šè¿‡14Ã—14ä¸­é—´è¡¨ç¤ºæ’å€¼ä¸Šé‡‡æ ·åˆ°224Ã—224ï¼Œæ»¡è¶³VQVAEéœ€æ±‚
    
    å…³é”®æ”¹è¿›ï¼š
    - 196åŸºå›  â†’ 14Ã—14ï¼ˆå®Œç¾åŒ¹é…ï¼Œ100%ç©ºé—´åˆ©ç”¨ç‡ï¼‰
    - 14Ã—14 â†’ æ’å€¼ä¸Šé‡‡æ · â†’ 224Ã—224ï¼ˆVQVAEæ ‡å‡†è¾“å…¥ï¼‰
    - æ¯ä¸ªåŸºå› å€¼æ‰©æ•£åˆ°16Ã—16åŒºåŸŸï¼Œä¿æŒä¿¡æ¯è¿ç»­æ€§
    - åå‘ï¼š224Ã—224 â†’ ä¸‹é‡‡æ · â†’ 14Ã—14 â†’ 196åŸºå› 
    """
    
    def __init__(
        self,
        num_genes: int = 196,
        intermediate_size: int = 14,  # ğŸ”§ ä¸­é—´14Ã—14è¡¨ç¤º
        target_image_size: int = 64,  # ğŸ”§ æ”¹å›64Ã—64è¾“å‡º
        normalize_method: str = 'layer_norm',
        eps: float = 1e-6
    ):
        """
        åˆå§‹åŒ–åŸºå› ä¼ªå›¾åƒé€‚é…å™¨ - æ’å€¼ä¸Šé‡‡æ ·ç‰ˆæœ¬
        
        Args:
            num_genes: åŸºå› æ•°é‡ï¼ˆå›ºå®š196ï¼‰
            intermediate_size: ä¸­é—´è¡¨ç¤ºå¤§å°ï¼ˆ14Ã—14=196ï¼‰
            target_image_size: ç›®æ ‡å›¾åƒå¤§å°ï¼ˆ64Ã—64ï¼ŒVQVAEæ ‡å‡†ï¼‰
            normalize_method: æ ‡å‡†åŒ–æ–¹æ³• ('layer_norm', 'batch_norm', 'none')
            eps: æ•°å€¼ç¨³å®šæ€§å‚æ•°
        """
        super().__init__()
        
        self.num_genes = num_genes
        self.intermediate_size = intermediate_size
        self.target_image_size = target_image_size
        self.normalize_method = normalize_method
        self.eps = eps
        
        # éªŒè¯196åŸºå› ä¸14Ã—14çš„å®Œç¾åŒ¹é…
        intermediate_positions = intermediate_size * intermediate_size
        if num_genes != intermediate_positions:
            raise ValueError(
                f"åŸºå› æ•°é‡ {num_genes} å¿…é¡»ç­‰äºä¸­é—´è¡¨ç¤ºä½ç½®æ•° {intermediate_size}^2 = {intermediate_positions}"
            )
        
        # è®¡ç®—ä¸Šé‡‡æ ·å€æ•°
        self.upsampling_factor = target_image_size // intermediate_size
        
        print(f"ğŸ§¬ åˆå§‹åŒ–åŸºå› ä¼ªå›¾åƒé€‚é…å™¨ (æ’å€¼ä¸Šé‡‡æ ·ç‰ˆæœ¬):")
        print(f"   - åŸºå› æ•°é‡: {num_genes}")
        print(f"   - ä¸­é—´è¡¨ç¤º: {intermediate_size}Ã—{intermediate_size}")
        print(f"   - ç›®æ ‡å›¾åƒå°ºå¯¸: {target_image_size}Ã—{target_image_size}")
        print(f"   - ä¸Šé‡‡æ ·å€æ•°: {self.upsampling_factor}Ã—")
        print(f"   - ç©ºé—´åˆ©ç”¨ç‡: 100% (å®Œç¾åŒ¹é…)")
        print(f"   - æ ‡å‡†åŒ–æ–¹æ³•: {normalize_method}")
        if normalize_method == 'none':
            print(f"   - âš ï¸ LayerNormå·²ç¦ç”¨ï¼Œä¿æŒlog2è½¬æ¢åŸºå› è¡¨è¾¾çš„åŸå§‹æ•°å€¼èŒƒå›´")
        print(f"   - âœ… 196åŸºå› æ¨¡å¼ï¼š14Ã—14 â†’ æ’å€¼ä¸Šé‡‡æ · â†’ {target_image_size}Ã—{target_image_size}")
        
        # åˆå§‹åŒ–æ ‡å‡†åŒ–å±‚ï¼ˆåªå¯¹å®é™…åŸºå› æ•°é‡è¿›è¡Œæ ‡å‡†åŒ–ï¼‰
        if normalize_method == 'layer_norm':
            self.norm_layer = nn.LayerNorm(num_genes, eps=eps)
        elif normalize_method == 'batch_norm':
            self.norm_layer = nn.BatchNorm1d(num_genes, eps=eps)
        else:
            self.norm_layer = nn.Identity()
    
    def _apply_normalization(self, gene_expression: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨æ ‡å‡†åŒ–åˆ°åŸºå› è¡¨è¾¾å‘é‡"""
        if self.normalize_method == 'none':
            return gene_expression
        elif self.normalize_method == 'batch_norm':
            # BatchNorm1d æœŸæœ› [B, C] æˆ– [B, C, L]
            return self.norm_layer(gene_expression)
        else:  # layer_norm
            # LayerNorm æœŸæœ› [..., normalized_shape]
            return self.norm_layer(gene_expression)
    
    def _apply_denormalization(self, gene_expression: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨åæ ‡å‡†åŒ–åˆ°åŸºå› è¡¨è¾¾å‘é‡"""
        # ğŸ”§ ä¿®å¤ï¼šåœ¨éªŒè¯å’Œæ¨ç†é˜¶æ®µéœ€è¦æ­£ç¡®çš„åæ ‡å‡†åŒ–
        # ä½†ç”±äºLayerNormçš„å‚æ•°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå˜åŒ–ï¼Œè¿™é‡Œæš‚æ—¶ç›´æ¥è¿”å›
        # æ­£ç¡®çš„åšæ³•æ˜¯ä¿å­˜æ ‡å‡†åŒ–çš„ç»Ÿè®¡ä¿¡æ¯æˆ–ä½¿ç”¨å¯é€†çš„æ ‡å‡†åŒ–
        return gene_expression
    
    def genes_to_pseudo_image(self, gene_expression: torch.Tensor) -> torch.Tensor:
        """
        å°†åŸºå› è¡¨è¾¾å‘é‡è½¬æ¢ä¸ºä¼ªå›¾åƒ (æ’å€¼ä¸Šé‡‡æ ·ç‰ˆæœ¬)
        
        æµç¨‹: [B, 196] â†’ reshape â†’ [B, 1, 14, 14] â†’ æ’å€¼ä¸Šé‡‡æ · â†’ [B, 1, 224, 224]
        
        Args:
            gene_expression: [B, num_genes] - åŸºå› è¡¨è¾¾å‘é‡ (196ä¸ªåŸºå› )
            
        Returns:
            torch.Tensor: [B, 1, target_image_size, target_image_size] - ä¼ªå›¾åƒ (å•é€šé“ï¼Œ224Ã—224)
        """
        B, num_genes = gene_expression.shape
        
        # éªŒè¯åŸºå› æ•°é‡
        if num_genes != self.num_genes:
            raise ValueError(f"æœŸæœ›åŸºå› æ•°é‡: {self.num_genes}, å¾—åˆ°: {num_genes}")
        
        # ğŸ”§ ä¿®å¤ï¼šLayerNormå·²ç¦ç”¨ï¼Œä¿æŒlog2åŸºå› è¡¨è¾¾çš„åŸå§‹æ•°å€¼èŒƒå›´
        # ä¸å†åŒºåˆ†è®­ç»ƒ/éªŒè¯æ¨¡å¼ï¼Œå§‹ç»ˆä¿æŒæ•°æ®çš„åŸå§‹åˆ†å¸ƒ
        normalized_genes = gene_expression
        
        # Step 1: å°†196åŸºå› é‡å¡‘ä¸º14Ã—14ä¸­é—´è¡¨ç¤º
        # [B, 196] â†’ [B, 1, 14, 14]
        intermediate_image = normalized_genes.view(
            B, 1, self.intermediate_size, self.intermediate_size
        ).contiguous()
        
        # Step 2: æ’å€¼ä¸Šé‡‡æ ·åˆ°224Ã—224
        # [B, 1, 14, 14] â†’ [B, 1, 224, 224]
        upsampled_image = F.interpolate(
            intermediate_image,
            size=(self.target_image_size, self.target_image_size),
            mode='nearest',  # æœ€è¿‘é‚»æ’å€¼ï¼Œæ¯ä¸ªåŸºå› å€¼å¤åˆ¶åˆ°16Ã—16åŒºåŸŸ
            align_corners=None
        )
        
        return upsampled_image
    
    def pseudo_image_to_genes(self, pseudo_image: torch.Tensor) -> torch.Tensor:
        """
        å°†ä¼ªå›¾åƒè½¬æ¢å›åŸºå› è¡¨è¾¾å‘é‡ (æ’å€¼ä¸Šé‡‡æ ·ç‰ˆæœ¬)
        
        æµç¨‹: [B, 1, 224, 224] â†’ ä¸‹é‡‡æ · â†’ [B, 1, 14, 14] â†’ reshape â†’ [B, 196]
        
        Args:
            pseudo_image: [B, 1, target_image_size, target_image_size] - ä¼ªå›¾åƒ (å•é€šé“ï¼Œ224Ã—224)
            
        Returns:
            torch.Tensor: [B, num_genes] - åŸºå› è¡¨è¾¾å‘é‡ (196ä¸ªåŸºå› )
        """
        B, C, H, W = pseudo_image.shape
        
        # éªŒè¯è¾“å…¥å½¢çŠ¶
        if C != 1:
            raise ValueError(f"æœŸæœ›å•é€šé“è¾“å…¥ï¼Œå¾—åˆ°: {C}")
        if H != self.target_image_size or W != self.target_image_size:
            raise ValueError(f"æœŸæœ›å›¾åƒå°ºå¯¸: {self.target_image_size}x{self.target_image_size}, å¾—åˆ°: {H}x{W}")
        
        # Step 1: ä¸‹é‡‡æ ·åˆ°14Ã—14ä¸­é—´è¡¨ç¤º
        # [B, 1, 224, 224] â†’ [B, 1, 14, 14]
        downsampled_image = F.interpolate(
            pseudo_image,
            size=(self.intermediate_size, self.intermediate_size),
            mode='bilinear',  # åŒçº¿æ€§æ’å€¼è¿›è¡Œä¸‹é‡‡æ ·ï¼Œä¿æŒå¹³æ»‘æ€§
            align_corners=False
        )
        
        # Step 2: é‡å¡‘ä¸ºåŸºå› è¡¨è¾¾å‘é‡
        # [B, 1, 14, 14] â†’ [B, 196]
        gene_expression = downsampled_image.view(B, self.num_genes).contiguous()
        
        # ğŸ”§ ä¿®å¤ï¼šLayerNormå·²ç¦ç”¨ï¼Œä¸éœ€è¦åæ ‡å‡†åŒ–
        # ç›´æ¥è¿”å›åŸå§‹åŸºå› è¡¨è¾¾æ•°å€¼èŒƒå›´
        denormalized_genes = gene_expression
        
        return denormalized_genes
    
    def validate_conversion(
        self, 
        test_batch_size: int = 4,
        tolerance: float = 1e-5
    ) -> Dict[str, Any]:
        """
        éªŒè¯åŸºå› è¡¨è¾¾ä¸ä¼ªå›¾åƒä¹‹é—´çš„è½¬æ¢å‡†ç¡®æ€§ï¼ˆåŒ…å«paddingå¤„ç†ï¼‰
        
        Args:
            test_batch_size: æµ‹è¯•batchå¤§å°
            tolerance: æ•°å€¼å®¹å·®
            
        Returns:
            åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        # ğŸ”§ ç¡®ä¿åœ¨evalæ¨¡å¼ä¸‹è¿›è¡ŒéªŒè¯ï¼ˆç¦ç”¨æ ‡å‡†åŒ–ï¼‰
        original_training_mode = self.training
        self.eval()
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            original_genes = torch.randn(test_batch_size, self.num_genes)
            
            with torch.no_grad():
                # æ­£å‘è½¬æ¢: åŸºå›  â†’ å•é€šé“ä¼ªå›¾åƒ (with padding)
                pseudo_image = self.genes_to_pseudo_image(original_genes)
                
                # åå‘è½¬æ¢: å•é€šé“ä¼ªå›¾åƒ â†’ åŸºå›  (remove padding)
                reconstructed_genes = self.pseudo_image_to_genes(pseudo_image)
                
                # è®¡ç®—é‡å»ºè¯¯å·®
                reconstruction_error = torch.abs(original_genes - reconstructed_genes)
                max_error = reconstruction_error.max().item()
                mean_error = reconstruction_error.mean().item()
                
                # éªŒè¯å½¢çŠ¶
                pseudo_shape_correct = pseudo_image.shape == (test_batch_size, 1, self.target_image_size, self.target_image_size)
                gene_shape_correct = reconstructed_genes.shape == (test_batch_size, self.num_genes)
                
                # éªŒè¯paddingåŒºåŸŸ
                padding_region = pseudo_image.view(test_batch_size, -1)[:, self.num_genes:]
                padding_zeros = torch.allclose(padding_region, torch.zeros_like(padding_region), atol=tolerance)
                
                return {
                    'conversion_successful': max_error < tolerance,
                    'max_reconstruction_error': max_error,
                    'mean_reconstruction_error': mean_error,
                    'pseudo_image_shape_correct': pseudo_shape_correct,
                    'gene_shape_correct': gene_shape_correct,
                    'padding_preserved': padding_zeros,
                    'original_genes_shape': original_genes.shape,
                    'pseudo_image_shape': pseudo_image.shape,
                    'reconstructed_genes_shape': reconstructed_genes.shape,
                    'num_genes': self.num_genes,
                    'target_image_size': self.target_image_size,
                    'upsampling_factor': self.upsampling_factor,
                    'space_utilization': 1.0
                }
        finally:
            # æ¢å¤åŸå§‹è®­ç»ƒçŠ¶æ€
            self.train(original_training_mode)

    def get_conversion_info(self) -> dict:
        """è·å–è½¬æ¢é…ç½®ä¿¡æ¯"""
        return {
            'num_genes': self.num_genes,
            'target_image_size': self.target_image_size,
            'intermediate_size': self.intermediate_size,
            'upsampling_factor': self.upsampling_factor,
            'space_utilization': 1.0,
            'normalize_method': self.normalize_method,
            'use_padding': False
        }
    
    def forward(self, x: torch.Tensor, direction: str = 'gene_to_image') -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­ (æ”¯æŒåŒå‘è½¬æ¢)
        
        Args:
            x: è¾“å…¥å¼ é‡
            direction: è½¬æ¢æ–¹å‘ ('gene_to_image' æˆ– 'image_to_gene')
        
        Returns:
            è½¬æ¢åçš„å¼ é‡
        """
        if direction == 'gene_to_image':
            return self.genes_to_pseudo_image(x)
        elif direction == 'image_to_gene':
            return self.pseudo_image_to_genes(x)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è½¬æ¢æ–¹å‘: {direction}")

    def reverse_transform(self, pseudo_images: torch.Tensor) -> torch.Tensor:
        """
        ä»ä¼ªå›¾åƒåå‘è½¬æ¢ä¸ºåŸºå› è¡¨è¾¾
        
        Args:
            pseudo_images: ä¼ªå›¾åƒ [B, 1, target_size, target_size]
            
        Returns:
            åŸºå› è¡¨è¾¾ [B, num_genes]
        """
        B = pseudo_images.shape[0]
        
        # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
        if pseudo_images.dim() != 4 or pseudo_images.shape[1] != 1:
            raise ValueError(f"æœŸæœ›è¾“å…¥å½¢çŠ¶ä¸º [B, 1, H, W]ï¼Œå¾—åˆ° {pseudo_images.shape}")
        
        # ä½¿ç”¨ç°æœ‰çš„pseudo_image_to_genesæ–¹æ³•
        return self.pseudo_image_to_genes(pseudo_images) 