"""
VAR-ST Complete: ç©ºé—´è½¬å½•ç»„å­¦çš„è§†è§‰è‡ªå›å½’æ¨¡å‹

åŸºäºVARåŸå§‹è®¾è®¡ç†å¿µçš„çœŸæ­£ç©ºé—´å¤šå°ºåº¦å®ç°ï¼š
- å°†ç©ºé—´è½¬å½•ç»„å­¦æ•°æ®ç»„ç»‡ä¸ºä¸åŒåˆ†è¾¨ç‡çš„ç©ºé—´ç½‘æ ¼
- ä½¿ç”¨VQVAEå¯¹æ¯ä¸ªå°ºåº¦çš„åŸºå› è¡¨è¾¾ç½‘æ ¼è¿›è¡Œç¼–ç 
- VARè‡ªå›å½’ç”Ÿæˆï¼šä»ç²—ç²’åº¦å…¨å±€æ¨¡å¼åˆ°ç»†ç²’åº¦å±€éƒ¨ç»†èŠ‚
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple, Any
import numpy as np

from .vqvae_st import VQVAE
from .var_st import VAR
from .spatial_multiscale_organizer import SpatialMultiscaleOrganizer


class VAR_ST_Complete(nn.Module):
    """
    VAR-ST Complete: ç©ºé—´è½¬å½•ç»„å­¦çš„å®Œæ•´VARå®ç°
    
    å®ç°çœŸæ­£çš„ç©ºé—´å¤šå°ºåº¦VARï¼š
    1. ç©ºé—´å¤šå°ºåº¦ç»„ç»‡ï¼šå°†spotsç»„ç»‡ä¸ºä¸åŒåˆ†è¾¨ç‡çš„ç©ºé—´ç½‘æ ¼
    2. å¤šå°ºåº¦VQVAEç¼–ç ï¼šæ¯ä¸ªå°ºåº¦ä½¿ç”¨ä¸“é—¨çš„VQVAEç¼–ç å™¨
    3. VARè‡ªå›å½’ç”Ÿæˆï¼šä»ç²—ç²’åº¦åˆ°ç»†ç²’åº¦æ¸è¿›å¼ç”Ÿæˆ
    4. ç©ºé—´é‡å»ºï¼šä»å¤šå°ºåº¦ç½‘æ ¼é‡å»ºåˆ°åŸå§‹spots
    """
    
    def __init__(
        self,
        num_genes: int = 200,
        histology_feature_dim: int = 512,
        spatial_scales: List[int] = [1, 2, 4, 8],
        vqvae_configs: Optional[List[Dict]] = None,
        var_config: Optional[Dict] = None,
        spatial_config: Optional[Dict] = None,
        **kwargs
    ):
        """
        åˆå§‹åŒ–VAR-ST Completeæ¨¡å‹
        
        Args:
            num_genes: åŸºå› æ•°é‡
            histology_feature_dim: ç»„ç»‡å­¦ç‰¹å¾ç»´åº¦ 
            spatial_scales: ç©ºé—´åˆ†è¾¨ç‡åˆ—è¡¨ [1, 2, 4, 8]
            vqvae_configs: æ¯ä¸ªå°ºåº¦çš„VQVAEé…ç½®åˆ—è¡¨
            var_config: VARæ¨¡å‹é…ç½®
            spatial_config: ç©ºé—´ç»„ç»‡å™¨é…ç½®
        """
        super().__init__()
        
        self.num_genes = num_genes
        self.histology_feature_dim = histology_feature_dim
        self.spatial_scales = spatial_scales
        self.num_scales = len(spatial_scales)
        
        print(f"ğŸ§¬ åˆå§‹åŒ–VAR_ST_Complete (çœŸæ­£çš„ç©ºé—´å¤šå°ºåº¦æ¨¡å¼)")
        print(f"   - ç›®æ ‡åŸºå› æ•°: {num_genes}")
        print(f"   - ç»„ç»‡å­¦ç‰¹å¾ç»´åº¦: {histology_feature_dim}")
        print(f"   - ç©ºé—´åˆ†è¾¨ç‡: {spatial_scales}")
        
        # åˆå§‹åŒ–ç©ºé—´å¤šå°ºåº¦ç»„ç»‡å™¨
        spatial_config = spatial_config or {}
        self.spatial_organizer = SpatialMultiscaleOrganizer(
            scales=spatial_scales,
            aggregation_method=spatial_config.get('aggregation_method', 'weighted_mean'),
            spatial_smoothing=spatial_config.get('spatial_smoothing', True),
            normalize_coordinates=spatial_config.get('normalize_coordinates', True)
        )
        
        # ä¸ºæ¯ä¸ªç©ºé—´å°ºåº¦åˆ›å»ºä¸“é—¨çš„VQVAEç¼–ç å™¨
        self.vqvaes = nn.ModuleList()
        self.codebook_sizes = []
        
        if vqvae_configs is None:
            vqvae_configs = [self._get_default_vqvae_config(scale) for scale in spatial_scales]
        
        for scale_idx, scale in enumerate(spatial_scales):
            print(f"ğŸ§¬ åˆå§‹åŒ–å°ºåº¦ {scale}Ã—{scale} çš„VQVAE:")
            
            vqvae_config = vqvae_configs[scale_idx] if scale_idx < len(vqvae_configs) else vqvae_configs[-1]
            
            # æ¯ä¸ªå°ºåº¦çš„VQVAEå¤„ç†ç›¸åŒç»´åº¦çš„åŸºå› å‘é‡ [num_genes]
            vqvae = VQVAE(
                input_dim=num_genes,
                hidden_dim=vqvae_config.get('hidden_dim', 256),
                latent_dim=vqvae_config.get('latent_dim', 32),
                num_embeddings=vqvae_config.get('num_embeddings', 2048),  # ä¸åŒå°ºåº¦å¯ä»¥æœ‰ä¸åŒç æœ¬å¤§å°
                commitment_cost=vqvae_config.get('commitment_cost', 0.25)
            )
            
            self.vqvaes.append(vqvae)
            self.codebook_sizes.append(vqvae_config.get('num_embeddings', 2048))
            
            print(f"  - éšè—ç»´åº¦: {vqvae_config.get('hidden_dim', 256)}")
            print(f"  - æ½œåœ¨ç»´åº¦: {vqvae_config.get('latent_dim', 32)}")
            print(f"  - ç æœ¬å¤§å°: {vqvae_config.get('num_embeddings', 2048)}")
        
        # è®¡ç®—æ¯ä¸ªå°ºåº¦çš„tokenæ•°é‡
        self.tokens_per_scale = [scale * scale for scale in spatial_scales]
        self.total_tokens = sum(self.tokens_per_scale)
        
        print(f"   - æ¯å°ºåº¦tokenæ•°: {self.tokens_per_scale}")
        print(f"   - æ€»tokenæ•°: {self.total_tokens}")
        
        # åˆå§‹åŒ–VARæ¨¡å‹
        if var_config is None:
            var_config = self._get_default_var_config()
        
        # VARéœ€è¦å¤„ç†æ‰€æœ‰å°ºåº¦çš„ç»„åˆtokenåºåˆ—
        self.var_model = VAR(
            vocab_size=max(self.codebook_sizes),  # ä½¿ç”¨æœ€å¤§çš„è¯æ±‡è¡¨
            embed_dim=var_config.get('embed_dim', 1024),
            depth=var_config.get('depth', 16),
            num_heads=var_config.get('num_heads', 16),
            sequence_length=self.total_tokens,
            class_dropout_prob=var_config.get('class_dropout_prob', 0.1)
        )
        
        print(f"ğŸš€ VARæ¨¡å‹åˆå§‹åŒ–:")
        print(f"  - è¯æ±‡è¡¨å¤§å°: {max(self.codebook_sizes)}")
        print(f"  - åµŒå…¥ç»´åº¦: {var_config.get('embed_dim', 1024)}")
        print(f"  - åºåˆ—é•¿åº¦: {self.total_tokens}")
        
        # ç»„ç»‡å­¦ç‰¹å¾å¤„ç†å™¨ï¼ˆæ”¯æŒåŠ¨æ€ç»´åº¦é€‚é…ï¼‰
        self.base_histology_dim = histology_feature_dim
        self.histology_processors = nn.ModuleDict()
        
        print(f"âœ… VAR_ST_Completeåˆå§‹åŒ–å®Œæˆ")
    
    def _get_default_vqvae_config(self, scale: int) -> Dict:
        """ä¸ºä¸åŒå°ºåº¦ç”Ÿæˆé»˜è®¤VQVAEé…ç½®"""
        # è¾ƒå¤§å°ºåº¦ä½¿ç”¨æ›´å¤§çš„ç æœ¬å’Œæ›´å¤æ‚çš„æ¨¡å‹
        base_size = 1024
        scale_factor = scale  # å°ºåº¦è¶Šå¤§ï¼Œæ¨¡å‹è¶Šå¤æ‚
        
        return {
            'hidden_dim': min(512, 128 + scale * 32),  # å°ºåº¦è¶Šå¤§ï¼Œéšè—å±‚è¶Šå¤§
            'latent_dim': 32,
            'num_embeddings': min(8192, base_size * scale_factor),  # å°ºåº¦è¶Šå¤§ï¼Œç æœ¬è¶Šå¤§
            'commitment_cost': 0.25
        }
    
    def _get_default_var_config(self) -> Dict:
        """ç”Ÿæˆé»˜è®¤VARé…ç½®"""
        return {
            'embed_dim': 1024,
            'depth': 16,
            'num_heads': 16,
            'class_dropout_prob': 0.1
        }
    
    def _get_histology_processor(self, input_dim: int) -> nn.Module:
        """è·å–æˆ–åˆ›å»ºå¯¹åº”ç»´åº¦çš„ç»„ç»‡å­¦ç‰¹å¾å¤„ç†å™¨"""
        key = str(input_dim)
        
        if key not in self.histology_processors:
            # åˆ›å»ºæ–°çš„å¤„ç†å™¨
            if input_dim == self.base_histology_dim:
                # ç»´åº¦åŒ¹é…ï¼Œä½¿ç”¨æ’ç­‰æ˜ å°„
                processor = nn.Identity()
            else:
                # ç»´åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨çº¿æ€§å˜æ¢
                processor = nn.Sequential(
                    nn.Linear(input_dim, self.base_histology_dim),
                    nn.ReLU(),
                    nn.Dropout(0.1)
                )
            
            # ç¡®ä¿å¤„ç†å™¨ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
            device = next(self.parameters()).device
            processor = processor.to(device)
            
            self.histology_processors[key] = processor
            print(f"ğŸ”§ åˆ›å»ºç»„ç»‡å­¦ç‰¹å¾å¤„ç†å™¨: {input_dim} â†’ {self.base_histology_dim} (è®¾å¤‡: {device})")
        
        return self.histology_processors[key]
    
    def forward_training(
        self,
        gene_expression: torch.Tensor,
        histology_features: torch.Tensor,
        positions: torch.Tensor,
        class_labels: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """
        è®­ç»ƒé˜¶æ®µå‰å‘ä¼ æ’­ - çœŸæ­£çš„ç©ºé—´å¤šå°ºåº¦æ¨¡å¼
        
        Args:
            gene_expression: [B, N, num_genes] - spotsçš„åŸºå› è¡¨è¾¾
            histology_features: [B, N, feature_dim] - spotsçš„ç»„ç»‡å­¦ç‰¹å¾
            positions: [B, N, 2] - spotsçš„ç©ºé—´åæ ‡
            class_labels: [B] - æ¡ä»¶ç±»åˆ«æ ‡ç­¾(å¯é€‰)
        
        Returns:
            DictåŒ…å«æ‰€æœ‰æŸå¤±å’Œé¢„æµ‹ç»“æœ
        """
        B, N, num_genes = gene_expression.shape
        device = gene_expression.device
        
        print(f"ğŸ“Š VAR-STè®­ç»ƒå‰å‘ä¼ æ’­:")
        print(f"   - åŸºå› è¡¨è¾¾: {gene_expression.shape}")
        print(f"   - ç»„ç»‡å­¦ç‰¹å¾: {histology_features.shape}")
        print(f"   - ç©ºé—´ä½ç½®: {positions.shape}")
        
        # åŠ¨æ€é€‚é…ç»„ç»‡å­¦ç‰¹å¾ç»´åº¦
        actual_hist_dim = histology_features.shape[-1]
        if actual_hist_dim != self.base_histology_dim:
            print(f"ğŸ”§ æ£€æµ‹åˆ°ç»„ç»‡å­¦ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.base_histology_dim}, å®é™…{actual_hist_dim}")
            print(f"   - è‡ªåŠ¨é€‚é…: {'UNIç¼–ç å™¨(1024ç»´)' if actual_hist_dim == 1024 else 'CONCHç¼–ç å™¨(512ç»´)'}")
        
        histology_processor = self._get_histology_processor(actual_hist_dim)
        processed_hist = histology_processor(histology_features)  # [B, N, base_hist_dim]
        
        # ç”Ÿæˆç±»åˆ«æ ‡ç­¾ (å¦‚æœæ²¡æœ‰æä¾›)
        if class_labels is None:
            # ä½¿ç”¨ç»„ç»‡å­¦ç‰¹å¾çš„ç»Ÿè®¡é‡ä½œä¸ºç±»åˆ«æ ‡ç­¾
            hist_stats = torch.mean(processed_hist.view(B, -1), dim=1) * 1000
            class_labels = hist_stats.long() % 1000  # [B]
        
        print(f"   - ç±»åˆ«æ ‡ç­¾: {class_labels.shape}")
        
        # Stage 1: ç©ºé—´å¤šå°ºåº¦ç»„ç»‡
        print(f"ğŸ—‚ï¸ Stage 1: ç©ºé—´å¤šå°ºåº¦ç»„ç»‡")
        multiscale_expressions = self.spatial_organizer.organize_multiscale(
            gene_expression, positions
        )
        
        # Stage 2: å¤šå°ºåº¦VQVAEç¼–ç 
        print(f"ğŸ”§ Stage 2: å¤šå°ºåº¦VQVAEç¼–ç ")
        all_tokens = []
        all_vqvae_losses = []
        
        for scale_idx, scale_expression in enumerate(multiscale_expressions):
            scale = self.spatial_scales[scale_idx]
            scale_vqvae = self.vqvaes[scale_idx]
            
            print(f"   - ç¼–ç å°ºåº¦ {scale}Ã—{scale}: {scale_expression.shape}")
            
            # é‡å¡‘ä¸ºæ‰¹é‡å¤„ç†æ ¼å¼
            B, num_cells, num_genes = scale_expression.shape
            scale_expression_flat = scale_expression.view(-1, num_genes)  # [B*num_cells, num_genes]
            
            # VQVAEç¼–ç 
            vq_result = scale_vqvae.encode_to_tokens(scale_expression_flat)
            tokens = vq_result['tokens']  # [B*num_cells, 1] or [B*num_cells]
            vq_loss = vq_result['loss']
            
            # é‡å¡‘å›åŸå§‹æ‰¹æ¬¡æ ¼å¼
            if tokens.dim() == 2 and tokens.shape[1] == 1:
                tokens = tokens.squeeze(1)  # [B*num_cells]
            tokens = tokens.view(B, num_cells)  # [B, num_cells]
            
            all_tokens.append(tokens)
            all_vqvae_losses.append(vq_loss)
            
            print(f"     -> tokens: {tokens.shape}, loss: {vq_loss.item():.4f}")
        
        # Stage 3: ç»„åˆtokensåºåˆ—
        print(f"ğŸ”— Stage 3: ç»„åˆtokensåºåˆ—")
        combined_tokens = torch.cat(all_tokens, dim=1)  # [B, total_tokens]
        print(f"   - ç»„åˆtokens: {combined_tokens.shape}")
        
        # Stage 4: VARè‡ªå›å½’è®­ç»ƒ
        print(f"ğŸš€ Stage 4: VARè‡ªå›å½’è®­ç»ƒ")
        var_result = self.var_model.forward_training(
            tokens=combined_tokens,
            class_labels=class_labels,
            cfg=1.0,  # è®­ç»ƒæ—¶ä¸ä½¿ç”¨CFG
            cond_drop_prob=0.1
        )
        
        # Stage 5: é‡å»ºéªŒè¯
        print(f"ğŸ”„ Stage 5: é‡å»ºéªŒè¯")
        with torch.no_grad():
            # ä»tokensé‡å»ºå¤šå°ºåº¦è¡¨è¾¾
            reconstructed_multiscale = self._decode_multiscale_from_tokens(all_tokens)
            
            # ä»å¤šå°ºåº¦é‡å»ºåŸå§‹spotsè¡¨è¾¾
            reconstructed_expression = self.spatial_organizer.reconstruct_from_multiscale(
                reconstructed_multiscale, positions, reconstruction_method='finest_scale'
            )
        
        # è®¡ç®—æ€»æŸå¤±
        total_vqvae_loss = sum(all_vqvae_losses) / len(all_vqvae_losses)
        var_loss = var_result['loss']
        
        # ç©ºé—´é‡å»ºæŸå¤±
        spatial_recon_loss = F.mse_loss(reconstructed_expression, gene_expression)
        
        # ç»„åˆæŸå¤±
        total_loss = var_loss + 0.1 * total_vqvae_loss + 0.1 * spatial_recon_loss
        
        print(f"ğŸ“Š æŸå¤±ç»Ÿè®¡:")
        print(f"   - VARæŸå¤±: {var_loss.item():.4f}")
        print(f"   - VQVAEæŸå¤±: {total_vqvae_loss.item():.4f}")
        print(f"   - ç©ºé—´é‡å»ºæŸå¤±: {spatial_recon_loss.item():.4f}")
        print(f"   - æ€»æŸå¤±: {total_loss.item():.4f}")
        
        return {
            'loss': total_loss,
            'var_loss': var_loss,
            'vqvae_loss': total_vqvae_loss,
            'spatial_recon_loss': spatial_recon_loss,
            'predictions': reconstructed_expression,
            'targets': gene_expression,
            'tokens': combined_tokens,
            'multiscale_expressions': multiscale_expressions
        }
    
    def forward_inference(
        self,
        histology_features: torch.Tensor,
        positions: torch.Tensor,
        class_labels: Optional[torch.Tensor] = None,
        cfg_scale: float = 1.5,
        top_k: int = 50,
        top_p: float = 0.9,
        temperature: float = 1.0,
        num_samples: int = 1
    ) -> Dict[str, torch.Tensor]:
        """
        æ¨ç†é˜¶æ®µï¼šä»ç»„ç»‡å­¦ç‰¹å¾å’Œç©ºé—´ä½ç½®ç”ŸæˆåŸºå› è¡¨è¾¾é¢„æµ‹
        
        Args:
            histology_features: [B, N, feature_dim] - ç»„ç»‡å­¦ç‰¹å¾
            positions: [B, N, 2] - ç©ºé—´åæ ‡
            class_labels: [B] - æ¡ä»¶ç±»åˆ«(å¯é€‰)
            cfg_scale: Classifier-free guidanceç¼©æ”¾å› å­
            top_k, top_p, temperature: é‡‡æ ·å‚æ•°
            num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
        
        Returns:
            DictåŒ…å«ç”Ÿæˆçš„åŸºå› è¡¨è¾¾é¢„æµ‹
        """
        B, N, feature_dim = histology_features.shape
        device = histology_features.device
        
        print(f"ğŸ”® VAR-STæ¨ç†ç”Ÿæˆ:")
        print(f"   - è¾“å…¥ç‰¹å¾: {histology_features.shape}")
        print(f"   - ç©ºé—´ä½ç½®: {positions.shape}")
        print(f"   - CFG scale: {cfg_scale}")
        
        # å¤„ç†ç»„ç»‡å­¦ç‰¹å¾
        actual_hist_dim = histology_features.shape[-1]
        histology_processor = self._get_histology_processor(actual_hist_dim)
        processed_hist = histology_processor(histology_features)
        
        # ç”Ÿæˆç±»åˆ«æ ‡ç­¾
        if class_labels is None:
            hist_stats = torch.mean(processed_hist.view(B, -1), dim=1) * 1000
            class_labels = hist_stats.long() % 1000
        
        print(f"   - ç±»åˆ«æ ‡ç­¾: {class_labels.shape}")
        
        # VARç”Ÿæˆtokensåºåˆ—
        print(f"ğŸš€ VARè‡ªå›å½’ç”Ÿæˆtokens...")
        generated_tokens = self.var_model.autoregressive_infer_cfg(
            B=B * num_samples,
            class_labels=class_labels.repeat(num_samples) if class_labels is not None else None,
            cfg=cfg_scale,
            top_k=top_k,
            top_p=top_p,
            temperature=temperature,
            generator=torch.Generator(device=device).manual_seed(42)
        )
        
        print(f"   - ç”Ÿæˆtokens: {generated_tokens.shape}")
        
        # åˆ†è§£tokensåˆ°ä¸åŒå°ºåº¦
        split_tokens = self._split_tokens_by_scale(generated_tokens)
        
        # ä»tokensè§£ç å¤šå°ºåº¦åŸºå› è¡¨è¾¾
        print(f"ğŸ”§ ä»tokensè§£ç å¤šå°ºåº¦åŸºå› è¡¨è¾¾...")
        decoded_multiscale = self._decode_multiscale_from_tokens(split_tokens)
        
        # ä»å¤šå°ºåº¦é‡å»ºæœ€ç»ˆåŸºå› è¡¨è¾¾
        print(f"ğŸ”„ ä»å¤šå°ºåº¦é‡å»ºæœ€ç»ˆåŸºå› è¡¨è¾¾...")
        final_expression = self.spatial_organizer.reconstruct_from_multiscale(
            decoded_multiscale, positions, reconstruction_method='hierarchical'
        )
        
        print(f"   - æœ€ç»ˆé¢„æµ‹: {final_expression.shape}")
        
        return {
            'predictions': final_expression,
            'tokens': generated_tokens,
            'multiscale_expressions': decoded_multiscale
        }
    
    def _decode_multiscale_from_tokens(
        self, 
        split_tokens: List[torch.Tensor]
    ) -> List[torch.Tensor]:
        """ä»åˆ†å‰²çš„tokensè§£ç å¤šå°ºåº¦åŸºå› è¡¨è¾¾"""
        decoded_expressions = []
        
        for scale_idx, scale_tokens in enumerate(split_tokens):
            scale = self.spatial_scales[scale_idx]
            scale_vqvae = self.vqvaes[scale_idx]
            
            # é‡å¡‘ä¸ºVQVAEæœŸæœ›çš„æ ¼å¼
            B, num_cells = scale_tokens.shape
            scale_tokens_flat = scale_tokens.view(-1)  # [B*num_cells]
            
            # VQVAEè§£ç 
            decoded_flat = scale_vqvae.decode_from_tokens(scale_tokens_flat)  # [B*num_cells, num_genes]
            
            # é‡å¡‘å›å¤šå°ºåº¦æ ¼å¼
            num_genes = decoded_flat.shape[-1]
            decoded = decoded_flat.view(B, num_cells, num_genes)  # [B, num_cells, num_genes]
            
            decoded_expressions.append(decoded)
        
        return decoded_expressions
    
    def _split_tokens_by_scale(self, combined_tokens: torch.Tensor) -> List[torch.Tensor]:
        """å°†ç»„åˆçš„tokensåºåˆ—åˆ†å‰²å›å„ä¸ªå°ºåº¦"""
        B = combined_tokens.shape[0]
        split_tokens = []
        start_idx = 0
        
        for scale_idx, tokens_count in enumerate(self.tokens_per_scale):
            end_idx = start_idx + tokens_count
            scale_tokens = combined_tokens[:, start_idx:end_idx]  # [B, tokens_count]
            split_tokens.append(scale_tokens)
            start_idx = end_idx
        
        return split_tokens
    
    def forward(self, **inputs) -> Dict[str, torch.Tensor]:
        """ç»Ÿä¸€å‰å‘ä¼ æ’­æ¥å£"""
        mode = inputs.get('mode', 'training')
        
        if mode == 'training':
            return self.forward_training(
                gene_expression=inputs['gene_expression'],
                histology_features=inputs['histology_features'],
                positions=inputs['positions'],
                class_labels=inputs.get('class_labels')
            )
        else:
            return self.forward_inference(
                histology_features=inputs['histology_features'],
                positions=inputs['positions'],
                class_labels=inputs.get('class_labels'),
                cfg_scale=inputs.get('cfg_scale', 1.5),
                top_k=inputs.get('top_k', 50),
                top_p=inputs.get('top_p', 0.9),
                temperature=inputs.get('temperature', 1.0),
                num_samples=inputs.get('num_samples', 1)
            ) 