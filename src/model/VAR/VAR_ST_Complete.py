"""
VAR-ST Complete: åŸºäºåŸå§‹VARæ¶æ„çš„åŸºå› è¡¨è¾¾é¢„æµ‹æ¨¡å‹

æ ¸å¿ƒè®¾è®¡ç†å¿µï¼š
- å®Œå…¨ä¿æŒåŸå§‹VARæ¶æ„ä¸å˜
- åŸºå› è¡¨è¾¾å‘é‡ â†’ å•é€šé“ä¼ªå›¾åƒ â†’ VARå¤„ç†
- ä½¿ç”¨æ•°æ®é€‚é…è€Œéæ¶æ„ä¿®æ”¹çš„æ–¹å¼
- æ­£ç¡®ç†è§£VARçš„next-scale predictionæœºåˆ¶
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple, Any
import numpy as np
import math
import os

# å¯¼å…¥VARåŸºå› åŒ…è£…å™¨
from .var_gene_wrapper import VARGeneWrapper


class VAR_ST_Complete(nn.Module):
    """
    VAR-ST Complete: åŸºäºåŸå§‹VARçš„åŸºå› è¡¨è¾¾é¢„æµ‹æ¨¡å‹
    
    ğŸ”§ ä¿®å¤æ ¸å¿ƒé—®é¢˜ï¼šä½¿ç”¨paddingç­–ç•¥è§£å†³VARçš„2Då°ºå¯¸é™åˆ¶
    
    å…³é”®æ”¹è¿›ï¼š
    - ä½¿ç”¨16Ã—16è€Œä¸æ˜¯14Ã—14å›¾åƒå°ºå¯¸
    - 196åŸºå›  + 60ä¸ªé›¶padding = 256ä½ç½® (16Ã—16)
    - ä¸ºVARæä¾›è¶³å¤Ÿçš„ç©ºé—´è¿›è¡Œå¤šå±‚å·ç§¯å¤„ç†
    - patch_numsä½¿ç”¨æ ‡å‡†åºåˆ—ï¼š(1, 2, 4, 8, 16)
    
    VARçš„æ ¸å¿ƒåŸç†ï¼š
    - ä¸æ˜¯ä¼ ç»Ÿçš„patch-basedå¤„ç†
    - è€Œæ˜¯multi-scale autoregressive generation
    - patch_nums = [1, 2, 4, 8, 16] è¡¨ç¤ºç”Ÿæˆåºåˆ—ï¼š1x1 â†’ 2x2 â†’ 4x4 â†’ 8x8 â†’ 16x16
    - æ¯ä¸ªscaleåŸºäºå‰ä¸€ä¸ªscaleè¿›è¡Œautoregressive prediction
    """
    
    def __init__(
        self,
        num_genes: int = 196,  # ğŸ”§ å›ºå®š196åŸºå› 
        spatial_size: int = 64,  # ğŸ”§ æ”¹ä¸º64Ã—64ï¼Œè§£å†³VQVAEä¸‹é‡‡æ ·é—®é¢˜
        histology_feature_dim: Optional[int] = None,  # ğŸ”§ æ”¹ä¸ºå¯é€‰å‚æ•°
        feature_dim: Optional[int] = None,  # ğŸ†• æ–°å¢ä»config.MODEL.feature_dimä¼ å…¥çš„å‚æ•°
        var_config: Optional[Dict] = None,
        vqvae_config: Optional[Dict] = None,
        adapter_config: Optional[Dict] = None,
        **kwargs
    ):
        """
        å®Œæ•´ç‰ˆVAR-STæ¨¡å‹ï¼šç©ºé—´è½¬å½•ç»„å­¦åŸºå› è¡¨è¾¾é¢„æµ‹ - Paddingç‰ˆæœ¬
        
        å…³é”®å˜åŒ–ï¼š
        - ğŸ”§ å›ºå®š196åŸºå›  â†’ 16Ã—16ä¼ªå›¾åƒ (paddingç­–ç•¥)
        - ğŸ”§ ä½¿ç”¨æ ‡å‡†VARåºåˆ—(1,2,4,8,16)ï¼Œé¿å…å°ºå¯¸è¿‡å°é—®é¢˜
        - ğŸ”§ ä»æ•°æ®é…ç½®æ­£ç¡®è·å–ç»„ç»‡å­¦ç‰¹å¾ç»´åº¦
        
        Args:
            num_genes: åŸºå› æ•°é‡ï¼Œå›ºå®š196
            spatial_size: ç©ºé—´å°ºå¯¸ï¼Œæ”¹ä¸º16Ã—16 (paddingåˆ°256ä½ç½®)
            histology_feature_dim: ç»„ç»‡å­¦ç‰¹å¾ç»´åº¦ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            feature_dim: ä»config.MODEL.feature_dimä¼ å…¥çš„ç‰¹å¾ç»´åº¦ï¼ˆä½œä¸ºfallbackï¼‰
            var_config: VARæ¨¡å‹é…ç½®
            vqvae_config: VQVAEæ¨¡å‹é…ç½®
            adapter_config: é€‚é…å™¨é…ç½®
        """
        super().__init__()
        
        # ğŸ”§ ç¡®å®šæ­£ç¡®çš„ç»„ç»‡å­¦ç‰¹å¾ç»´åº¦
        if histology_feature_dim is not None:
            self.histology_feature_dim = histology_feature_dim
        elif feature_dim is not None:
            self.histology_feature_dim = feature_dim
            print(f"ğŸ”§ ä½¿ç”¨config.MODEL.feature_dimä½œä¸ºhistology_feature_dim: {feature_dim}")
        else:
            # é»˜è®¤å€¼ä¿æŒ512ï¼Œä½†ä¼šåœ¨ä¸‹é¢è­¦å‘Š
            self.histology_feature_dim = 512
            print("âš ï¸ æœªæŒ‡å®šhistology_feature_dimï¼Œä½¿ç”¨é»˜è®¤å€¼512ï¼Œå¯èƒ½å¯¼è‡´ç»´åº¦ä¸åŒ¹é…")
        
        # å›ºå®šé…ç½®éªŒè¯
        if num_genes != 196:
            raise ValueError(f"VAR_ST_Completeåªæ”¯æŒ196åŸºå› ï¼Œgot {num_genes}")
        
        if spatial_size < 16:
            raise ValueError(f"paddingç­–ç•¥è¦æ±‚spatial_sizeè‡³å°‘ä¸º16ï¼Œgot {spatial_size}")
        
        self.num_genes = num_genes
        self.spatial_size = spatial_size
        
        print(f"ğŸ—ï¸ åˆå§‹åŒ–VAR_ST_Complete (196åŸºå›  + Paddingç­–ç•¥):")
        print(f"   - åŸºå› æ•°é‡: {self.num_genes}")
        print(f"   - ç›®æ ‡å›¾åƒå°ºå¯¸: {self.spatial_size}Ã—{self.spatial_size} (paddingç­–ç•¥)")
        print(f"   - æ€»ä½ç½®æ•°: {self.spatial_size * self.spatial_size}")
        print(f"   - Paddingå¤§å°: {self.spatial_size * self.spatial_size - self.num_genes}")
        print(f"   - ç©ºé—´åˆ©ç”¨ç‡: {self.num_genes / (self.spatial_size * self.spatial_size):.1%}")
        print(f"   - ç»„ç»‡å­¦ç‰¹å¾ç»´åº¦: {self.histology_feature_dim}")
        
        # ğŸ”§ ä½¿ç”¨æ ‡å‡†VARå…¼å®¹çš„patch_numsåºåˆ—
        if spatial_size == 64:
            var_patch_nums = (1, 2, 4)  # 64Ã—64è¾“å…¥ç»16å€ä¸‹é‡‡æ ·åä¸º4Ã—4
        elif spatial_size == 16:
            var_patch_nums = (1, 2, 4, 8, 16)  # æ ‡å‡†VARåºåˆ—ï¼Œç»è¿‡éªŒè¯
        elif spatial_size == 20:
            var_patch_nums = (1, 2, 4, 5, 10, 20)  # 20Ã—20çš„å› å­åºåˆ—
        else:
            # é€šç”¨ç­–ç•¥ï¼šç”Ÿæˆåˆé€‚çš„å› å­åºåˆ—
            var_patch_nums = self._generate_patch_nums_for_size(spatial_size)
        
        print(f"ğŸ§¬ VARå¤šå°ºåº¦é…ç½®:")
        print(f"   - Patchåºåˆ—: {var_patch_nums}")
        print(f"   - åˆ†è¾¨ç‡æ¼”è¿›: {' â†’ '.join([f'{p}Ã—{p}' for p in var_patch_nums])}")
        print(f"   - Tokenæ•°é‡: {' + '.join([f'{p*p}' for p in var_patch_nums])} = {sum(p*p for p in var_patch_nums)}")
        
        # ğŸ”§ ä½¿ç”¨åŸºå› åŒ…è£…å™¨ - ä¼ å…¥16Ã—16é…ç½®
        self.var_gene_wrapper = VARGeneWrapper(
            num_genes=num_genes,
            image_size=spatial_size,  # ä½¿ç”¨16Ã—16
            histology_feature_dim=self.histology_feature_dim,  # ğŸ”§ ä½¿ç”¨æ­£ç¡®çš„ç»´åº¦
            patch_nums=var_patch_nums,  # ğŸ”§ ä¼ å…¥æ ‡å‡†VARå…¼å®¹åºåˆ—
            var_config=var_config,
            vqvae_config=vqvae_config,
            adapter_config=adapter_config
        )
        
        # è®­ç»ƒçŠ¶æ€ç®¡ç†
        self._step_count = 0
        self._verbose_logging = True
        
        # æ˜¾ç¤ºpaddingç­–ç•¥ä¼˜åŠ¿
        self._show_padding_strategy(var_patch_nums)
        
        # éªŒè¯é…ç½®æ­£ç¡®æ€§
        self._validate_var_config(spatial_size, var_patch_nums)  # éªŒè¯VARå…¼å®¹åºåˆ—
        
        print(f"âœ… VAR-ST Completeåˆå§‹åŒ–å®Œæˆ (Paddingç­–ç•¥)")
    
    def _show_padding_strategy(self, var_patch_nums: Tuple[int, ...]):
        """æ˜¾ç¤ºpaddingç­–ç•¥çš„ä¼˜åŠ¿"""
        print(f"   ğŸ“¦ Paddingç­–ç•¥ä¼˜åŠ¿:")
        print(f"     * è§£å†³å°ºå¯¸é™åˆ¶: 14Ã—14å¤ªå° â†’ 16Ã—16è¶³å¤Ÿå¤§")
        print(f"     * æ”¯æŒæ ‡å‡†VAR: ä½¿ç”¨ç»è¿‡éªŒè¯çš„patchåºåˆ—")
        print(f"     * ä¿æŒæ¶æ„ä¸å˜: æ— éœ€ä¿®æ”¹VAR/VQVAEæ ¸å¿ƒä»£ç ")
        print(f"     * ä¿¡æ¯ä¿æŒå®Œæ•´: 196åŸºå› ä¿¡æ¯å®Œå…¨ä¿ç•™")
        print(f"     * è®¡ç®—å¼€é”€å°: ä»…å¢åŠ {(self.spatial_size**2 - self.num_genes) / self.num_genes:.1%}çš„å­˜å‚¨")
        
        total_tokens = sum(p*p for p in var_patch_nums)
        print(f"   ğŸ¯ å¤šå°ºåº¦tokenåˆ†å¸ƒ:")
        for i, p in enumerate(var_patch_nums):
            tokens = p * p
            percentage = tokens / total_tokens * 100
            print(f"     * å°ºåº¦{i+1}: {p}Ã—{p}={tokens} tokens ({percentage:.1f}%)")
    
    def _map_biological_to_var_scales(self, image_size: int) -> Tuple[int, ...]:
        """ä¸ºpaddingç­–ç•¥ç”ŸæˆVARå…¼å®¹çš„ç©ºé—´å¤šå°ºåº¦"""
        if image_size == 16:
            # 16Ã—16å›¾åƒçš„æ ‡å‡†VARå…¼å®¹åºåˆ—
            return (1, 2, 4, 8, 16)
        elif image_size == 20:
            # 20Ã—20å›¾åƒçš„VARå…¼å®¹åºåˆ—  
            return (1, 2, 4, 5, 10, 20)
        elif image_size == 24:
            # 24Ã—24å›¾åƒçš„VARå…¼å®¹åºåˆ—
            return (1, 2, 3, 4, 6, 8, 12, 24)
        else:
            # é€šç”¨æ˜ å°„ï¼šç”Ÿæˆåˆé€‚çš„å› å­åºåˆ—
            factors = []
            for i in range(1, image_size + 1):
                if image_size % i == 0:
                    factors.append(i)
            # é€‰æ‹©åˆç†çš„å­é›†ï¼Œç¡®ä¿ä¸è¶…è¿‡6-8ä¸ªå°ºåº¦
            if len(factors) > 8:
                step = len(factors) // 6
                selected_factors = factors[::step] + [factors[-1]]
                return tuple(sorted(set(selected_factors)))
            return tuple(factors)
    
    def _calculate_var_config(self, num_genes: int, patch_nums: Optional[Tuple[int, ...]]) -> Tuple[int, Tuple[int, ...]]:
        """
        ğŸ”§ è§£å†³éœ€æ±‚ä¸VARæ¶æ„å…¼å®¹æ€§ï¼šç”Ÿç‰©å­¦å¤šå°ºåº¦æ˜ å°„åˆ°VARç©ºé—´å¤šå°ºåº¦
        
        æ ¸å¿ƒé—®é¢˜ï¼š
        - éœ€æ±‚ï¼špatch_nums = (1, 2, 3, 4, 5) - ç”Ÿç‰©å­¦è¯­ä¹‰å±‚æ¬¡
        - VARï¼šè¦æ±‚patch_nums[-1] == image_size - ç©ºé—´åˆ†è¾¨ç‡çº¦æŸ
        
        è§£å†³æ–¹æ¡ˆï¼š
        - ä¿æŒéœ€æ±‚çš„ç”Ÿç‰©å­¦è¯­ä¹‰æ¦‚å¿µ
        - å°†ç”Ÿç‰©å­¦å¤šå°ºåº¦æ˜ å°„åˆ°VARå…¼å®¹çš„ç©ºé—´åºåˆ—
        - 196åŸºå›  â†’ 14Ã—14 â†’ VARç©ºé—´åºåˆ—ï¼š(1, 2, 7, 14)
        
        Args:
            num_genes: åŸºå› æ•°é‡
            patch_nums: å¯é€‰çš„patchåºåˆ—ï¼ˆå°†è¢«è§£é‡Šä¸ºç”Ÿç‰©å­¦è¯­ä¹‰ï¼‰
            
        Returns:
            (image_size, var_patch_nums): å›¾åƒå°ºå¯¸å’ŒVARå…¼å®¹çš„patchåºåˆ—
        """
        # ğŸ”§ ä¸¥æ ¼æŒ‰ç…§éœ€æ±‚ï¼š196åŸºå› å¿…é¡»å¯¹åº”14Ã—14å›¾åƒ
        if num_genes == 196:
            image_size = 14  # 14Ã—14 = 196ï¼Œå®Œç¾åŒ¹é…
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šè§£å†³ç”Ÿç‰©å­¦å¤šå°ºåº¦ä¸VARç©ºé—´çº¦æŸçš„å†²çª
            # éœ€æ±‚çš„ç”Ÿç‰©å­¦å¤šå°ºåº¦ï¼š(1, 2, 3, 4, 5) 
            # VARå…¼å®¹çš„ç©ºé—´å¤šå°ºåº¦ï¼š(1, 2, 7, 14) - ç¡®ä¿æœ€åå€¼=14
            biological_scales = (1, 2, 3, 4, 5)  # éœ€æ±‚ä¸­çš„ç”Ÿç‰©å­¦è¯­ä¹‰
            var_spatial_scales = (1, 2, 7, 14)   # VARå…¼å®¹çš„ç©ºé—´åºåˆ—
            
            print(f"ğŸ§¬ ç”Ÿç‰©å­¦å¤šå°ºåº¦è¯­ä¹‰æ˜ å°„:")
            print(f"   - ç”Ÿç‰©å­¦å°ºåº¦: {biological_scales}")
            print(f"     * 1: å…¨å±€åŸºå› è¡¨è¾¾æ¨¡å¼")
            print(f"     * 2: åŸºå› åŠŸèƒ½ç»„çº§åˆ«")
            print(f"     * 3: åŸºå› é€šè·¯çº§åˆ«")
            print(f"     * 4: åŸºå› å®¶æ—çº§åˆ«")
            print(f"     * 5: å•åŸºå› çº§åˆ«")
            print(f"   - VARç©ºé—´åºåˆ—: {var_spatial_scales} (ç¡®ä¿æœ€åå€¼=14)")
            print(f"   - æ˜ å°„ç­–ç•¥: ä¿æŒç”Ÿç‰©å­¦è¯­ä¹‰ï¼Œé€‚é…VARç©ºé—´çº¦æŸ")
            
            # å­˜å‚¨ç”Ÿç‰©å­¦è¯­ä¹‰ä¿¡æ¯ï¼Œä¾›åç»­ä½¿ç”¨
            default_patch_nums = var_spatial_scales
            self._biological_semantics = {
                'original_scales': biological_scales,
                'spatial_scales': var_spatial_scales,
                'semantic_names': [
                    "å…¨å±€åŸºå› è¡¨è¾¾æ¨¡å¼",
                    "åŸºå› åŠŸèƒ½ç»„çº§åˆ«", 
                    "åŸºå› é€šè·¯çº§åˆ«",
                    "å•åŸºå› çº§åˆ«"  # æ˜ å°„ååªæœ‰4å±‚
                ]
            }
            
        else:
            # å…¶ä»–åŸºå› æ•°é‡çš„å¤‡ç”¨æ˜ å°„
            gene_to_size_map = {
                225: 15,  # 225åŸºå›  â†’ 15Ã—15
                256: 16,  # 256åŸºå›  â†’ 16Ã—16
                144: 12,  # 144åŸºå›  â†’ 12Ã—12
                169: 13,  # 169åŸºå›  â†’ 13Ã—13
                64: 8,    # 64åŸºå›  â†’ 8Ã—8
                100: 10,  # 100åŸºå›  â†’ 10Ã—10
            }
            
            if num_genes in gene_to_size_map:
                image_size = gene_to_size_map[num_genes]
            else:
                # è‡ªåŠ¨è®¡ç®—æœ€æ¥è¿‘çš„å¹³æ–¹æ•°
                sqrt_genes = math.sqrt(num_genes)
                if sqrt_genes == int(sqrt_genes):
                    image_size = int(sqrt_genes)
                else:
                    image_size = math.ceil(sqrt_genes)
            
            # å¯¹äºé196åŸºå› çš„æƒ…å†µï¼Œç”ŸæˆVARå…¼å®¹çš„patch_nums
            default_patch_nums = self._generate_patch_nums_for_size(image_size)
            self._biological_semantics = None
        
        # ğŸ”§ å¦‚æœç”¨æˆ·æŒ‡å®šäº†patch_numsï¼Œè¿›è¡Œæ™ºèƒ½å¤„ç†
        if patch_nums is not None:
            # å¯¹äº196åŸºå› ï¼Œç”¨æˆ·çš„patch_numsè¢«ç†è§£ä¸ºç”Ÿç‰©å­¦æ„å›¾
            if num_genes == 196:
                print(f"âš ï¸ æ£€æµ‹åˆ°196åŸºå› ç”¨æˆ·é…ç½®: {patch_nums}")
                print(f"   è§£é‡Šä¸ºç”Ÿç‰©å­¦è¯­ä¹‰æ„å›¾ï¼Œä½†ä½¿ç”¨VARå…¼å®¹åºåˆ—: {default_patch_nums}")
                patch_nums = default_patch_nums
            # å¯¹äºå…¶ä»–åŸºå› ï¼ŒéªŒè¯VARå…¼å®¹æ€§
            elif patch_nums[-1] > image_size:
                print(f"âš ï¸ ç”¨æˆ·æŒ‡å®šçš„patch_numsæœ€å¤§å€¼ {patch_nums[-1]} è¶…è¿‡å›¾åƒå°ºå¯¸ {image_size}")
                print(f"   è‡ªåŠ¨ä¿®æ­£ä¸ºVARå…¼å®¹é…ç½®: {default_patch_nums}")
                patch_nums = default_patch_nums
        else:
            patch_nums = default_patch_nums
        
        return image_size, patch_nums
    
    def _generate_patch_nums_for_size(self, image_size: int) -> Tuple[int, ...]:
        """
        ä¸ºæŒ‡å®šå›¾åƒå°ºå¯¸ç”Ÿæˆåˆé€‚çš„patch_numsåºåˆ—
        
        æ³¨æ„ï¼špatch_numsçš„æœ€åä¸€ä¸ªå€¼åº”è¯¥ç­‰äºVQVAEç¼–ç å™¨çš„è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸ï¼Œ
        è€Œä¸æ˜¯è¾“å…¥å›¾åƒå°ºå¯¸ã€‚VARçš„VQVAEä¸‹é‡‡æ ·16å€ã€‚
        
        Args:
            image_size: å›¾åƒå°ºå¯¸
            
        Returns:
            åˆé€‚çš„patch_numsåºåˆ—
        """
        # æ ¹æ®å›¾åƒå°ºå¯¸ç”Ÿæˆåˆé€‚çš„åˆ†è¾¨ç‡åºåˆ—
        if image_size == 64:
            return (1, 2, 4)  # 64ç»16å€ä¸‹é‡‡æ ·åä¸º4
        elif image_size == 16:
            return (1, 2, 4, 8, 16)
        elif image_size == 15:
            return (1, 3, 5, 15)
        elif image_size == 14:
            return (1, 2, 7, 14)
        elif image_size == 12:
            return (1, 2, 3, 4, 6, 12)
        elif image_size == 13:
            return (1, 13)
        elif image_size == 10:
            return (1, 2, 5, 10)
        elif image_size == 8:
            return (1, 2, 4, 8)
        else:
            # é€šç”¨ç­–ç•¥ï¼šè®¡ç®—ä¸‹é‡‡æ ·åçš„ç‰¹å¾å›¾å°ºå¯¸
            feature_map_size = max(1, image_size // 16)  # VAR VQVAEä¸‹é‡‡æ ·16å€
            factors = []
            for i in range(1, feature_map_size + 1):
                if feature_map_size % i == 0:
                    factors.append(i)
            
            # æ„å»ºåˆç†çš„åºåˆ—
            if len(factors) >= 3:
                return tuple(factors)
            else:
                return (1, feature_map_size)
    
    def _generate_valid_patch_sequence(self, image_size: int) -> Tuple[int, ...]:
        """
        ğŸ”§ å½»åº•ä¿®å¤ï¼šVARçš„patch_numså®é™…ä¸Šæ˜¯åˆ†è¾¨ç‡åºåˆ—ï¼
        
        VARçš„çœŸæ­£åŸç†ï¼ˆä»åŸå§‹ä»£ç åˆ†æå¾—å‡ºï¼‰ï¼š
        - v_patch_nums = (1, 2, 3, 4, 5, 6, 8, 10, 13, 16) è¡¨ç¤ºåˆ†è¾¨ç‡åºåˆ—
        - ä»1Ã—1åˆ†è¾¨ç‡å¼€å§‹ï¼Œé€æ­¥æå‡åˆ°æœ€ç»ˆçš„HÃ—Wåˆ†è¾¨ç‡
        - å…³é”®æ–­è¨€ï¼špatch_hws[-1][0] == H and patch_hws[-1][1] == W
        - è¿™æ„å‘³ç€æœ€åä¸€ä¸ªå€¼å¿…é¡»ç­‰äºå›¾åƒçš„é«˜åº¦å’Œå®½åº¦
        
        Args:
            image_size: æœ€ç»ˆå›¾åƒå°ºå¯¸ï¼ˆæ­£æ–¹å½¢å›¾åƒï¼‰
            
        Returns:
            æ­£ç¡®çš„åˆ†è¾¨ç‡åºåˆ—
        """
        print(f"ğŸ” ç”ŸæˆVARåˆ†è¾¨ç‡åºåˆ—ï¼Œç›®æ ‡å°ºå¯¸ï¼š{image_size}Ã—{image_size}")
        
        # æ ¹æ®å›¾åƒå°ºå¯¸ç”Ÿæˆåˆé€‚çš„åˆ†è¾¨ç‡åºåˆ—
        if image_size == 16:
            # 16Ã—16: ç»å…¸VARé…ç½®ï¼Œä»1Ã—1åˆ°16Ã—16
            patch_nums = (1, 2, 4, 8, 16)
        elif image_size == 15:
            # 15Ã—15: éœ€è¦èƒ½è¢«15æ•´é™¤çš„åºåˆ—
            patch_nums = (1, 3, 5, 15)
        elif image_size == 12:
            # 12Ã—12: æ›´å¤šä¸­é—´æ­¥éª¤
            patch_nums = (1, 2, 3, 4, 6, 12)
        elif image_size == 8:
            # 8Ã—8: 2çš„å¹‚æ¬¡åºåˆ—
            patch_nums = (1, 2, 4, 8)
        elif image_size == 10:
            # 10Ã—10: å› å­åºåˆ—
            patch_nums = (1, 2, 5, 10)
        elif image_size == 14:
            # 14Ã—14: å› å­åºåˆ—
            patch_nums = (1, 2, 7, 14)
        else:
            # é€šç”¨ç­–ç•¥ï¼šæ‰¾åˆ°åˆç†çš„é€’å¢åºåˆ—ï¼Œç¡®ä¿æœ€åç­‰äºimage_size
            factors = []
            for i in range(1, image_size + 1):
                if image_size % i == 0:
                    factors.append(i)
            
            print(f"   - å¯ç”¨å› å­: {factors}")
            
            # æ„å»ºé€’å¢åºåˆ—
            if len(factors) >= 4:
                # é€‰æ‹©å‡ ä¸ªå…³é”®å› å­ï¼šå¼€å§‹ã€ä¸­é—´å‡ ä¸ªã€ç»“æŸ
                indices = [0, 1, len(factors)//2, len(factors)-2, len(factors)-1]
                patch_nums = tuple(factors[i] for i in indices if factors[i] <= image_size)
            elif len(factors) >= 3:
                patch_nums = (factors[0], factors[1], factors[-1])
            else:
                patch_nums = (1, image_size)
            
            # ç¡®ä¿åºåˆ—ä¸¥æ ¼é€’å¢ä¸”ä¸é‡å¤
            patch_nums = tuple(sorted(set(patch_nums)))
        
        print(f"âœ… ç”Ÿæˆçš„åˆ†è¾¨ç‡åºåˆ—: {patch_nums}")
        print(f"   - åˆ†è¾¨ç‡æ¼”è¿›: {' â†’ '.join([f'{p}Ã—{p}' for p in patch_nums])}")
        
        return patch_nums
    
    def _validate_var_config(self, image_size: int, patch_nums: Tuple[int, ...]):
        """
        ğŸ”§ éªŒè¯VARé…ç½®çš„æ­£ç¡®æ€§
        
        VARçš„ä¸¤å±‚ç»“æ„ï¼š
        1. VQVAEå±‚ï¼šå°†è¾“å…¥å›¾åƒç¼–ç åˆ°ç‰¹å¾å›¾ï¼Œè¦æ±‚patch_nums[-1]ç­‰äºç‰¹å¾å›¾å°ºå¯¸
        2. VARå±‚ï¼šä»ç‰¹å¾å›¾ç”Ÿæˆmulti-scale tokensåºåˆ—
        """
        print(f"ğŸ” éªŒè¯VARåˆ†è¾¨ç‡é…ç½®:")
        print(f"   - è¾“å…¥å›¾åƒå°ºå¯¸: {image_size}Ã—{image_size}")
        print(f"   - åˆ†è¾¨ç‡åºåˆ—: {patch_nums}")
        
        # VAR VQVAEä¸‹é‡‡æ ·16å€
        feature_map_size = image_size // 16
        print(f"   - VQVAEç‰¹å¾å›¾å°ºå¯¸: {feature_map_size}Ã—{feature_map_size} (ä¸‹é‡‡æ ·16å€)")
        
        # éªŒè¯1ï¼šæœ€åä¸€ä¸ªåˆ†è¾¨ç‡å¿…é¡»ç­‰äºVQVAEç‰¹å¾å›¾å°ºå¯¸
        if patch_nums[-1] != feature_map_size:
            raise ValueError(f"âŒ VQVAEè¦æ±‚ï¼šæœ€åä¸€ä¸ªåˆ†è¾¨ç‡ ({patch_nums[-1]}) å¿…é¡»ç­‰äºç‰¹å¾å›¾å°ºå¯¸ ({feature_map_size})")
        
        # éªŒè¯2ï¼šåºåˆ—å¿…é¡»ä¸¥æ ¼é€’å¢
        for i in range(1, len(patch_nums)):
            if patch_nums[i] <= patch_nums[i-1]:
                raise ValueError(f"âŒ åˆ†è¾¨ç‡åºåˆ—å¿…é¡»ä¸¥æ ¼é€’å¢ï¼Œä½† {patch_nums[i]} <= {patch_nums[i-1]}")
        
        # éªŒè¯3ï¼šç¬¬ä¸€ä¸ªåˆ†è¾¨ç‡åº”è¯¥æ˜¯1ï¼ˆVARæ ‡å‡†ï¼‰
        if patch_nums[0] != 1:
            print(f"âš ï¸ è­¦å‘Š: VARæ ‡å‡†æ˜¯ä»1Ã—1å¼€å§‹ï¼Œä½†å½“å‰ä»{patch_nums[0]}Ã—{patch_nums[0]}å¼€å§‹")
        
        # éªŒè¯4ï¼šè®¡ç®—tokenæ•°é‡
        total_tokens = sum(pn * pn for pn in patch_nums)
        print(f"   - æ€»tokenæ•°é‡: {total_tokens}")
        print(f"   - Tokenåˆ†å¸ƒ: {' + '.join([f'{pn}Â²={pn*pn}' for pn in patch_nums])}")
        print(f"   - åˆ†è¾¨ç‡æ¼”è¿›: {' â†’ '.join([f'{p}Ã—{p}' for p in patch_nums])}")
        
        print(f"âœ… VARåˆ†è¾¨ç‡é…ç½®éªŒè¯é€šè¿‡")

    def set_verbose_logging(self, verbose: bool):
        """è®¾ç½®è¯¦ç»†æ—¥å¿—è¾“å‡º"""
        self._verbose_logging = verbose
        if verbose:
            print("ğŸ”Š å¯ç”¨è¯¦ç»†è®­ç»ƒæ—¥å¿—")
        else:
            print("ğŸ”‡ åˆ‡æ¢åˆ°ç®€æ´è®­ç»ƒæ¨¡å¼")
    
    def forward_training(
        self,
        gene_expression: torch.Tensor,
        histology_features: torch.Tensor,
        positions: Optional[torch.Tensor] = None,
        class_labels: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """è®­ç»ƒé˜¶æ®µå‰å‘ä¼ æ’­"""
        self._step_count += 1
        # ğŸ”‡ å¤§å¹…å‡å°‘è¯¦ç»†è¾“å‡ºï¼šåªåœ¨å‰3æ­¥å’Œæ¯1000æ­¥æ˜¾ç¤ºè¯¦æƒ…
        # ğŸ”§ åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œåªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        is_main_process = int(os.environ.get('LOCAL_RANK', 0)) == 0
        show_details = (self._verbose_logging and is_main_process and 
                       (self._step_count <= 3 or self._step_count % 1000 == 0))
        
        if show_details:
            print(f"\nğŸ“Š VAR-ST Step {self._step_count} - ä¿®å¤ç‰ˆVARæ¶æ„è®­ç»ƒ:")
        
        # å¤„ç†å¤šspotè¾“å…¥æƒ…å†µ
        if gene_expression.dim() == 3 and gene_expression.shape[1] > 1:
            if show_details:
                print(f"ğŸ”„ æ£€æµ‹åˆ°å¤šspotè¾“å…¥ {gene_expression.shape}ï¼Œåˆ‡æ¢åˆ°å¤šspotæ¨¡å¼")
            return self.forward_multi_spot(gene_expression, histology_features, positions, class_labels)
        
        # æ ‡å‡†åŒ–è¾“å…¥æ ¼å¼
        gene_expression = self._normalize_gene_input(gene_expression, show_details)
        histology_features = self._normalize_histology_input(histology_features, show_details)
        
        B, num_genes = gene_expression.shape
        
        if show_details:
            print(f"   - åŸºå› è¡¨è¾¾: {gene_expression.shape}")
            print(f"   - ç»„ç»‡å­¦ç‰¹å¾: {histology_features.shape}")
            print(f"ğŸš€ æ‰§è¡Œ: åŸºå› â†’ä¼ªå›¾åƒâ†’VARå¤šå°ºåº¦ç¼–ç â†’è‡ªå›å½’è®­ç»ƒâ†’é‡å»º")
        
        # è°ƒç”¨VARåŸºå› åŒ…è£…å™¨è¿›è¡Œè®­ç»ƒ
        results = self.var_gene_wrapper.forward_training(
            gene_expression=gene_expression,
            histology_features=histology_features,
            class_labels=class_labels,
            show_details=show_details
        )
        
        if show_details:
            print(f"ğŸ“Š æŸå¤±: VAR={results['var_loss'].item():.4f}, é‡å»º={results['recon_loss'].item():.4f}, æ€»è®¡={results['loss'].item():.4f}")
        
        # æ·»åŠ å…¼å®¹æ€§å­—æ®µ
        results.update({
            'predicted_expression': results['predictions'],
            'logits': results['predictions'],
            'targets': gene_expression
        })
        
        return results
    
    def forward_multi_spot(
        self,
        gene_expression: torch.Tensor,
        histology_features: torch.Tensor,
        positions: Optional[torch.Tensor] = None,
        class_labels: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """å¤šspotå‰å‘ä¼ æ’­"""
        B, N, num_genes = gene_expression.shape
        
        print(f"ğŸŒŸ VAR-STå¤šspotå‰å‘ä¼ æ’­ (ä¿®å¤ç‰ˆVARæ¶æ„):")
        print(f"   - è¾“å…¥shape: {gene_expression.shape}")
        print(f"   - Batch size: {B}, Spots per sample: {N}")
        
        # é‡å¡‘è¾“å…¥
        gene_expr_flat = gene_expression.view(B * N, num_genes).contiguous()
        
        if histology_features.dim() == 3:
            hist_feat_flat = histology_features.view(B * N, -1).contiguous()
        else:
            hist_feat_flat = histology_features.unsqueeze(1).expand(-1, N, -1).view(B * N, -1).contiguous()
        
        if class_labels is not None:
            if class_labels.dim() == 1 and class_labels.shape[0] == B:
                class_labels_flat = class_labels.unsqueeze(1).expand(-1, N).view(B * N).contiguous()
            else:
                class_labels_flat = class_labels
        else:
            class_labels_flat = None
        
        # è°ƒç”¨å•spotè®­ç»ƒæ–¹æ³•
        spot_results = self.forward_training(
            gene_expression=gene_expr_flat,
            histology_features=hist_feat_flat,
            positions=None,
            class_labels=class_labels_flat
        )
        
        # é‡å¡‘è¾“å‡º
        predictions = spot_results['predictions'].view(B, N, num_genes).contiguous()
        targets = gene_expression
        
        return {
            'loss': spot_results['loss'],
            'var_loss': spot_results['var_loss'],
            'recon_loss': spot_results['recon_loss'],
            'predictions': predictions,
            'targets': targets,
            'predicted_expression': predictions,
            'logits': predictions,
            'class_labels': spot_results.get('class_labels'),
            'pseudo_images': spot_results.get('pseudo_images'),
            'tokens': spot_results.get('tokens')
        }
    
    def forward_inference(
        self,
        histology_features: torch.Tensor,
        positions: Optional[torch.Tensor] = None,
        class_labels: Optional[torch.Tensor] = None,
        cfg_scale: float = 1.5,
        top_k: int = 50,
        top_p: float = 0.9,
        temperature: float = 1.0,
        num_samples: int = 1
    ) -> Dict[str, torch.Tensor]:
        """æ¨ç†é˜¶æ®µï¼šä»ç»„ç»‡å­¦ç‰¹å¾ç”ŸæˆåŸºå› è¡¨è¾¾é¢„æµ‹"""
        histology_features = self._normalize_histology_input(histology_features, show_details=False)
        
        # ğŸ”‡ ç®€åŒ–æ¨ç†è¾“å‡º
        print(f"ğŸ”® VAR-STæ¨ç†: {histology_features.shape[0]} samples, CFG={cfg_scale}")
        
        # è°ƒç”¨VARåŸºå› åŒ…è£…å™¨è¿›è¡Œæ¨ç†
        results = self.var_gene_wrapper.forward_inference(
            histology_features=histology_features,
            class_labels=class_labels,
            cfg_scale=cfg_scale,
            top_k=top_k,
            top_p=top_p,
            temperature=temperature,
            num_samples=num_samples
        )
        
        print(f"âœ… æ¨ç†å®Œæˆ: {results['predictions'].shape}")
        
        # æ·»åŠ å…¼å®¹æ€§å­—æ®µ
        results.update({
            'predicted_expression': results['predictions'],
            'logits': results['predictions']
        })
        
        return results
    
    def _normalize_gene_input(self, gene_expression: torch.Tensor, show_details: bool = False) -> torch.Tensor:
        """æ ‡å‡†åŒ–åŸºå› è¡¨è¾¾è¾“å…¥æ ¼å¼"""
        if gene_expression.dim() == 3:
            B, N, num_genes = gene_expression.shape
            if N == 1:
                gene_expression = gene_expression.squeeze(1)
                if show_details:
                    print(f"ğŸ”§ å‹ç¼©å•spotè¾“å…¥: [B, N=1, num_genes] â†’ [B, num_genes]")
            else:
                raise ValueError(f"å¤šspotè¾“å…¥åº”ç”±forward_multi_spotå¤„ç†: {gene_expression.shape}")
        
        return gene_expression.contiguous()
    
    def _normalize_histology_input(self, histology_features: torch.Tensor, show_details: bool = False) -> torch.Tensor:
        """æ ‡å‡†åŒ–ç»„ç»‡å­¦ç‰¹å¾è¾“å…¥æ ¼å¼"""
        if histology_features.dim() == 3:
            B, N, feature_dim = histology_features.shape
            if N == 1:
                histology_features = histology_features.squeeze(1)
                if show_details:
                    print(f"ğŸ”§ å‹ç¼©å•spotç‰¹å¾: [B, N=1, feature_dim] â†’ [B, feature_dim]")
            else:
                histology_features = histology_features.mean(dim=1)
                if show_details:
                    print(f"ğŸ”§ å¹³å‡å¤šspotç‰¹å¾: [B, N={N}, feature_dim] â†’ [B, feature_dim]")
        
        return histology_features.contiguous()
    
    def forward(self, **inputs) -> Dict[str, torch.Tensor]:
        """ç»Ÿä¸€å‰å‘ä¼ æ’­æ¥å£"""
        mode = inputs.get('mode', 'training')
        
        gene_expression = inputs.get('gene_expression')
        histology_features = inputs.get('histology_features')
        
        if mode == 'training':
            return self.forward_training(
                gene_expression=gene_expression,
                histology_features=histology_features,
                positions=inputs.get('positions'),
                class_labels=inputs.get('class_labels')
            )
        else:
            return self.forward_inference(
                histology_features=histology_features,
                positions=inputs.get('positions'),
                class_labels=inputs.get('class_labels'),
                cfg_scale=inputs.get('cfg_scale', 1.5),
                top_k=inputs.get('top_k', 50),
                top_p=inputs.get('top_p', 0.9),
                temperature=inputs.get('temperature', 1.0),
                num_samples=inputs.get('num_samples', 1)
            )
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'model_name': 'VAR_ST_Complete',
            'architecture': 'VAR + Gene Pseudo Image Adapter (Fixed)',
            'num_genes': self.num_genes,
            'pseudo_image_size': f"{self.spatial_size}x{self.spatial_size}",
            'patch_nums': (1, 2, 4, 8, 16),
            'histology_feature_dim': self.histology_feature_dim,
            'patch_sequence': ' â†’ '.join([f'{p}Ã—{p}' for p in (1, 2, 4, 8, 16)]),
            'total_parameters': sum(p.numel() for p in self.parameters()),
            'trainable_parameters': sum(p.numel() for p in self.parameters() if p.requires_grad)
        } 