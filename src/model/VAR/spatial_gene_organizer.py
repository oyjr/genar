"""
Spatial Gene Expression Organizer for VAR-ST

This module converts scattered spot gene expressions into spatial "images" 
that VAR can process, maintaining the original VAR architecture without modifications.

Author: VAR-ST Team
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Tuple, Optional


class SpatialGeneOrganizer:
    """
    å°†æ•£ä¹±çš„spotsåŸºå› è¡¨è¾¾é‡ç»„ä¸ºè§„åˆ™çš„ç©ºé—´"å›¾åƒ"
    è¿™æ˜¯é€‚é…VARçš„å…³é”®ç»„ä»¶ - å®Œå…¨ä¿ç•™åŸå§‹è¾“å…¥æ ¼å¼
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. spotsåŸºå› è¡¨è¾¾ -> ç©ºé—´åŸºå› è¡¨è¾¾"å›¾åƒ" (ç±»ä¼¼RGBå›¾åƒ)
    2. ç©ºé—´åŸºå› è¡¨è¾¾"å›¾åƒ" -> spotsåŸºå› è¡¨è¾¾ (é€†å‘æ“ä½œ)
    
    è®¾è®¡ç†å¿µï¼š
    - å°†åŸºå› è¡¨è¾¾è§†ä¸º"é¢œè‰²é€šé“"
    - å°†ç©ºé—´ä½ç½®è§†ä¸º"åƒç´ ä½ç½®"
    - ä½¿VARèƒ½å¤Ÿåƒå¤„ç†å›¾åƒä¸€æ ·å¤„ç†åŸºå› è¡¨è¾¾æ•°æ®
    """
    
    def __init__(self, target_spatial_size: int = 16, num_genes: int = 200):
        """
        Initialize spatial gene organizer
        
        Args:
            target_spatial_size: Target spatial size for gene expression "image"
                                Creates target_spatial_size Ã— target_spatial_size grid
            num_genes: Number of genes, acts as "color channels"
        """
        self.target_size = target_spatial_size
        self.num_genes = num_genes
        
        print(f"ğŸ”§ åˆå§‹åŒ–ç©ºé—´åŸºå› ç»„ç»‡å™¨:")
        print(f"  - ç›®æ ‡ç©ºé—´å°ºå¯¸: {target_spatial_size}Ã—{target_spatial_size}")
        print(f"  - åŸºå› æ•°é‡: {num_genes} (ä½œä¸ºé¢œè‰²é€šé“)")
    
    def spots_to_spatial_gene_image(
        self, 
        gene_expression: torch.Tensor, 
        positions: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        æ ¸å¿ƒåŠŸèƒ½ï¼šå°†spotsè½¬æ¢ä¸ºç©ºé—´åŸºå› "å›¾åƒ"
        
        è¿™ä¸ªå‡½æ•°å®ç°äº†ä»ç¦»æ•£spotsåˆ°è¿ç»­ç©ºé—´è¡¨ç¤ºçš„è½¬æ¢ï¼Œ
        ä½¿å¾—VARå¯ä»¥åƒå¤„ç†å›¾åƒä¸€æ ·å¤„ç†åŸºå› è¡¨è¾¾æ•°æ®ã€‚
        
        Args:
            gene_expression: [B, N, num_genes] - spotsçš„åŸºå› è¡¨è¾¾
            positions: [B, N, 2] - spotsçš„ç©ºé—´ä½ç½®ï¼ŒèŒƒå›´[0,1]
        
        Returns:
            spatial_gene_image: [B, num_genes, H, W] - ç©ºé—´åŸºå› è¡¨è¾¾"å›¾åƒ"
            spatial_mask: [B, 1, H, W] - æœ‰æ•ˆåŒºåŸŸæ©ç 
        """
        B, N, G = gene_expression.shape
        H, W = self.target_size, self.target_size
        
        # åˆå§‹åŒ–ç©ºé—´ç½‘æ ¼
        spatial_gene_image = torch.zeros(B, G, H, W, device=gene_expression.device, dtype=gene_expression.dtype)
        spatial_mask = torch.zeros(B, 1, H, W, device=gene_expression.device, dtype=gene_expression.dtype)
        spot_count_grid = torch.zeros(B, H, W, device=gene_expression.device, dtype=gene_expression.dtype)
        
        for b in range(B):
            # å°†è¿ç»­ä½ç½®[0,1]æ˜ å°„åˆ°ç½‘æ ¼åæ ‡[0, H-1], [0, W-1]
            grid_x = (positions[b, :, 0] * (W - 1)).long().clamp(0, W - 1)  # [N]
            grid_y = (positions[b, :, 1] * (H - 1)).long().clamp(0, H - 1)  # [N]
            
            # èšåˆåˆ°ç½‘æ ¼ï¼šå¤„ç†å¤šä¸ªspotsæ˜ å°„åˆ°åŒä¸€ç½‘æ ¼çš„æƒ…å†µ
            for n in range(N):
                x, y = grid_x[n].item(), grid_y[n].item()
                spatial_gene_image[b, :, y, x] += gene_expression[b, n]  # [G]
                spot_count_grid[b, y, x] += 1
                spatial_mask[b, 0, y, x] = 1
        
        # å½’ä¸€åŒ–ï¼šå¹³å‡åŒä¸€ç½‘æ ¼å†…çš„å¤šä¸ªspots
        # è¿™ç¡®ä¿äº†ç©ºé—´å¯†åº¦ä¸åŒçš„åŒºåŸŸå…·æœ‰åˆç†çš„åŸºå› è¡¨è¾¾å€¼
        for b in range(B):
            for y in range(H):
                for x in range(W):
                    if spot_count_grid[b, y, x] > 1:
                        spatial_gene_image[b, :, y, x] /= spot_count_grid[b, y, x]
        
        return spatial_gene_image, spatial_mask
    
    def spatial_gene_image_to_spots(
        self, 
        spatial_gene_image: torch.Tensor, 
        target_positions: torch.Tensor
    ) -> torch.Tensor:
        """
        é€†å‘æ“ä½œï¼šä»ç©ºé—´åŸºå› "å›¾åƒ"æå–spotsçš„åŸºå› è¡¨è¾¾
        
        ä½¿ç”¨åŒçº¿æ€§æ’å€¼ä»è¿ç»­çš„ç©ºé—´åŸºå› è¡¨è¾¾å›¾åƒä¸­æå–ä»»æ„ä½ç½®çš„åŸºå› è¡¨è¾¾å€¼ã€‚
        è¿™ä½¿å¾—æ¨¡å‹å¯ä»¥é¢„æµ‹ä»»æ„ç©ºé—´ä½ç½®çš„åŸºå› è¡¨è¾¾ï¼Œè€Œä¸ä»…ä»…æ˜¯è®­ç»ƒæ—¶çš„ç½‘æ ¼ä½ç½®ã€‚
        
        Args:
            spatial_gene_image: [B, num_genes, H, W] - ç©ºé—´åŸºå› è¡¨è¾¾"å›¾åƒ"
            target_positions: [B, N, 2] - ç›®æ ‡spotsä½ç½®ï¼ŒèŒƒå›´[0,1]
        
        Returns:
            gene_expression: [B, N, num_genes] - spotsåŸºå› è¡¨è¾¾
        """
        B, G, H, W = spatial_gene_image.shape
        N = target_positions.shape[1]
        
        gene_expression = torch.zeros(B, N, G, device=spatial_gene_image.device, dtype=spatial_gene_image.dtype)
        
        for b in range(B):
            # å¯¹æ¯ä¸ªç›®æ ‡spotä½ç½®è¿›è¡ŒåŒçº¿æ€§æ’å€¼
            for n in range(N):
                x_pos, y_pos = target_positions[b, n]  # [0, 1]èŒƒå›´
                
                # è½¬æ¢åˆ°å›¾åƒåæ ‡
                x_img = x_pos * (W - 1)
                y_img = y_pos * (H - 1)
                
                # åŒçº¿æ€§æ’å€¼çš„å››ä¸ªé‚»è¿‘ç‚¹
                x0, x1 = int(x_img), min(int(x_img) + 1, W - 1)
                y0, y1 = int(y_img), min(int(y_img) + 1, H - 1)
                
                # æ’å€¼æƒé‡
                wx = x_img - x0
                wy = y_img - y0
                
                # åŒçº¿æ€§æ’å€¼è®¡ç®—
                # gene_expression[b, n] = âˆ‘(weight * spatial_gene_image[b, :, yi, xi])
                gene_expression[b, n] = (
                    (1 - wy) * (1 - wx) * spatial_gene_image[b, :, y0, x0] +
                    (1 - wy) * wx * spatial_gene_image[b, :, y0, x1] +
                    wy * (1 - wx) * spatial_gene_image[b, :, y1, x0] +
                    wy * wx * spatial_gene_image[b, :, y1, x1]
                )
        
        return gene_expression
    
    def generate_default_positions(self, B: int, N: int, device: torch.device) -> torch.Tensor:
        """
        ç”Ÿæˆé»˜è®¤çš„è§„åˆ™ç½‘æ ¼ä½ç½®
        
        å½“è¾“å…¥æ•°æ®æ²¡æœ‰æä¾›ç©ºé—´ä½ç½®ä¿¡æ¯æ—¶ï¼Œç”Ÿæˆè§„åˆ™çš„ç½‘æ ¼ä½ç½®ã€‚
        è¿™ç¡®ä¿äº†æ¨¡å‹å³ä½¿åœ¨æ²¡æœ‰çœŸå®ç©ºé—´ä¿¡æ¯çš„æƒ…å†µä¸‹ä¹Ÿèƒ½æ­£å¸¸å·¥ä½œã€‚
        
        Args:
            B: Batch size
            N: Number of spots
            device: Target device
        
        Returns:
            positions: [B, N, 2] - è§„åˆ™ç½‘æ ¼ä½ç½®ï¼ŒèŒƒå›´[0,1]
        """
        # ç”ŸæˆâˆšN Ã— âˆšNçš„è§„åˆ™ç½‘æ ¼
        side_length = int(np.ceil(np.sqrt(N)))
        positions = []
        
        for i in range(N):
            row = i // side_length
            col = i % side_length
            # å½’ä¸€åŒ–åˆ°[0,1]ï¼Œå¹¶æ·»åŠ å°åç§»é¿å…è¾¹ç•Œé—®é¢˜
            x = (col + 0.5) / side_length
            y = (row + 0.5) / side_length
            positions.append([x, y])
        
        positions = torch.tensor(positions, device=device, dtype=torch.float32)
        return positions.unsqueeze(0).expand(B, -1, -1)
    
    def visualize_spatial_mapping(
        self, 
        gene_expression: torch.Tensor, 
        positions: torch.Tensor, 
        gene_idx: int = 0
    ) -> dict:
        """
        å¯è§†åŒ–ç©ºé—´æ˜ å°„è¿‡ç¨‹ï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰
        
        Args:
            gene_expression: [B, N, num_genes] - spotsåŸºå› è¡¨è¾¾
            positions: [B, N, 2] - spotsä½ç½®
            gene_idx: è¦å¯è§†åŒ–çš„åŸºå› ç´¢å¼•
        
        Returns:
            dict: åŒ…å«å¯è§†åŒ–ä¿¡æ¯çš„å­—å…¸
        """
        spatial_gene_image, spatial_mask = self.spots_to_spatial_gene_image(gene_expression, positions)
        reconstructed_expr = self.spatial_gene_image_to_spots(spatial_gene_image, positions)
        
        # è®¡ç®—é‡å»ºè¯¯å·®
        reconstruction_error = torch.mean(torch.abs(gene_expression - reconstructed_expr))
        
        return {
            'original_spots': gene_expression[0, :, gene_idx].cpu().numpy(),
            'spatial_image': spatial_gene_image[0, gene_idx].cpu().numpy(),
            'reconstructed_spots': reconstructed_expr[0, :, gene_idx].cpu().numpy(),
            'reconstruction_error': reconstruction_error.item(),
            'spatial_mask': spatial_mask[0, 0].cpu().numpy()
        }