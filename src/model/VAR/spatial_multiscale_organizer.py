"""
ç©ºé—´å¤šå°ºåº¦åŸºå› è¡¨è¾¾ç»„ç»‡å™¨

å®ç°VARåŸå§‹è®¾è®¡ç†å¿µçš„ç©ºé—´å¤šå°ºåº¦æ¦‚å¿µï¼š
- å°†ç©ºé—´è½¬å½•ç»„å­¦æ•°æ®ç»„ç»‡ä¸ºä¸åŒåˆ†è¾¨ç‡çš„ç©ºé—´ç½‘æ ¼
- æ¯ä¸ªç½‘æ ¼cellèšåˆå…¶å†…éƒ¨spotsçš„åŸºå› è¡¨è¾¾
- æ”¯æŒä»ç²—ç²’åº¦åˆ°ç»†ç²’åº¦çš„æ¸è¿›å¼ç”Ÿæˆ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Tuple, Dict, Optional
from scipy.spatial.distance import cdist


class SpatialMultiscaleOrganizer:
    """
    ç©ºé—´å¤šå°ºåº¦åŸºå› è¡¨è¾¾ç»„ç»‡å™¨
    
    å°†spotsçš„åæ ‡å’ŒåŸºå› è¡¨è¾¾ç»„ç»‡ä¸ºå¤šä¸ªç©ºé—´åˆ†è¾¨ç‡çš„ç½‘æ ¼è¡¨ç¤ºï¼Œ
    æ¯ä¸ªç½‘æ ¼cellåŒ…å«èšåˆçš„åŸºå› è¡¨è¾¾å‘é‡ã€‚
    """
    
    def __init__(
        self,
        scales: List[int] = [1, 2, 4, 8],
        aggregation_method: str = 'mean',
        spatial_smoothing: bool = True,
        normalize_coordinates: bool = True
    ):
        """
        åˆå§‹åŒ–ç©ºé—´å¤šå°ºåº¦ç»„ç»‡å™¨
        
        Args:
            scales: ç©ºé—´åˆ†è¾¨ç‡åˆ—è¡¨ [1, 2, 4, 8] è¡¨ç¤º 1Ã—1, 2Ã—2, 4Ã—4, 8Ã—8 ç½‘æ ¼
            aggregation_method: èšåˆæ–¹æ³• ('mean', 'sum', 'max', 'weighted_mean')
            spatial_smoothing: æ˜¯å¦åº”ç”¨ç©ºé—´å¹³æ»‘
            normalize_coordinates: æ˜¯å¦æ ‡å‡†åŒ–åæ ‡åˆ°[0,1]èŒƒå›´
        """
        self.scales = scales
        self.aggregation_method = aggregation_method
        self.spatial_smoothing = spatial_smoothing
        self.normalize_coordinates = normalize_coordinates
        
        print(f"ğŸ—‚ï¸ åˆå§‹åŒ–ç©ºé—´å¤šå°ºåº¦ç»„ç»‡å™¨:")
        print(f"   - åˆ†è¾¨ç‡å±‚çº§: {scales}")
        print(f"   - èšåˆæ–¹æ³•: {aggregation_method}")
        print(f"   - ç©ºé—´å¹³æ»‘: {spatial_smoothing}")
        print(f"   - åæ ‡æ ‡å‡†åŒ–: {normalize_coordinates}")
    
    def organize_multiscale(
        self,
        gene_expression: torch.Tensor,
        positions: torch.Tensor
    ) -> List[torch.Tensor]:
        """
        å°†spotsç»„ç»‡ä¸ºå¤šå°ºåº¦ç©ºé—´ç½‘æ ¼
        
        Args:
            gene_expression: [B, N, num_genes] - spotsçš„åŸºå› è¡¨è¾¾
            positions: [B, N, 2] - spotsçš„ç©ºé—´åæ ‡ (x, y)
        
        Returns:
            List[torch.Tensor]: æ¯ä¸ªå°ºåº¦çš„ç½‘æ ¼è¡¨ç¤º
            - scale 1Ã—1: [B, 1, num_genes]
            - scale 2Ã—2: [B, 4, num_genes] 
            - scale 4Ã—4: [B, 16, num_genes]
            - scale 8Ã—8: [B, 64, num_genes]
        """
        B, N, num_genes = gene_expression.shape
        device = gene_expression.device
        
        print(f"ğŸ—‚ï¸ ç»„ç»‡å¤šå°ºåº¦ç©ºé—´æ•°æ®:")
        print(f"   - è¾“å…¥: {gene_expression.shape} åŸºå› è¡¨è¾¾, {positions.shape} ä½ç½®")
        
        multiscale_expressions = []
        
        for scale_idx, scale in enumerate(self.scales):
            print(f"   - å¤„ç†å°ºåº¦ {scale}Ã—{scale}...")
            
            # ä¸ºæ¯ä¸ªbatchæ ·æœ¬å¤„ç†
            batch_scale_expressions = []
            
            for b in range(B):
                batch_gene_expr = gene_expression[b]  # [N, num_genes]
                batch_positions = positions[b]        # [N, 2]
                
                # ç»„ç»‡ä¸ºå½“å‰å°ºåº¦çš„ç½‘æ ¼
                grid_expression = self._organize_single_scale(
                    batch_gene_expr, batch_positions, scale
                )  # [scale*scale, num_genes]
                
                batch_scale_expressions.append(grid_expression)
            
            # åˆå¹¶batchç»´åº¦
            scale_expressions = torch.stack(batch_scale_expressions, dim=0)  # [B, scale*scale, num_genes]
            multiscale_expressions.append(scale_expressions)
            
            print(f"     -> è¾“å‡º: {scale_expressions.shape}")
        
        print(f"âœ… å¤šå°ºåº¦ç»„ç»‡å®Œæˆï¼Œå…±{len(multiscale_expressions)}ä¸ªå°ºåº¦")
        return multiscale_expressions
    
    def _organize_single_scale(
        self,
        gene_expression: torch.Tensor,
        positions: torch.Tensor,
        scale: int
    ) -> torch.Tensor:
        """
        å°†å•ä¸ªæ ·æœ¬ç»„ç»‡ä¸ºæŒ‡å®šå°ºåº¦çš„ç½‘æ ¼
        
        Args:
            gene_expression: [N, num_genes] - spotsåŸºå› è¡¨è¾¾
            positions: [N, 2] - spotsç©ºé—´åæ ‡
            scale: ç½‘æ ¼åˆ†è¾¨ç‡ (scaleÃ—scale)
        
        Returns:
            torch.Tensor: [scale*scale, num_genes] - ç½‘æ ¼åŒ–çš„åŸºå› è¡¨è¾¾
        """
        N, num_genes = gene_expression.shape
        device = gene_expression.device
        
        # æ ‡å‡†åŒ–åæ ‡åˆ°[0, 1]èŒƒå›´
        if self.normalize_coordinates:
            positions_norm = self._normalize_positions(positions)
        else:
            positions_norm = positions
        
        # åˆ›å»ºç½‘æ ¼
        grid_coords = self._create_grid_coordinates(scale, device)  # [scale*scale, 2]
        
        # ä¸ºæ¯ä¸ªç½‘æ ¼cellèšåˆåŸºå› è¡¨è¾¾
        grid_expressions = []
        
        for grid_idx in range(scale * scale):
            grid_center = grid_coords[grid_idx]  # [2]
            
            # è®¡ç®—æ¯ä¸ªspotåˆ°å½“å‰grid centerçš„è·ç¦»æƒé‡
            distances = torch.norm(positions_norm - grid_center.unsqueeze(0), dim=1)  # [N]
            
            # ä½¿ç”¨è·ç¦»æƒé‡èšåˆåŸºå› è¡¨è¾¾
            if self.aggregation_method == 'mean':
                # ç®€å•å¹³å‡ (åœ¨ç½‘æ ¼cellå†…çš„spots)
                cell_size = 1.0 / scale
                in_cell_mask = (
                    (torch.abs(positions_norm[:, 0] - grid_center[0]) < cell_size / 2) &
                    (torch.abs(positions_norm[:, 1] - grid_center[1]) < cell_size / 2)
                )
                
                if in_cell_mask.sum() > 0:
                    cell_expression = gene_expression[in_cell_mask].mean(dim=0)
                else:
                    # å¦‚æœcellå†…æ²¡æœ‰spotsï¼Œä½¿ç”¨æœ€è¿‘é‚»
                    nearest_idx = distances.argmin()
                    cell_expression = gene_expression[nearest_idx]
                    
            elif self.aggregation_method == 'weighted_mean':
                # é«˜æ–¯æƒé‡èšåˆ
                sigma = 1.0 / (scale * 2)  # è‡ªé€‚åº”æ ‡å‡†å·®
                weights = torch.exp(-distances**2 / (2 * sigma**2))
                weights = weights / (weights.sum() + 1e-8)  # å½’ä¸€åŒ–æƒé‡
                
                cell_expression = torch.sum(
                    weights.unsqueeze(1) * gene_expression, dim=0
                )  # [num_genes]
                
            elif self.aggregation_method == 'sum':
                # åŒºåŸŸå†…æ±‚å’Œ
                cell_size = 1.0 / scale
                in_cell_mask = (
                    (torch.abs(positions_norm[:, 0] - grid_center[0]) < cell_size / 2) &
                    (torch.abs(positions_norm[:, 1] - grid_center[1]) < cell_size / 2)
                )
                
                if in_cell_mask.sum() > 0:
                    cell_expression = gene_expression[in_cell_mask].sum(dim=0)
                else:
                    nearest_idx = distances.argmin()
                    cell_expression = gene_expression[nearest_idx]
                    
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„èšåˆæ–¹æ³•: {self.aggregation_method}")
            
            grid_expressions.append(cell_expression)
        
        # åˆå¹¶æ‰€æœ‰grid cells
        grid_result = torch.stack(grid_expressions, dim=0)  # [scale*scale, num_genes]
        
        # å¯é€‰çš„ç©ºé—´å¹³æ»‘
        if self.spatial_smoothing and scale > 1:
            grid_result = self._apply_spatial_smoothing(grid_result, scale)
        
        return grid_result
    
    def _normalize_positions(self, positions: torch.Tensor) -> torch.Tensor:
        """æ ‡å‡†åŒ–åæ ‡åˆ°[0, 1]èŒƒå›´"""
        pos_min = positions.min(dim=0, keepdim=True)[0]
        pos_max = positions.max(dim=0, keepdim=True)[0]
        pos_range = pos_max - pos_min
        
        # é¿å…é™¤é›¶
        pos_range = torch.where(pos_range > 1e-8, pos_range, torch.ones_like(pos_range))
        
        normalized = (positions - pos_min) / pos_range
        return normalized
    
    def _create_grid_coordinates(self, scale: int, device: torch.device) -> torch.Tensor:
        """åˆ›å»ºç½‘æ ¼ä¸­å¿ƒåæ ‡"""
        # åˆ›å»ºå‡åŒ€åˆ†å¸ƒçš„ç½‘æ ¼ä¸­å¿ƒç‚¹
        step = 1.0 / scale
        coords = torch.linspace(step/2, 1-step/2, scale, device=device)
        
        # åˆ›å»ºç½‘æ ¼åæ ‡ [scale*scale, 2]
        grid_x, grid_y = torch.meshgrid(coords, coords, indexing='ij')
        grid_coords = torch.stack([grid_x.flatten(), grid_y.flatten()], dim=1)
        
        return grid_coords
    
    def _apply_spatial_smoothing(self, grid_expression: torch.Tensor, scale: int) -> torch.Tensor:
        """å¯¹ç½‘æ ¼åº”ç”¨ç©ºé—´å¹³æ»‘"""
        # é‡å¡‘ä¸ºç©ºé—´ç½‘æ ¼ [scale, scale, num_genes]
        num_genes = grid_expression.shape[1]
        spatial_grid = grid_expression.view(scale, scale, num_genes)
        
        # åº”ç”¨2Dé«˜æ–¯æ»¤æ³¢è¿›è¡Œå¹³æ»‘
        # è½¬ç½®ä¸º [num_genes, scale, scale] ä»¥ä¾¿æ‰¹é‡å¤„ç†
        spatial_grid = spatial_grid.permute(2, 0, 1).unsqueeze(0)  # [1, num_genes, scale, scale]
        
        # åˆ›å»ºé«˜æ–¯æ ¸
        kernel_size = 3 if scale >= 4 else 1
        if kernel_size > 1:
            smoothed = F.avg_pool2d(
                spatial_grid, 
                kernel_size=kernel_size, 
                stride=1, 
                padding=kernel_size//2
            )
            smoothed = smoothed.squeeze(0).permute(1, 2, 0)  # [scale, scale, num_genes]
            smoothed = smoothed.view(-1, num_genes)  # [scale*scale, num_genes]
        else:
            smoothed = grid_expression
        
        return smoothed
    
    def reconstruct_from_multiscale(
        self, 
        multiscale_expressions: List[torch.Tensor],
        target_positions: torch.Tensor,
        reconstruction_method: str = 'finest_scale'
    ) -> torch.Tensor:
        """
        ä»å¤šå°ºåº¦è¡¨ç¤ºé‡å»ºåŸå§‹spotsçš„åŸºå› è¡¨è¾¾
        
        Args:
            multiscale_expressions: å¤šå°ºåº¦åŸºå› è¡¨è¾¾åˆ—è¡¨
            target_positions: [B, N, 2] - ç›®æ ‡spotsçš„ä½ç½®
            reconstruction_method: é‡å»ºæ–¹æ³• ('finest_scale', 'hierarchical', 'weighted_combination')
        
        Returns:
            torch.Tensor: [B, N, num_genes] - é‡å»ºçš„åŸºå› è¡¨è¾¾
        """
        B, N, _ = target_positions.shape
        num_genes = multiscale_expressions[0].shape[-1]
        device = target_positions.device
        
        print(f"ğŸ”„ ä»å¤šå°ºåº¦é‡å»ºåŸºå› è¡¨è¾¾:")
        print(f"   - ç›®æ ‡ä½ç½®: {target_positions.shape}")
        print(f"   - é‡å»ºæ–¹æ³•: {reconstruction_method}")
        
        if reconstruction_method == 'finest_scale':
            # ä½¿ç”¨æœ€ç»†å°ºåº¦è¿›è¡Œæ’å€¼é‡å»º
            finest_scale_expr = multiscale_expressions[-1]  # [B, scale*scale, num_genes]
            finest_scale = self.scales[-1]
            
            reconstructed = self._interpolate_from_grid(
                finest_scale_expr, target_positions, finest_scale
            )
            
        elif reconstruction_method == 'hierarchical':
            # åˆ†å±‚é‡å»ºï¼šä»ç²—åˆ°ç»†é€æ­¥ç»†åŒ–
            reconstructed = None
            
            for scale_idx, scale_expr in enumerate(multiscale_expressions):
                scale = self.scales[scale_idx]
                
                scale_contribution = self._interpolate_from_grid(
                    scale_expr, target_positions, scale
                )
                
                if reconstructed is None:
                    reconstructed = scale_contribution
                else:
                    # åŠ æƒèåˆ
                    weight = 0.5 ** (len(multiscale_expressions) - scale_idx - 1)
                    reconstructed = reconstructed * (1 - weight) + scale_contribution * weight
                    
        elif reconstruction_method == 'weighted_combination':
            # åŠ æƒç»„åˆæ‰€æœ‰å°ºåº¦
            all_contributions = []
            weights = []
            
            for scale_idx, scale_expr in enumerate(multiscale_expressions):
                scale = self.scales[scale_idx]
                contribution = self._interpolate_from_grid(
                    scale_expr, target_positions, scale
                )
                all_contributions.append(contribution)
                
                # æ›´ç»†çš„å°ºåº¦æœ‰æ›´é«˜æƒé‡
                weight = (scale_idx + 1) / len(multiscale_expressions)
                weights.append(weight)
            
            # æ ‡å‡†åŒ–æƒé‡
            weights = torch.tensor(weights, device=device)
            weights = weights / weights.sum()
            
            # åŠ æƒç»„åˆ
            reconstructed = torch.zeros_like(all_contributions[0])
            for contrib, weight in zip(all_contributions, weights):
                reconstructed += contrib * weight
                
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é‡å»ºæ–¹æ³•: {reconstruction_method}")
        
        print(f"   - é‡å»ºç»“æœ: {reconstructed.shape}")
        return reconstructed
    
    def _interpolate_from_grid(
        self,
        grid_expression: torch.Tensor,
        target_positions: torch.Tensor,
        scale: int
    ) -> torch.Tensor:
        """
        ä»ç½‘æ ¼æ’å€¼åˆ°ç›®æ ‡ä½ç½®
        
        Args:
            grid_expression: [B, scale*scale, num_genes] - ç½‘æ ¼åŸºå› è¡¨è¾¾
            target_positions: [B, N, 2] - ç›®æ ‡ä½ç½®
            scale: ç½‘æ ¼åˆ†è¾¨ç‡
        
        Returns:
            torch.Tensor: [B, N, num_genes] - æ’å€¼åçš„åŸºå› è¡¨è¾¾
        """
        B, N, _ = target_positions.shape
        num_genes = grid_expression.shape[-1]
        device = target_positions.device
        
        # åˆ›å»ºç½‘æ ¼åæ ‡
        grid_coords = self._create_grid_coordinates(scale, device)  # [scale*scale, 2]
        
        interpolated_expressions = []
        
        for b in range(B):
            batch_grid_expr = grid_expression[b]      # [scale*scale, num_genes]
            batch_target_pos = target_positions[b]    # [N, 2]
            
            # æ ‡å‡†åŒ–ç›®æ ‡ä½ç½®
            if self.normalize_coordinates:
                batch_target_pos_norm = self._normalize_positions(batch_target_pos)
            else:
                batch_target_pos_norm = batch_target_pos
            
            # è®¡ç®—è·ç¦»æƒé‡è¿›è¡Œæ’å€¼
            distances = torch.cdist(batch_target_pos_norm, grid_coords)  # [N, scale*scale]
            
            # ä½¿ç”¨åè·ç¦»æƒé‡æ’å€¼
            eps = 1e-8
            weights = 1.0 / (distances + eps)  # [N, scale*scale]
            weights = weights / weights.sum(dim=1, keepdim=True)  # å½’ä¸€åŒ–
            
            # åŠ æƒå¹³å‡
            interpolated = torch.mm(weights, batch_grid_expr)  # [N, num_genes]
            interpolated_expressions.append(interpolated)
        
        result = torch.stack(interpolated_expressions, dim=0)  # [B, N, num_genes]
        return result 