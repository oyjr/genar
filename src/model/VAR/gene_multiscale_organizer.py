"""
åŸºå› å¤šå°ºåº¦ç»„ç»‡å™¨

å®ç°VARåŸå§‹è®¾è®¡ç†å¿µçš„åŸºå› ç»´åº¦å¤šå°ºåº¦æ¦‚å¿µï¼š
- å°†åŸºå› è¡¨è¾¾å‘é‡ç»„ç»‡ä¸ºä¸åŒç²’åº¦çš„è¡¨ç¤º
- æ¯ä¸ªå°ºåº¦åŒ…å«ä¸åŒæ•°é‡çš„åŸºå› ç‰¹å¾
- æ”¯æŒä»ç²—ç²’åº¦åˆ°ç»†ç²’åº¦çš„æ¸è¿›å¼ç”Ÿæˆ

è¿™æ˜¯VARæ¶æ„çš„æ ¸å¿ƒï¼šå¤šå°ºåº¦è‡ªå›å½’å»ºæ¨¡ï¼Œåªæ˜¯åº”ç”¨åœ¨åŸºå› ç»´åº¦è€Œä¸æ˜¯ç©ºé—´ç»´åº¦
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Tuple, Dict, Optional, Any


class GeneMultiscaleOrganizer(nn.Module):
    """
    åŸºå› å¤šå°ºåº¦ç»„ç»‡å™¨
    
    å°†åŸºå› è¡¨è¾¾å‘é‡ç»„ç»‡ä¸ºå¤šä¸ªå°ºåº¦çš„è¡¨ç¤ºï¼Œ
    æ¯ä¸ªå°ºåº¦åŒ…å«ä¸åŒç²’åº¦çš„åŸºå› ä¿¡æ¯ã€‚
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    - å°ºåº¦1: 1ä¸ªç‰¹å¾ (å…¨å±€åŸºå› è¡¨è¾¾æ¨¡å¼)
    - å°ºåº¦2: 4ä¸ªç‰¹å¾ (ä¸»è¦åŠŸèƒ½æ¨¡å—)  
    - å°ºåº¦3: 16ä¸ªç‰¹å¾ (åŠŸèƒ½é€šè·¯çº§åˆ«)
    - å°ºåº¦4: 64ä¸ªç‰¹å¾ (åŸºå› ç°‡çº§åˆ«)
    - å°ºåº¦5: 200ä¸ªç‰¹å¾ (å®Œæ•´åŸºå› è¡¨è¾¾)
    
    è¿™ä¸VARåœ¨å›¾åƒä¸Šçš„1Ã—1â†’2Ã—2â†’4Ã—4â†’8Ã—8â†’16Ã—16å®Œå…¨å¯¹åº”
    """
    
    def __init__(
        self,
        num_genes: int = 200,
        scales: List[int] = [1, 4, 16, 64, 200],
        projection_method: str = 'learned',
        preserve_variance: bool = True,
        normalize_features: bool = True
    ):
        """
        åˆå§‹åŒ–åŸºå› å¤šå°ºåº¦ç»„ç»‡å™¨
        
        Args:
            num_genes: æ€»åŸºå› æ•°é‡
            scales: å¤šå°ºåº¦ç‰¹å¾æ•°é‡åˆ—è¡¨ [1, 4, 16, 64, 200]
            projection_method: æŠ•å½±æ–¹æ³• ('learned', 'pca', 'importance')
            preserve_variance: æ˜¯å¦ä¿æŒæ–¹å·®ä¿¡æ¯
            normalize_features: æ˜¯å¦æ ‡å‡†åŒ–ç‰¹å¾
        """
        super().__init__()  # ç»§æ‰¿nn.Module
        
        self.num_genes = num_genes
        self.scales = scales
        self.projection_method = projection_method
        self.preserve_variance = preserve_variance
        self.normalize_features = normalize_features
        
        print(f"ğŸ§¬ åˆå§‹åŒ–åŸºå› å¤šå°ºåº¦ç»„ç»‡å™¨:")
        print(f"   - åŸºå› æ•°é‡: {num_genes}")
        print(f"   - å°ºåº¦å±‚çº§: {scales}")
        print(f"   - æŠ•å½±æ–¹æ³•: {projection_method}")
        print(f"   - ä¿æŒæ–¹å·®: {preserve_variance}")
        
        # éªŒè¯å°ºåº¦è®¾ç½®
        assert scales[-1] == num_genes, f"æœ€åä¸€ä¸ªå°ºåº¦å¿…é¡»ç­‰äºåŸºå› æ•°é‡: {scales[-1]} != {num_genes}"
        assert all(scales[i] <= scales[i+1] for i in range(len(scales)-1)), "å°ºåº¦å¿…é¡»é€’å¢"
        
        # åˆå§‹åŒ–æŠ•å½±å±‚ï¼ˆå¦‚æœä½¿ç”¨å­¦ä¹ æŠ•å½±ï¼‰
        if projection_method == 'learned':
            self.projection_layers = nn.ModuleList()
            for scale in scales[:-1]:  # æœ€åä¸€ä¸ªå°ºåº¦å°±æ˜¯åŸå§‹æ•°æ®
                self.projection_layers.append(
                    nn.Linear(num_genes, scale, bias=False)
                )
            
            # åˆå§‹åŒ–æŠ•å½±çŸ©é˜µ
            self._initialize_projections()
        
        # å­˜å‚¨é‡å»ºå±‚ï¼ˆç”¨äºéªŒè¯ä¿¡æ¯ä¿æŒï¼‰
        if preserve_variance:
            self.reconstruction_layers = nn.ModuleList()
            for scale in scales[:-1]:
                self.reconstruction_layers.append(
                    nn.Linear(scale, num_genes, bias=False)
                )
    
    def _initialize_projections(self):
        """åˆå§‹åŒ–æŠ•å½±çŸ©é˜µä»¥ä¿æŒé‡è¦ä¿¡æ¯"""
        print("ğŸ”§ åˆå§‹åŒ–åŸºå› æŠ•å½±çŸ©é˜µ...")
        
        for i, proj_layer in enumerate(self.projection_layers):
            # ä½¿ç”¨æ­£äº¤åˆå§‹åŒ–ä¿æŒä¿¡æ¯
            nn.init.orthogonal_(proj_layer.weight)
            
            # ç¼©æ”¾æƒé‡ä»¥ä¿æŒæ–¹å·®
            scale_factor = np.sqrt(self.scales[i] / self.num_genes)
            proj_layer.weight.data *= scale_factor
            
            print(f"   - å°ºåº¦{i+1}: {self.num_genes} â†’ {self.scales[i]} (æ­£äº¤æŠ•å½±)")
    
    def organize_multiscale(
        self,
        gene_expression: torch.Tensor
    ) -> List[torch.Tensor]:
        """
        å°†åŸºå› è¡¨è¾¾å‘é‡ç»„ç»‡ä¸ºå¤šå°ºåº¦è¡¨ç¤º
        
        Args:
            gene_expression: [B, num_genes] - åŸºå› è¡¨è¾¾å‘é‡
        
        Returns:
            List[torch.Tensor]: å¤šå°ºåº¦åŸºå› è¡¨è¾¾
            - scale_0: [B, 1] - å…¨å±€æ¨¡å¼
            - scale_1: [B, 4] - ä¸»è¦æ¨¡å—  
            - scale_2: [B, 16] - åŠŸèƒ½é€šè·¯
            - scale_3: [B, 64] - åŸºå› ç°‡
            - scale_4: [B, 200] - å®Œæ•´è¡¨è¾¾
        """
        B, num_genes = gene_expression.shape
        device = gene_expression.device
        
        if num_genes != self.num_genes:
            raise ValueError(f"è¾“å…¥åŸºå› æ•°é‡ {num_genes} ä¸é…ç½®ä¸ç¬¦ {self.num_genes}")
        
        print(f"ğŸ§¬ ç»„ç»‡åŸºå› å¤šå°ºåº¦è¡¨ç¤º:")
        print(f"   - è¾“å…¥: {gene_expression.shape}")
        
        # å¯é€‰çš„ç‰¹å¾æ ‡å‡†åŒ–
        if self.normalize_features:
            gene_expression_norm = F.layer_norm(gene_expression, [num_genes])
        else:
            gene_expression_norm = gene_expression
        
        multiscale_expressions = []
        
        # ç”Ÿæˆæ¯ä¸ªå°ºåº¦çš„è¡¨ç¤º
        for scale_idx, scale in enumerate(self.scales):
            if scale == self.num_genes:
                # æœ€åä¸€ä¸ªå°ºåº¦ï¼šä½¿ç”¨åŸå§‹æ•°æ®
                scale_expression = gene_expression_norm
                print(f"   - å°ºåº¦{scale_idx+1}: {scale_expression.shape} (åŸå§‹)")
                
            else:
                # å…¶ä»–å°ºåº¦ï¼šä½¿ç”¨æŠ•å½±
                if self.projection_method == 'learned':
                    proj_layer = self.projection_layers[scale_idx]
                    scale_expression = proj_layer(gene_expression_norm)  # [B, scale]
                    
                elif self.projection_method == 'pca':
                    scale_expression = self._pca_projection(gene_expression_norm, scale)
                    
                elif self.projection_method == 'importance':
                    scale_expression = self._importance_projection(gene_expression_norm, scale)
                    
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æŠ•å½±æ–¹æ³•: {self.projection_method}")
                
                print(f"   - å°ºåº¦{scale_idx+1}: {scale_expression.shape} (æŠ•å½±)")
            
            # ç¡®ä¿å¼ é‡è¿ç»­æ€§
            scale_expression = scale_expression.contiguous()
            multiscale_expressions.append(scale_expression)
        
        print(f"âœ… åŸºå› å¤šå°ºåº¦ç»„ç»‡å®Œæˆï¼Œå…±{len(multiscale_expressions)}ä¸ªå°ºåº¦")
        return multiscale_expressions
    
    def _pca_projection(self, gene_expression: torch.Tensor, target_dim: int) -> torch.Tensor:
        """ä½¿ç”¨PCAè¿›è¡Œé™ç»´æŠ•å½±"""
        # ç®€åŒ–çš„PCAæŠ•å½±ï¼ˆå®é™…ä½¿ç”¨ä¸­å¯ä»¥é¢„è®¡ç®—ä¸»æˆåˆ†ï¼‰
        B, num_genes = gene_expression.shape
        
        # è®¡ç®—åæ–¹å·®çŸ©é˜µçš„ä¸»æˆåˆ†ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        centered = gene_expression - gene_expression.mean(dim=0, keepdim=True)
        
        # SVDåˆ†è§£
        U, S, V = torch.svd(centered.t())  # è½¬ç½®åè¿›è¡ŒSVD
        
        # å–å‰target_dimä¸ªä¸»æˆåˆ†
        principal_components = V[:, :target_dim]  # [num_genes, target_dim]
        
        # æŠ•å½±
        projected = torch.mm(gene_expression, principal_components)  # [B, target_dim]
        
        return projected
    
    def _importance_projection(self, gene_expression: torch.Tensor, target_dim: int) -> torch.Tensor:
        """åŸºäºåŸºå› é‡è¦æ€§çš„æŠ•å½±"""
        B, num_genes = gene_expression.shape
        
        # è®¡ç®—åŸºå› çš„é‡è¦æ€§åˆ†æ•°ï¼ˆæ–¹å·®ä½œä¸ºç®€å•çš„é‡è¦æ€§åº¦é‡ï¼‰
        gene_variance = gene_expression.var(dim=0)  # [num_genes]
        
        # é€‰æ‹©æ–¹å·®æœ€å¤§çš„åŸºå› 
        _, top_indices = torch.topk(gene_variance, target_dim)
        
        # æŠ•å½±åˆ°é‡è¦åŸºå› å­ç©ºé—´
        projected = gene_expression[:, top_indices]  # [B, target_dim]
        
        return projected
    
    def reconstruct_from_multiscale(
        self, 
        multiscale_expressions: List[torch.Tensor],
        reconstruction_method: str = 'finest_scale'
    ) -> torch.Tensor:
        """
        ä»å¤šå°ºåº¦è¡¨ç¤ºé‡å»ºå®Œæ•´çš„åŸºå› è¡¨è¾¾
        
        Args:
            multiscale_expressions: å¤šå°ºåº¦åŸºå› è¡¨è¾¾åˆ—è¡¨
            reconstruction_method: é‡å»ºæ–¹æ³•
                - 'finest_scale': ç›´æ¥ä½¿ç”¨æœ€ç»†ç²’åº¦å°ºåº¦
                - 'learned_combination': å­¦ä¹ å¤šå°ºåº¦ç»„åˆ
                - 'progressive': æ¸è¿›å¼é‡å»º
        
        Returns:
            torch.Tensor: [B, num_genes] - é‡å»ºçš„åŸºå› è¡¨è¾¾
        """
        if reconstruction_method == 'finest_scale':
            # æœ€ç®€å•ï¼šç›´æ¥è¿”å›æœ€åä¸€ä¸ªå°ºåº¦ï¼ˆå®Œæ•´åŸºå› è¡¨è¾¾ï¼‰
            return multiscale_expressions[-1]
        
        elif reconstruction_method == 'learned_combination':
            # ä½¿ç”¨å­¦ä¹ åˆ°çš„é‡å»ºå±‚ç»„åˆå¤šå°ºåº¦ä¿¡æ¯
            B = multiscale_expressions[0].shape[0]
            device = multiscale_expressions[0].device
            
            reconstructed = torch.zeros(B, self.num_genes, device=device)
            
            for scale_idx, scale_expr in enumerate(multiscale_expressions[:-1]):
                if hasattr(self, 'reconstruction_layers'):
                    recon_layer = self.reconstruction_layers[scale_idx]
                    scale_contribution = recon_layer(scale_expr)
                    reconstructed += scale_contribution
            
            # æ·»åŠ æœ€ç»†å°ºåº¦
            reconstructed += multiscale_expressions[-1]
            
            return reconstructed
        
        elif reconstruction_method == 'progressive':
            # æ¸è¿›å¼é‡å»ºï¼šä»ç²—ç²’åº¦å¼€å§‹é€æ­¥ç»†åŒ–
            current_reconstruction = multiscale_expressions[0]  # ä»æœ€ç²—å°ºåº¦å¼€å§‹
            
            for scale_idx in range(1, len(multiscale_expressions)):
                current_scale = multiscale_expressions[scale_idx]
                
                if current_scale.shape[1] == self.num_genes:
                    # æœ€åä¸€ä¸ªå°ºåº¦ï¼šç›´æ¥ä½¿ç”¨
                    current_reconstruction = current_scale
                else:
                    # ä¸­é—´å°ºåº¦ï¼šç»„åˆå½“å‰é‡å»ºå’Œæ–°å°ºåº¦ä¿¡æ¯
                    if hasattr(self, 'reconstruction_layers') and scale_idx-1 < len(self.reconstruction_layers):
                        recon_layer = self.reconstruction_layers[scale_idx-1]
                        upsampled = recon_layer(current_scale)
                        
                        # å¦‚æœç»´åº¦åŒ¹é…ï¼Œè¿›è¡Œæ®‹å·®è¿æ¥
                        if hasattr(current_reconstruction, 'shape') and current_reconstruction.shape[1] == upsampled.shape[1]:
                            current_reconstruction = current_reconstruction + upsampled
                        else:
                            current_reconstruction = upsampled
                    else:
                        # ç®€å•ç­–ç•¥ï¼šä½¿ç”¨å½“å‰å°ºåº¦
                        current_reconstruction = current_scale
            
            return current_reconstruction
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é‡å»ºæ–¹æ³•: {reconstruction_method}")
    
    def validate_information_preservation(
        self,
        original: torch.Tensor,
        multiscale: List[torch.Tensor],
        tolerance: float = 0.1
    ) -> Dict[str, float]:
        """
        éªŒè¯å¤šå°ºåº¦åˆ†è§£æ˜¯å¦ä¿æŒäº†é‡è¦ä¿¡æ¯
        
        Args:
            original: [B, num_genes] - åŸå§‹åŸºå› è¡¨è¾¾
            multiscale: å¤šå°ºåº¦è¡¨ç¤ºåˆ—è¡¨
            tolerance: å®¹å¿çš„ä¿¡æ¯æŸå¤±æ¯”ä¾‹
        
        Returns:
            Dict: éªŒè¯ç»“æœ
        """
        results = {}
        
        # é‡å»ºéªŒè¯
        reconstructed = self.reconstruct_from_multiscale(multiscale, 'finest_scale')
        
        # è®¡ç®—é‡å»ºè¯¯å·®
        mse_loss = F.mse_loss(reconstructed, original)
        relative_error = mse_loss / (original.var() + 1e-8)
        
        results['mse_loss'] = mse_loss.item()
        results['relative_error'] = relative_error.item()
        results['information_preserved'] = relative_error.item() < tolerance
        
        # æ¯ä¸ªå°ºåº¦çš„ä¿¡æ¯é‡
        for i, scale_expr in enumerate(multiscale):
            scale_variance = scale_expr.var()
            results[f'scale_{i+1}_variance'] = scale_variance.item()
        
        # ç›¸å…³æ€§éªŒè¯
        correlation = F.cosine_similarity(
            original.view(-1), 
            reconstructed.view(-1), 
            dim=0
        )
        results['cosine_similarity'] = correlation.item()
        
        print(f"ğŸ“Š ä¿¡æ¯ä¿æŒéªŒè¯:")
        print(f"   - MSEæŸå¤±: {results['mse_loss']:.6f}")
        print(f"   - ç›¸å¯¹è¯¯å·®: {results['relative_error']:.4f}")
        print(f"   - ä½™å¼¦ç›¸ä¼¼åº¦: {results['cosine_similarity']:.4f}")
        print(f"   - ä¿¡æ¯ä¿æŒ: {'âœ…' if results['information_preserved'] else 'âŒ'}")
        
        return results
    
    def get_scale_info(self) -> Dict[str, Any]:
        """è·å–å°ºåº¦é…ç½®ä¿¡æ¯"""
        return {
            'num_genes': self.num_genes,
            'scales': self.scales,
            'projection_method': self.projection_method,
            'num_scale_levels': len(self.scales),
            'scale_ratios': [s / self.num_genes for s in self.scales],
            'compression_ratios': [self.num_genes / s for s in self.scales]
        } 