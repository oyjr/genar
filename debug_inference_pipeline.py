#!/usr/bin/env python3
"""
è°ƒè¯•ä¸¤é˜¶æ®µVAR-STæ¨ç†ç®¡é“

æ£€æŸ¥æ¯ä¸ªæ­¥éª¤çš„è¾“å…¥è¾“å‡ºï¼Œæ‰¾å‡ºæŒ‡æ ‡å¼‚å¸¸çš„åŸå› ï¼š
1. æ£€æŸ¥æ¨¡å‹æƒé‡åŠ è½½
2. æ£€æŸ¥æ•°æ®é¢„å¤„ç†
3. æ£€æŸ¥Stage 2ç”Ÿæˆçš„tokens
4. æ£€æŸ¥Stage 1é‡å»ºçš„åŸºå› è¡¨è¾¾
5. æ£€æŸ¥æœ€ç»ˆé¢„æµ‹å€¼çš„åˆ†å¸ƒ
"""

import sys
import os
sys.path.insert(0, 'src')

import torch
import numpy as np
from two_stage_complete_inference import TwoStageCompleteInference
from main import DATASETS
from addict import Dict as AddictDict
from dataset.data_interface import DataInterface

def debug_inference_pipeline():
    """è°ƒè¯•å®Œæ•´çš„æ¨ç†ç®¡é“"""
    print("ğŸ” å¼€å§‹è°ƒè¯•ä¸¤é˜¶æ®µVAR-STæ¨ç†ç®¡é“")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–æ¨ç†å™¨
    stage1_ckpt = "logs/PRAD/TWO_STAGE_VAR_ST/stage1-best-epoch=epoch=143-val_mse=val_mse=0.5353.ckpt"
    stage2_ckpt = "logs/PRAD/TWO_STAGE_VAR_ST/stage2-best-epoch=epoch=03-val_acc=val_accuracy=0.8263.ckpt"
    
    inferencer = TwoStageCompleteInference(
        stage1_ckpt_path=stage1_ckpt,
        stage2_ckpt_path=stage2_ckpt,
        device='cuda'
    )
    
    # 2. åŠ è½½æ¨¡å‹
    model = inferencer.load_model()
    
    # 3. å‡†å¤‡ä¸€å°æ‰¹æ•°æ®
    print(f"\nğŸ“Š å‡†å¤‡è°ƒè¯•æ•°æ®...")
    dataset_info = DATASETS['PRAD']
    
    config = AddictDict({
        'data_path': dataset_info['path'],
        'slide_val': dataset_info['val_slides'],
        'slide_test': dataset_info['test_slides'],
        'encoder_name': dataset_info['recommended_encoder'],
        'use_augmented': False,
        'expand_augmented': False,
        'expr_name': 'PRAD',
        'MODEL': AddictDict({'model_name': 'TWO_STAGE_VAR_ST'}),
        'DATA': {
            'normalize': True,
            'test_dataloader': {
                'batch_size': 4,  # å°æ‰¹æ¬¡ç”¨äºè°ƒè¯•
                'num_workers': 0,
                'pin_memory': True,
                'shuffle': False,
                'persistent_workers': False
            }
        }
    })
    
    data_interface = DataInterface(config)
    data_interface.setup(stage='test')
    dataloader = data_interface.test_dataloader()
    
    # 4. è·å–ä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œè¯¦ç»†è°ƒè¯•
    batch = next(iter(dataloader))
    histology_features = batch['img'].cuda()      # [B, 1024]
    spatial_coords = batch['positions'].cuda()   # [B, 2]
    target_genes = batch['target_genes'].cuda()  # [B, 200]
    
    print(f"\nğŸ” è°ƒè¯•æ‰¹æ¬¡ä¿¡æ¯:")
    print(f"   æ‰¹æ¬¡å¤§å°: {histology_features.shape[0]}")
    print(f"   ç»„ç»‡å­¦ç‰¹å¾: {histology_features.shape}")
    print(f"   ç©ºé—´åæ ‡: {spatial_coords.shape}")
    print(f"   ç›®æ ‡åŸºå› : {target_genes.shape}")
    print(f"   ç›®æ ‡åŸºå› èŒƒå›´: [{target_genes.min().item():.4f}, {target_genes.max().item():.4f}]")
    print(f"   ç›®æ ‡åŸºå› å‡å€¼: {target_genes.mean().item():.4f}")
    print(f"   ç›®æ ‡åŸºå› æ ‡å‡†å·®: {target_genes.std().item():.4f}")
    
    # 5. é€æ­¥è°ƒè¯•æ¨ç†è¿‡ç¨‹
    print(f"\nğŸ”§ å¼€å§‹é€æ­¥è°ƒè¯•æ¨ç†è¿‡ç¨‹...")
    
    model.eval()
    with torch.no_grad():
        # Step 1: æ¡ä»¶å¤„ç†
        print(f"\n   æ­¥éª¤1: æ¡ä»¶å¤„ç†...")
        condition_embed = model.condition_processor(histology_features, spatial_coords)
        print(f"   æ¡ä»¶åµŒå…¥å½¢çŠ¶: {condition_embed.shape}")
        print(f"   æ¡ä»¶åµŒå…¥èŒƒå›´: [{condition_embed.min().item():.4f}, {condition_embed.max().item():.4f}]")
        print(f"   æ¡ä»¶åµŒå…¥å‡å€¼: {condition_embed.mean().item():.4f}")
        
        # Step 2: VARç”Ÿæˆtokens
        print(f"\n   æ­¥éª¤2: VARç”Ÿæˆtokens...")
        try:
            generated_tokens = model.stage2_var.generate(
                condition_embed=condition_embed,
                max_length=241,
                temperature=1.0,
                top_k=50,
                top_p=0.9
            )
            print(f"   ç”Ÿæˆtokenså½¢çŠ¶: {generated_tokens.shape}")
            print(f"   ç”ŸæˆtokensèŒƒå›´: [{generated_tokens.min().item()}, {generated_tokens.max().item()}]")
            print(f"   ç”Ÿæˆtokenså‰10ä¸ª: {generated_tokens[0, :10].cpu().tolist()}")
            
            # æ£€æŸ¥tokensåˆ†å¸ƒ
            unique_tokens, counts = torch.unique(generated_tokens, return_counts=True)
            print(f"   å”¯ä¸€tokensæ•°é‡: {len(unique_tokens)}/{model.stage2_var.vocab_size}")
            print(f"   æœ€å¸¸è§çš„5ä¸ªtokens: {unique_tokens[:5].cpu().tolist()}")
            
        except Exception as e:
            print(f"   âŒ VARç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
        
        # Step 3: é‡æ„å¤šå°ºåº¦tokens
        print(f"\n   æ­¥éª¤3: é‡æ„å¤šå°ºåº¦tokens...")
        tokens = {
            'global': generated_tokens[:, 0:1],         # [B, 1]
            'pathway': generated_tokens[:, 1:9],        # [B, 8]
            'module': generated_tokens[:, 9:41],        # [B, 32]
            'individual': generated_tokens[:, 41:241]   # [B, 200]
        }
        
        for scale, scale_tokens in tokens.items():
            print(f"   {scale} tokens: {scale_tokens.shape}, èŒƒå›´: [{scale_tokens.min().item()}, {scale_tokens.max().item()}]")
        
        # Step 4: VQVAEè§£ç 
        print(f"\n   æ­¥éª¤4: VQVAEè§£ç ...")
        try:
            decoded_output = model.stage1_vqvae.decode_from_tokens(tokens)
            predicted_gene_expression = decoded_output['final_reconstruction']
            
            print(f"   é¢„æµ‹åŸºå› è¡¨è¾¾å½¢çŠ¶: {predicted_gene_expression.shape}")
            print(f"   é¢„æµ‹åŸºå› è¡¨è¾¾èŒƒå›´: [{predicted_gene_expression.min().item():.4f}, {predicted_gene_expression.max().item():.4f}]")
            print(f"   é¢„æµ‹åŸºå› è¡¨è¾¾å‡å€¼: {predicted_gene_expression.mean().item():.4f}")
            print(f"   é¢„æµ‹åŸºå› è¡¨è¾¾æ ‡å‡†å·®: {predicted_gene_expression.std().item():.4f}")
            
        except Exception as e:
            print(f"   âŒ VQVAEè§£ç å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
        
        # Step 5: ä¸ç›®æ ‡å¯¹æ¯”
        print(f"\n   æ­¥éª¤5: é¢„æµ‹ä¸ç›®æ ‡å¯¹æ¯”...")
        
        pred_flat = predicted_gene_expression.view(-1).cpu().numpy()
        target_flat = target_genes.view(-1).cpu().numpy()
        
        print(f"   é¢„æµ‹ç»Ÿè®¡:")
        print(f"     å‡å€¼: {pred_flat.mean():.4f}")
        print(f"     æ ‡å‡†å·®: {pred_flat.std():.4f}")
        print(f"     æœ€å°å€¼: {pred_flat.min():.4f}")
        print(f"     æœ€å¤§å€¼: {pred_flat.max():.4f}")
        
        print(f"   ç›®æ ‡ç»Ÿè®¡:")
        print(f"     å‡å€¼: {target_flat.mean():.4f}")
        print(f"     æ ‡å‡†å·®: {target_flat.std():.4f}")
        print(f"     æœ€å°å€¼: {target_flat.min():.4f}")
        print(f"     æœ€å¤§å€¼: {target_flat.max():.4f}")
        
        # è®¡ç®—åŸºæœ¬æŒ‡æ ‡
        mse = np.mean((pred_flat - target_flat) ** 2)
        mae = np.mean(np.abs(pred_flat - target_flat))
        
        from scipy.stats import pearsonr
        pcc, _ = pearsonr(pred_flat, target_flat)
        
        print(f"   åŸºæœ¬æŒ‡æ ‡:")
        print(f"     MSE: {mse:.4f}")
        print(f"     MAE: {mae:.4f}")
        print(f"     PCC: {pcc:.4f}")
        
        # Step 6: æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
        print(f"\n   æ­¥éª¤6: å¼‚å¸¸å€¼æ£€æŸ¥...")
        
        # æ£€æŸ¥é¢„æµ‹ä¸­çš„å¼‚å¸¸å€¼
        pred_q99 = np.percentile(pred_flat, 99)
        pred_q01 = np.percentile(pred_flat, 1)
        target_q99 = np.percentile(target_flat, 99)
        target_q01 = np.percentile(target_flat, 1)
        
        print(f"   é¢„æµ‹å€¼åˆ†ä½æ•°: 1%={pred_q01:.4f}, 99%={pred_q99:.4f}")
        print(f"   ç›®æ ‡å€¼åˆ†ä½æ•°: 1%={target_q01:.4f}, 99%={target_q99:.4f}")
        
        # æ£€æŸ¥NaNå’ŒInf
        pred_nan = np.isnan(pred_flat).sum()
        pred_inf = np.isinf(pred_flat).sum()
        target_nan = np.isnan(target_flat).sum()
        target_inf = np.isinf(target_flat).sum()
        
        print(f"   é¢„æµ‹å€¼å¼‚å¸¸: NaN={pred_nan}, Inf={pred_inf}")
        print(f"   ç›®æ ‡å€¼å¼‚å¸¸: NaN={target_nan}, Inf={target_inf}")
        
        # Step 7: æ£€æŸ¥å‡ ä¸ªå…·ä½“åŸºå› çš„é¢„æµ‹
        print(f"\n   æ­¥éª¤7: å…·ä½“åŸºå› é¢„æµ‹æ£€æŸ¥...")
        for i in range(min(5, target_genes.shape[1])):
            pred_gene = predicted_gene_expression[:, i].cpu().numpy()
            target_gene = target_genes[:, i].cpu().numpy()
            gene_pcc, _ = pearsonr(pred_gene, target_gene)
            
            print(f"   åŸºå› {i}: é¢„æµ‹å‡å€¼={pred_gene.mean():.4f}, ç›®æ ‡å‡å€¼={target_gene.mean():.4f}, PCC={gene_pcc:.4f}")

def debug_stage1_reconstruction():
    """è°ƒè¯•Stage 1çš„é‡å»ºèƒ½åŠ›"""
    print(f"\nğŸ§ª è°ƒè¯•Stage 1é‡å»ºèƒ½åŠ›...")
    
    # åŠ è½½Stage 1æ£€æŸ¥ç‚¹
    stage1_ckpt = "logs/PRAD/TWO_STAGE_VAR_ST/stage1-best-epoch=epoch=143-val_mse=val_mse=0.5353.ckpt"
    checkpoint = torch.load(stage1_ckpt, map_location='cpu')
    
    print(f"   Stage 1 checkpoint epoch: {checkpoint.get('epoch', 'unknown')}")
    print(f"   Stage 1 val_mse: {checkpoint.get('val_mse', 'unknown')}")
    
    # TODO: å¯ä»¥ç›´æ¥æµ‹è¯•Stage 1çš„ç¼–ç -è§£ç èƒ½åŠ›

def debug_stage2_generation():
    """è°ƒè¯•Stage 2çš„ç”Ÿæˆèƒ½åŠ›"""
    print(f"\nğŸ§ª è°ƒè¯•Stage 2ç”Ÿæˆèƒ½åŠ›...")
    
    # åŠ è½½Stage 2æ£€æŸ¥ç‚¹
    stage2_ckpt = "logs/PRAD/TWO_STAGE_VAR_ST/stage2-best-epoch=epoch=03-val_acc=val_accuracy=0.8263.ckpt"
    checkpoint = torch.load(stage2_ckpt, map_location='cpu')
    
    print(f"   Stage 2 checkpoint epoch: {checkpoint.get('epoch', 'unknown')}")
    print(f"   Stage 2 val_accuracy: {checkpoint.get('val_accuracy', 'unknown')}")
    
    # TODO: å¯ä»¥ç›´æ¥æµ‹è¯•Stage 2çš„tokenç”Ÿæˆèƒ½åŠ›

if __name__ == "__main__":
    debug_inference_pipeline()
    debug_stage1_reconstruction()
    debug_stage2_generation() 