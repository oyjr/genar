#!/usr/bin/env python3
"""
éªŒè¯æ•°æ®åŠ è½½å™¨æ€§èƒ½è„šæœ¬

æ­¤è„šæœ¬éªŒè¯ï¼š
1. éªŒè¯æ•°æ®åŠ è½½å™¨æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„æ‰¹æ¬¡å¤§å°
2. æµ‹è¯•æ•°æ®åŠ è½½å™¨çš„æ€§èƒ½
3. æä¾›æ€§èƒ½ä¼˜åŒ–å»ºè®®

ä½¿ç”¨æ–¹æ³•ï¼š
python verify_dataloader_performance.py
"""

import sys
import os
sys.path.insert(0, 'src')
import time
import torch
from dataset.data_interface import DataInterface
from main import DATASETS, build_config_from_args, DEFAULT_CONFIG
from addict import Dict as AddictDict
import argparse

def test_dataloader_performance():
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨æ€§èƒ½"""
    print("ğŸ§ª éªŒè¯æ•°æ®åŠ è½½å™¨æ€§èƒ½...")
    
    # æ„å»ºæµ‹è¯•é…ç½®
    class MockArgs:
        def __init__(self):
            self.dataset = 'PRAD'
            self.model = 'TWO_STAGE_VAR_ST'
            self.training_stage = 1
            self.encoder = None
            self.gpus = 1
            self.epochs = None
            self.batch_size = None
            self.lr = None
            self.weight_decay = None
            self.patience = None
            self.strategy = 'auto'
            self.sync_batchnorm = False
            self.use_augmented = True
            self.expand_augmented = True
            self.mode = 'train'
            self.seed = None
            self.stage1_ckpt = None
            self.config = None
    
    args = MockArgs()
    config = build_config_from_args(args)
    
    print(f"âœ… é…ç½®æ„å»ºå®Œæˆ")
    print(f"   - è®­ç»ƒæ‰¹æ¬¡å¤§å°: {config.DATA.train_dataloader.batch_size}")
    print(f"   - éªŒè¯æ‰¹æ¬¡å¤§å°: {config.DATA.val_dataloader.batch_size}")
    print(f"   - æµ‹è¯•æ‰¹æ¬¡å¤§å°: {config.DATA.test_dataloader.batch_size}")
    
    # åˆ›å»ºæ•°æ®æ¥å£
    data_interface = DataInterface(config)
    data_interface.setup(stage='fit')
    
    # è·å–æ•°æ®åŠ è½½å™¨
    train_loader = data_interface.train_dataloader()
    val_loader = data_interface.val_dataloader()
    
    print(f"\nğŸ“Š æ•°æ®åŠ è½½å™¨ä¿¡æ¯:")
    print(f"   - è®­ç»ƒæ•°æ®é›†å¤§å°: {len(data_interface.train_dataset)}")
    print(f"   - éªŒè¯æ•°æ®é›†å¤§å°: {len(data_interface.val_dataset)}")
    print(f"   - è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    print(f"   - éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
    
    # æµ‹è¯•è®­ç»ƒæ•°æ®åŠ è½½å™¨é€Ÿåº¦
    print(f"\nâ±ï¸  æµ‹è¯•è®­ç»ƒæ•°æ®åŠ è½½å™¨æ€§èƒ½...")
    start_time = time.time()
    num_batches = 10
    
    for i, batch in enumerate(train_loader):
        if i >= num_batches:
            break
        # ç®€å•å¤„ç†ç¡®ä¿æ•°æ®åŠ è½½å®Œæˆ
        _ = batch['target_genes'].shape
    
    train_time = time.time() - start_time
    train_speed = num_batches / train_time
    print(f"   - è®­ç»ƒæ•°æ®åŠ è½½å™¨: {train_speed:.2f} batches/sec")
    
    # æµ‹è¯•éªŒè¯æ•°æ®åŠ è½½å™¨é€Ÿåº¦
    print(f"\nâ±ï¸  æµ‹è¯•éªŒè¯æ•°æ®åŠ è½½å™¨æ€§èƒ½...")
    start_time = time.time()
    
    for i, batch in enumerate(val_loader):
        if i >= num_batches:
            break
        # ç®€å•å¤„ç†ç¡®ä¿æ•°æ®åŠ è½½å®Œæˆ
        _ = batch['target_genes'].shape
    
    val_time = time.time() - start_time
    val_speed = num_batches / val_time
    print(f"   - éªŒè¯æ•°æ®åŠ è½½å™¨: {val_speed:.2f} batches/sec")
    
    # è®¡ç®—æ€§èƒ½æ¯”è¾ƒ
    speed_ratio = val_speed / train_speed if train_speed > 0 else 0
    print(f"\nğŸ“ˆ æ€§èƒ½åˆ†æ:")
    print(f"   - éªŒè¯/è®­ç»ƒé€Ÿåº¦æ¯”: {speed_ratio:.3f}")
    
    if speed_ratio > 0.5:
        print("âœ… éªŒè¯æ•°æ®åŠ è½½å™¨æ€§èƒ½æ­£å¸¸")
    else:
        print("âš ï¸  éªŒè¯æ•°æ®åŠ è½½å™¨æ€§èƒ½ä»ç„¶è¾ƒæ…¢")
    
    return {
        'train_speed': train_speed,
        'val_speed': val_speed,
        'speed_ratio': speed_ratio,
        'train_batch_size': config.DATA.train_dataloader.batch_size,
        'val_batch_size': config.DATA.val_dataloader.batch_size
    }

def print_performance_tips():
    """æ‰“å°æ€§èƒ½ä¼˜åŒ–å»ºè®®"""
    print(f"\nğŸš€ æ•°æ®åŠ è½½å™¨æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
    print(f"")
    print(f"1. **æ‰¹æ¬¡å¤§å°ä¼˜åŒ–**:")
    print(f"   - éªŒè¯/æµ‹è¯•å¯ä»¥ä½¿ç”¨æ›´å¤§æ‰¹æ¬¡ï¼š--batch_size 64 æˆ– 128")
    print(f"   - GPUå†…å­˜å…è®¸çš„æƒ…å†µä¸‹ï¼Œå¢å¤§æ‰¹æ¬¡èƒ½æ˜¾è‘—æå‡é€Ÿåº¦")
    print(f"")
    print(f"2. **å·¥ä½œè¿›ç¨‹ä¼˜åŒ–**:")
    print(f"   - å¢åŠ num_workersï¼šåœ¨é…ç½®ä¸­è®¾ç½®ä¸ºCPUæ ¸å¿ƒæ•°")
    print(f"   - å»ºè®®å€¼ï¼š4-8ä¸ªå·¥ä½œè¿›ç¨‹")
    print(f"")
    print(f"3. **å†…å­˜ä¼˜åŒ–**:")
    print(f"   - å¯ç”¨pin_memory=True (å·²å¯ç”¨)")
    print(f"   - å¯ç”¨persistent_workers=True (å·²å¯ç”¨)")
    print(f"")
    print(f"4. **ç¡¬ä»¶ä¼˜åŒ–**:")
    print(f"   - ä½¿ç”¨SSDå­˜å‚¨æ•°æ®")
    print(f"   - ç¡®ä¿è¶³å¤Ÿçš„å†…å­˜é¿å…swap")
    print(f"   - ä½¿ç”¨é«˜é€ŸGPU (V100/A100/RTXç³»åˆ—)")
    print(f"")
    print(f"5. **è®­ç»ƒç‰¹å®šä¼˜åŒ–**:")
    print(f"   - TWO_STAGE_VAR_ST Stage 2å¯ä»¥ä½¿ç”¨è¾ƒå°æ‰¹æ¬¡ (32-64)")
    print(f"   - Stage 1å¯ä»¥ä½¿ç”¨è¾ƒå¤§æ‰¹æ¬¡ (128-256)")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ•°æ®åŠ è½½å™¨æ€§èƒ½éªŒè¯å·¥å…·")
    print("=" * 60)
    
    try:
        # æµ‹è¯•æ€§èƒ½
        results = test_dataloader_performance()
        
        # æ‰“å°ä¼˜åŒ–å»ºè®®
        print_performance_tips()
        
        # æ€»ç»“
        print(f"\nğŸ“‹ æ€§èƒ½éªŒè¯æ€»ç»“:")
        print(f"   - è®­ç»ƒæ‰¹æ¬¡å¤§å°: {results['train_batch_size']}")
        print(f"   - éªŒè¯æ‰¹æ¬¡å¤§å°: {results['val_batch_size']}")
        print(f"   - è®­ç»ƒé€Ÿåº¦: {results['train_speed']:.2f} batches/sec")
        print(f"   - éªŒè¯é€Ÿåº¦: {results['val_speed']:.2f} batches/sec")
        print(f"   - é€Ÿåº¦æ¯”: {results['speed_ratio']:.3f}")
        
        if results['speed_ratio'] > 0.5:
            print(f"âœ… æ•°æ®åŠ è½½å™¨æ€§èƒ½æ­£å¸¸ï¼Œä¿®å¤æˆåŠŸï¼")
        else:
            print(f"âš ï¸  ä»æœ‰æ€§èƒ½é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç¡¬ä»¶æˆ–è¿›ä¸€æ­¥ä¼˜åŒ–")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main() 