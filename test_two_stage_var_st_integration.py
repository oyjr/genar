"""
Two-Stage VAR-ST Integration Test
å®Œæ•´æµ‹è¯•ä¸¤é˜¶æ®µVAR-STæ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æµç¨‹

ä¿®å¤äº†ä¹‹å‰æµ‹è¯•ä¸­çš„å…³é”®é—®é¢˜ï¼š
1. ç¡®ä¿Stage 2æ­£ç¡®åŠ è½½Stage 1 checkpoint
2. éªŒè¯training_stageæ­£ç¡®æ˜ å°„åˆ°current_stage 
3. æµ‹è¯•é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶
"""

import sys
import os
sys.path.insert(0, 'src')

import torch
import tempfile
import pytest
from pathlib import Path

from model.VAR.two_stage_var_st import TwoStageVARST
from model.model_interface import ModelInterface
from addict import Dict


def test_stage_parameter_mapping():
    """æµ‹è¯•training_stageåˆ°current_stageçš„å‚æ•°æ˜ å°„"""
    print("ğŸ§ª æµ‹è¯•å‚æ•°æ˜ å°„...")
    
    # æ¨¡æ‹Ÿé…ç½® - Stage 1
    config_stage1 = Dict({
        'MODEL': {
            'model_name': 'TWO_STAGE_VAR_ST',
            'training_stage': 1,  # æ³¨æ„ï¼šè¿™é‡Œæ˜¯training_stage
            'stage1_ckpt_path': None,
            'num_genes': 200,
            'histology_feature_dim': 1024,
            'spatial_coord_dim': 2,
        }
    })
    
    # æµ‹è¯•Stage 1å‚æ•°æ˜ å°„
    try:
        model_interface = ModelInterface(config_stage1)
        model = model_interface.model
        
        # éªŒè¯å‚æ•°æ˜ å°„æ­£ç¡®
        assert model.current_stage == 1, f"æœŸæœ›current_stage=1ï¼Œå®é™…å¾—åˆ°{model.current_stage}"
        print("âœ… Stage 1å‚æ•°æ˜ å°„æ­£ç¡®")
    except Exception as e:
        print(f"âŒ Stage 1å‚æ•°æ˜ å°„å¤±è´¥: {e}")
        raise
    
    # æ¨¡æ‹Ÿé…ç½® - Stage 2 (ä½†æ²¡æœ‰checkpointï¼Œåº”è¯¥æŠ¥é”™)
    config_stage2_no_ckpt = Dict({
        'MODEL': {
            'model_name': 'TWO_STAGE_VAR_ST',
            'training_stage': 2,
            'stage1_ckpt_path': None,  # æ²¡æœ‰checkpoint
            'num_genes': 200,
            'histology_feature_dim': 1024,
            'spatial_coord_dim': 2,
        }
    })
    
    # æµ‹è¯•Stage 2æ²¡æœ‰checkpointæ—¶çš„é”™è¯¯å¤„ç†
    print("ğŸ§ª æµ‹è¯•Stage 2ç¼ºå°‘checkpointçš„é”™è¯¯å¤„ç†...")
    try:
        model_interface = ModelInterface(config_stage2_no_ckpt)
        print("âŒ åº”è¯¥æŠ¥é”™ä½†æ²¡æœ‰æŠ¥é”™!")
        assert False, "Stage 2æ²¡æœ‰checkpointåº”è¯¥æŠ¥é”™"
    except ValueError as e:
        if "stage1_ckpt_path is required" in str(e) or "Two-stage VAR-STé…ç½®é”™è¯¯" in str(e):
            print("âœ… Stage 2ç¼ºå°‘checkpointæ­£ç¡®æŠ¥é”™")
        else:
            print(f"âŒ é”™è¯¯ä¿¡æ¯ä¸æ­£ç¡®: {e}")
            raise
    except Exception as e:
        print(f"âŒ æ„å¤–é”™è¯¯: {e}")
        raise


def test_stage1_training():
    """æµ‹è¯•Stage 1 VQVAEè®­ç»ƒ"""
    print("\nğŸ§ª æµ‹è¯•Stage 1è®­ç»ƒ...")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    batch_size = 4
    num_genes = 200
    
    # åˆ›å»ºStage 1æ¨¡å‹
    model = TwoStageVARST(
        num_genes=num_genes,
        current_stage=1,  # ç›´æ¥ä½¿ç”¨current_stageå‚æ•°
        device=device
    )
    
    model = model.to(device)
    
    # æ¨¡æ‹ŸåŸºå› è¡¨è¾¾æ•°æ®
    gene_expression = torch.randn(batch_size, num_genes, device=device)
    
    # Stage 1å‰å‘ä¼ æ’­
    model.train()
    output = model(gene_expression)
    
    # éªŒè¯è¾“å‡º
    assert 'loss' in output, "è¾“å‡ºåº”åŒ…å«loss"
    assert 'reconstructed' in output, "è¾“å‡ºåº”åŒ…å«reconstructed"
    assert 'tokens' in output, "è¾“å‡ºåº”åŒ…å«tokens"
    assert 'stage1_losses' in output, "è¾“å‡ºåº”åŒ…å«stage1_losses"
    
    # éªŒè¯losså¯ä»¥åå‘ä¼ æ’­
    loss = output['loss']
    loss.backward()
    
    print(f"âœ… Stage 1è®­ç»ƒæµ‹è¯•é€šè¿‡")
    print(f"   - Loss: {loss.item():.4f}")
    print(f"   - Reconstructed shape: {output['reconstructed'].shape}")
    
    return model


def test_stage1_checkpoint_saving_loading():
    """æµ‹è¯•Stage 1 checkpointä¿å­˜å’ŒåŠ è½½"""
    print("\nğŸ§ª æµ‹è¯•Stage 1 checkpointä¿å­˜å’ŒåŠ è½½...")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # åˆ›å»ºå¹¶è®­ç»ƒStage 1æ¨¡å‹
    model1 = TwoStageVARST(
        num_genes=200,
        current_stage=1,
        device=device
    )
    model1 = model1.to(device)
    
    # ä¿å­˜checkpoint
    with tempfile.TemporaryDirectory() as tmp_dir:
        ckpt_path = os.path.join(tmp_dir, "stage1_test.ckpt")
        model1.save_stage_checkpoint(ckpt_path, stage=1)
        
        assert os.path.exists(ckpt_path), "Checkpointæ–‡ä»¶åº”è¯¥è¢«åˆ›å»º"
        print(f"âœ… Stage 1 checkpointä¿å­˜æˆåŠŸ: {ckpt_path}")
        
        # æµ‹è¯•åŠ è½½checkpoint
        model2 = TwoStageVARST(
            num_genes=200,
            current_stage=2,  # Stage 2æ¨¡å¼
            stage1_ckpt_path=ckpt_path,  # åŠ è½½Stage 1
            device=device
        )
        model2 = model2.to(device)
        
        print("âœ… Stage 1 checkpointåŠ è½½æˆåŠŸ")
        
        # éªŒè¯VQVAEæƒé‡ä¸€è‡´
        model1_state = model1.stage1_vqvae.state_dict()
        model2_state = model2.stage1_vqvae.state_dict()
        
        for key in model1_state:
            if key in model2_state:
                diff = torch.norm(model1_state[key] - model2_state[key]).item()
                assert diff < 1e-6, f"æƒé‡ä¸ä¸€è‡´: {key}, diff={diff}"
        
        print("âœ… Stage 1æƒé‡åŠ è½½éªŒè¯é€šè¿‡")
        
        return ckpt_path, model2


def test_stage2_training():
    """æµ‹è¯•Stage 2 VAR Transformerè®­ç»ƒ"""
    print("\nğŸ§ª æµ‹è¯•Stage 2è®­ç»ƒ...")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    batch_size = 2  # Stage 2å†…å­˜éœ€æ±‚æ›´å¤§
    num_genes = 200
    histology_dim = 1024
    spatial_dim = 2
    
    # é¦–å…ˆåˆ›å»ºå¹¶ä¿å­˜Stage 1æ¨¡å‹
    with tempfile.TemporaryDirectory() as tmp_dir:
        ckpt_path = os.path.join(tmp_dir, "stage1_for_stage2.ckpt")
        
        # åˆ›å»ºStage 1æ¨¡å‹å¹¶ä¿å­˜
        stage1_model = TwoStageVARST(
            num_genes=num_genes,
            current_stage=1,
            device=device
        )
        stage1_model = stage1_model.to(device)
        stage1_model.save_stage_checkpoint(ckpt_path, stage=1)
        
        print(f"âœ… Stage 1æ¨¡å‹ä¿å­˜å®Œæˆ: {ckpt_path}")
        
        # åˆ›å»ºStage 2æ¨¡å‹
        stage2_model = TwoStageVARST(
            num_genes=num_genes,
            histology_feature_dim=histology_dim,
            spatial_coord_dim=spatial_dim,
            current_stage=2,
            stage1_ckpt_path=ckpt_path,
            device=device
        )
        stage2_model = stage2_model.to(device)
        
        print("âœ… Stage 2æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # éªŒè¯Stage 1è¢«å†»ç»“ï¼ŒStage 2å¯è®­ç»ƒ
        vqvae_trainable = any(p.requires_grad for p in stage2_model.stage1_vqvae.parameters())
        var_trainable = any(p.requires_grad for p in stage2_model.stage2_var.parameters())
        condition_trainable = any(p.requires_grad for p in stage2_model.condition_processor.parameters())
        
        assert not vqvae_trainable, "Stage 1 VQVAEåº”è¯¥è¢«å†»ç»“"
        assert var_trainable, "Stage 2 VARåº”è¯¥å¯è®­ç»ƒ"
        assert condition_trainable, "Condition processoråº”è¯¥å¯è®­ç»ƒ"
        
        print("âœ… Stage 2å‚æ•°å†»ç»“/è§£å†»çŠ¶æ€æ­£ç¡®")
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
        gene_expression = torch.randn(batch_size, num_genes, device=device)
        histology_features = torch.randn(batch_size, histology_dim, device=device)
        spatial_coords = torch.randn(batch_size, spatial_dim, device=device)
        
        # Stage 2å‰å‘ä¼ æ’­
        stage2_model.train()
        output = stage2_model(
            gene_expression=gene_expression,
            histology_features=histology_features,
            spatial_coords=spatial_coords
        )
        
        # éªŒè¯è¾“å‡º
        assert 'loss' in output, "è¾“å‡ºåº”åŒ…å«loss"
        assert 'logits' in output, "è¾“å‡ºåº”åŒ…å«logits"
        assert 'stage2_losses' in output, "è¾“å‡ºåº”åŒ…å«stage2_losses"
        
        # éªŒè¯losså¯ä»¥åå‘ä¼ æ’­
        loss = output['loss']
        loss.backward()
        
        print(f"âœ… Stage 2è®­ç»ƒæµ‹è¯•é€šè¿‡")
        print(f"   - Loss: {loss.item():.4f}")
        print(f"   - Logits shape: {output['logits'].shape}")


def test_end_to_end_inference():
    """æµ‹è¯•ç«¯åˆ°ç«¯æ¨ç†æµç¨‹"""
    print("\nğŸ§ª æµ‹è¯•ç«¯åˆ°ç«¯æ¨ç†...")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    batch_size = 1
    num_genes = 200
    histology_dim = 1024
    spatial_dim = 2
    
    with tempfile.TemporaryDirectory() as tmp_dir:
        ckpt_path = os.path.join(tmp_dir, "stage1_for_inference.ckpt")
        
        # åˆ›å»ºå¹¶ä¿å­˜Stage 1æ¨¡å‹
        stage1_model = TwoStageVARST(
            num_genes=num_genes,
            current_stage=1,
            device=device
        )
        stage1_model = stage1_model.to(device)
        stage1_model.save_stage_checkpoint(ckpt_path, stage=1)
        
        # åˆ›å»ºå®Œæ•´æ¨¡å‹ç”¨äºæ¨ç†
        model = TwoStageVARST(
            num_genes=num_genes,
            histology_feature_dim=histology_dim,
            spatial_coord_dim=spatial_dim,
            current_stage=2,
            stage1_ckpt_path=ckpt_path,
            device=device
        )
        model = model.to(device)
        model.eval()
        
        # æ¨¡æ‹Ÿæ¨ç†è¾“å…¥
        histology_features = torch.randn(batch_size, histology_dim, device=device)
        spatial_coords = torch.randn(batch_size, spatial_dim, device=device)
        
        # æ¨ç†
        with torch.no_grad():
            results = model.inference(
                histology_features=histology_features,
                spatial_coords=spatial_coords,
                temperature=1.0,
                top_k=50,
                top_p=0.9
            )
        
        # éªŒè¯æ¨ç†è¾“å‡º
        assert 'predicted_gene_expression' in results, "åº”åŒ…å«é¢„æµ‹åŸºå› è¡¨è¾¾"
        assert 'generated_tokens' in results, "åº”åŒ…å«ç”Ÿæˆçš„tokens"
        assert 'multi_scale_tokens' in results, "åº”åŒ…å«å¤šå°ºåº¦tokens"
        
        predicted_genes = results['predicted_gene_expression']
        assert predicted_genes.shape == (batch_size, num_genes), f"é¢„æµ‹åŸºå› å½¢çŠ¶é”™è¯¯: {predicted_genes.shape}"
        
        print(f"âœ… ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•é€šè¿‡")
        print(f"   - é¢„æµ‹åŸºå› è¡¨è¾¾å½¢çŠ¶: {predicted_genes.shape}")
        print(f"   - ç”Ÿæˆtokenså½¢çŠ¶: {results['generated_tokens'].shape}")


def test_model_interface_integration():
    """æµ‹è¯•ModelInterfaceé›†æˆ"""
    print("\nğŸ§ª æµ‹è¯•ModelInterfaceé›†æˆ...")
    
    with tempfile.TemporaryDirectory() as tmp_dir:
        ckpt_path = os.path.join(tmp_dir, "stage1_for_interface.ckpt")
        
        # é¦–å…ˆåˆ›å»ºStage 1 checkpoint
        stage1_model = TwoStageVARST(num_genes=200, current_stage=1)
        stage1_model.save_stage_checkpoint(ckpt_path, stage=1)
        
        # æµ‹è¯•Stage 1 ModelInterface
        config_stage1 = Dict({
            'MODEL': {
                'model_name': 'TWO_STAGE_VAR_ST',
                'training_stage': 1,
                'stage1_ckpt_path': None,
                'num_genes': 200,
                'histology_feature_dim': 1024,
                'spatial_coord_dim': 2,
            }
        })
        
        try:
            interface1 = ModelInterface(config_stage1)
            assert interface1.model.current_stage == 1
            print("âœ… Stage 1 ModelInterfaceæµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"âŒ Stage 1 ModelInterfaceæµ‹è¯•å¤±è´¥: {e}")
            raise
        
        # æµ‹è¯•Stage 2 ModelInterface
        config_stage2 = Dict({
            'MODEL': {
                'model_name': 'TWO_STAGE_VAR_ST',
                'training_stage': 2,
                'stage1_ckpt_path': ckpt_path,
                'num_genes': 200,
                'histology_feature_dim': 1024,
                'spatial_coord_dim': 2,
            }
        })
        
        try:
            interface2 = ModelInterface(config_stage2)
            assert interface2.model.current_stage == 2
            print("âœ… Stage 2 ModelInterfaceæµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"âŒ Stage 2 ModelInterfaceæµ‹è¯•å¤±è´¥: {e}")
            raise


def test_error_conditions():
    """æµ‹è¯•é”™è¯¯æ¡ä»¶å’Œè¾¹ç•Œæƒ…å†µ"""
    print("\nğŸ§ª æµ‹è¯•é”™è¯¯æ¡ä»¶...")
    
    # æµ‹è¯•ä¸å­˜åœ¨çš„checkpointè·¯å¾„
    try:
        model = TwoStageVARST(
            current_stage=2,
            stage1_ckpt_path="/nonexistent/path.ckpt"
        )
        print("âŒ åº”è¯¥å› ä¸ºcheckpointä¸å­˜åœ¨è€ŒæŠ¥é”™")
        assert False, "åº”è¯¥æŠ¥é”™ä½†æ²¡æœ‰"
    except FileNotFoundError:
        print("âœ… ä¸å­˜åœ¨çš„checkpointè·¯å¾„æ­£ç¡®æŠ¥é”™")
    except Exception as e:
        print(f"âŒ æ„å¤–é”™è¯¯ç±»å‹: {e}")
        raise
    
    # æµ‹è¯•Stage 2ç¼ºå°‘checkpoint
    try:
        model = TwoStageVARST(current_stage=2, stage1_ckpt_path=None)
        print("âŒ åº”è¯¥å› ä¸ºStage 2ç¼ºå°‘checkpointè€ŒæŠ¥é”™")
        assert False, "åº”è¯¥æŠ¥é”™ä½†æ²¡æœ‰"
    except ValueError as e:
        if "stage1_ckpt_path is required" in str(e):
            print("âœ… Stage 2ç¼ºå°‘checkpointæ­£ç¡®æŠ¥é”™")
        else:
            print(f"âŒ é”™è¯¯ä¿¡æ¯ä¸æ­£ç¡®: {e}")
            raise
    except Exception as e:
        print(f"âŒ æ„å¤–é”™è¯¯ç±»å‹: {e}")
        raise
    
    # æµ‹è¯•æ— æ•ˆçš„stageå€¼
    try:
        model = TwoStageVARST(current_stage=3)
        print("âŒ åº”è¯¥å› ä¸ºæ— æ•ˆstageå€¼è€ŒæŠ¥é”™")
        assert False, "åº”è¯¥æŠ¥é”™ä½†æ²¡æœ‰"
    except ValueError as e:
        if "Invalid stage" in str(e):
            print("âœ… æ— æ•ˆstageå€¼æ­£ç¡®æŠ¥é”™")
        else:
            print(f"âŒ é”™è¯¯ä¿¡æ¯ä¸æ­£ç¡®: {e}")
            raise
    except Exception as e:
        print(f"âŒ æ„å¤–é”™è¯¯ç±»å‹: {e}")
        raise


def test_stage2_metrics_skipping():
    """æµ‹è¯•Stage 2è®­ç»ƒæ—¶æ­£ç¡®è·³è¿‡åŸºå› è¡¨è¾¾æŒ‡æ ‡è®¡ç®—"""
    print("\nğŸ§ª æµ‹è¯•Stage 2æŒ‡æ ‡è·³è¿‡...")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    with tempfile.TemporaryDirectory() as tmp_dir:
        ckpt_path = os.path.join(tmp_dir, "stage1_for_metrics_test.ckpt")
        
        # åˆ›å»ºStage 1æ¨¡å‹å¹¶ä¿å­˜
        stage1_model = TwoStageVARST(num_genes=200, current_stage=1, device=device)
        stage1_model = stage1_model.to(device)
        stage1_model.save_stage_checkpoint(ckpt_path, stage=1)
        
        # åˆ›å»ºStage 2 ModelInterface
        config_stage2 = Dict({
            'MODEL': {
                'model_name': 'TWO_STAGE_VAR_ST',
                'training_stage': 2,
                'stage1_ckpt_path': ckpt_path,
                'num_genes': 200,
                'histology_feature_dim': 1024,
                'spatial_coord_dim': 2,
            }
        })
        
        interface = ModelInterface(config_stage2)
        interface = interface.to(device)
        
        # éªŒè¯Stage 2é…ç½®
        assert interface.model.current_stage == 2, "åº”è¯¥æ˜¯Stage 2"
        
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„è¾“å…¥æ ¼å¼
        batch = {
            'target_genes': torch.randn(4, 200, device=device),
            'img': torch.randn(4, 1024, device=device),
            'positions': torch.randn(4, 2, device=device),
        }
        
        # é¢„å¤„ç†è¾“å…¥
        processed_batch = interface._preprocess_inputs(batch)
        
        # éªŒè¯é¢„å¤„ç†ç»“æœ
        assert 'gene_expression' in processed_batch, "åº”è¯¥åŒ…å«gene_expression"
        assert 'histology_features' in processed_batch, "åº”è¯¥åŒ…å«histology_features"
        assert 'spatial_coords' in processed_batch, "åº”è¯¥åŒ…å«spatial_coords"
        
        # æ¨¡å‹å‰å‘ä¼ æ’­
        results_dict = interface.model(**processed_batch)
        
        # éªŒè¯è¾“å‡ºæ ¼å¼
        assert 'loss' in results_dict, "åº”è¯¥åŒ…å«VARæŸå¤±"
        assert 'logits' in results_dict, "åº”è¯¥åŒ…å«VAR logits"
        assert results_dict['logits'].shape == (4, 241, 4096), f"VAR logitså½¢çŠ¶é”™è¯¯: {results_dict['logits'].shape}"
        
        # æµ‹è¯•æŒ‡æ ‡æå– - åº”è¯¥è¿”å›dummyæ•°æ®
        logits, target_genes = interface._extract_predictions_and_targets(results_dict, batch)
        
        # éªŒè¯è¿”å›çš„æ˜¯dummyæ•°æ®ï¼ˆé›¶å¼ é‡ï¼‰
        assert logits.shape == (4, 200), f"é¢„æœŸå½¢çŠ¶ [4, 200]ï¼Œå®é™… {logits.shape}"
        assert target_genes.shape == (4, 200), f"é¢„æœŸå½¢çŠ¶ [4, 200]ï¼Œå®é™… {target_genes.shape}"
        assert torch.allclose(logits, torch.zeros_like(logits)), "åº”è¯¥è¿”å›é›¶å¼ é‡ä½œä¸ºdummyæ•°æ®"
        
        print("âœ… Stage 2æŒ‡æ ‡è·³è¿‡æµ‹è¯•é€šè¿‡")
        print(f"   - VAR logitså½¢çŠ¶: {results_dict['logits'].shape}")
        print(f"   - Dummyé¢„æµ‹å½¢çŠ¶: {logits.shape}")
        print(f"   - æ˜¯å¦ä¸ºé›¶å¼ é‡: {torch.allclose(logits, torch.zeros_like(logits))}")


def test_stage2_end_to_end_inference():
    """æµ‹è¯•Stage 2çš„ç«¯åˆ°ç«¯æ¨ç†æµç¨‹"""
    print("\nğŸ§ª æµ‹è¯•Stage 2ç«¯åˆ°ç«¯æ¨ç†...")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    with tempfile.TemporaryDirectory() as tmp_dir:
        ckpt_path = os.path.join(tmp_dir, "stage1_for_e2e.ckpt")
        
        # åˆ›å»ºå¹¶ä¿å­˜Stage 1æ¨¡å‹
        stage1_model = TwoStageVARST(num_genes=200, current_stage=1, device=device)
        stage1_model = stage1_model.to(device)
        stage1_model.save_stage_checkpoint(ckpt_path, stage=1)
        
        # åˆ›å»ºStage 2æ¨¡å‹
        stage2_model = TwoStageVARST(
            num_genes=200,
            histology_feature_dim=1024,
            spatial_coord_dim=2,
            current_stage=2,
            stage1_ckpt_path=ckpt_path,
            device=device
        )
        stage2_model = stage2_model.to(device)
        stage2_model.eval()
        
        # æ¨¡æ‹Ÿæ¨ç†è¾“å…¥
        histology_features = torch.randn(2, 1024, device=device)
        spatial_coords = torch.randn(2, 2, device=device)
        
        # ç«¯åˆ°ç«¯æ¨ç†
        with torch.no_grad():
            results = stage2_model.inference(
                histology_features=histology_features,
                spatial_coords=spatial_coords,
                temperature=1.0,
                top_k=50,
                top_p=0.9
            )
        
        # éªŒè¯æ¨ç†è¾“å‡º
        assert 'predicted_gene_expression' in results, "åº”åŒ…å«é¢„æµ‹åŸºå› è¡¨è¾¾"
        assert 'generated_tokens' in results, "åº”åŒ…å«ç”Ÿæˆçš„tokens"
        assert 'multi_scale_tokens' in results, "åº”åŒ…å«å¤šå°ºåº¦tokens"
        
        predicted_genes = results['predicted_gene_expression']
        generated_tokens = results['generated_tokens']
        
        # éªŒè¯å½¢çŠ¶
        assert predicted_genes.shape == (2, 200), f"é¢„æµ‹åŸºå› å½¢çŠ¶é”™è¯¯: {predicted_genes.shape}"
        assert generated_tokens.shape == (2, 241), f"ç”Ÿæˆtokenså½¢çŠ¶é”™è¯¯: {generated_tokens.shape}"
        
        # éªŒè¯å¤šå°ºåº¦tokensç»“æ„
        multi_scale_tokens = results['multi_scale_tokens']
        assert multi_scale_tokens['global'].shape == (2, 1), "å…¨å±€tokenså½¢çŠ¶é”™è¯¯"
        assert multi_scale_tokens['pathway'].shape == (2, 8), "é€šè·¯tokenså½¢çŠ¶é”™è¯¯"
        assert multi_scale_tokens['module'].shape == (2, 32), "æ¨¡å—tokenså½¢çŠ¶é”™è¯¯"
        assert multi_scale_tokens['individual'].shape == (2, 200), "ä¸ªä½“tokenså½¢çŠ¶é”™è¯¯"
        
        print("âœ… Stage 2ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•é€šè¿‡")
        print(f"   - é¢„æµ‹åŸºå› è¡¨è¾¾å½¢çŠ¶: {predicted_genes.shape}")
        print(f"   - ç”Ÿæˆtokenså½¢çŠ¶: {generated_tokens.shape}")
        print(f"   - å¤šå°ºåº¦tokens: global{multi_scale_tokens['global'].shape}, pathway{multi_scale_tokens['pathway'].shape}, module{multi_scale_tokens['module'].shape}, individual{multi_scale_tokens['individual'].shape}")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ä¸¤é˜¶æ®µVAR-STé›†æˆæµ‹è¯•")
    print("=" * 60)
    
    try:
        # 1. å‚æ•°æ˜ å°„æµ‹è¯•
        test_stage_parameter_mapping()
        
        # 2. Stage 1è®­ç»ƒæµ‹è¯•
        test_stage1_training()
        
        # 3. Checkpointä¿å­˜åŠ è½½æµ‹è¯•
        test_stage1_checkpoint_saving_loading()
        
        # 4. Stage 2è®­ç»ƒæµ‹è¯•
        test_stage2_training()
        
        # 5. ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•
        test_end_to_end_inference()
        
        # 6. ModelInterfaceé›†æˆæµ‹è¯•
        test_model_interface_integration()
        
        # 7. é”™è¯¯æ¡ä»¶æµ‹è¯•
        test_error_conditions()
        
        # ğŸ”§ æ–°å¢ï¼šStage 2æŒ‡æ ‡è·³è¿‡æµ‹è¯•
        test_stage2_metrics_skipping()
        
        # ğŸ”§ æ–°å¢ï¼šStage 2ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•
        test_stage2_end_to_end_inference()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¸¤é˜¶æ®µVAR-STå®ç°æ­£ç¡®")
        print("âœ… Stage 1 VQVAEè®­ç»ƒæ­£å¸¸")
        print("âœ… Stage 2 VAR Transformerè®­ç»ƒæ­£å¸¸")
        print("âœ… Stage 2æ­£ç¡®è·³è¿‡åŸºå› è¡¨è¾¾æŒ‡æ ‡è®¡ç®—")
        print("âœ… å‚æ•°æ˜ å°„å’Œé”™è¯¯å¤„ç†æ­£ç¡®")
        print("âœ… ç«¯åˆ°ç«¯æ¨ç†æµç¨‹æ­£å¸¸")
        print("âœ… ModelInterfaceé›†æˆæ­£å¸¸")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    run_all_tests() 