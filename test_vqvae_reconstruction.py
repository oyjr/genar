#!/usr/bin/env python3
"""
æµ‹è¯•Stage 1 VQVAEçš„ç¼–ç -è§£ç èƒ½åŠ›

ç›®çš„ï¼š
1. éªŒè¯VQVAEæœ¬èº«çš„é‡å»ºèƒ½åŠ›æ˜¯å¦æ­£å¸¸
2. å¯¹æ¯”ç›´æ¥ç¼–ç -è§£ç  vs ä»VARç”Ÿæˆçš„tokensè§£ç 
3. æ‰¾å‡ºæ¨ç†é—®é¢˜çš„çœŸæ­£åŸå› 
"""

import sys
import os
sys.path.insert(0, 'src')

import torch
import numpy as np
from addict import Dict as AddictDict
from dataset.data_interface import DataInterface
from model.VAR.multi_scale_gene_vqvae import MultiScaleGeneVQVAE
from main import DATASETS

def test_vqvae_direct_reconstruction():
    """æµ‹è¯•VQVAEç›´æ¥ç¼–ç -è§£ç èƒ½åŠ›"""
    print("ğŸ§ª æµ‹è¯•VQVAEç›´æ¥ç¼–ç -è§£ç èƒ½åŠ›")
    print("=" * 50)
    
    # 1. åŠ è½½VQVAEæ¨¡å‹
    stage1_ckpt = "logs/PRAD/TWO_STAGE_VAR_ST/stage1-best-epoch=epoch=143-val_mse=val_mse=0.5353.ckpt"
    
    # ä»checkpointåŠ è½½é…ç½®
    checkpoint = torch.load(stage1_ckpt, map_location='cpu')
    if 'hyper_parameters' in checkpoint and 'config' in checkpoint['hyper_parameters']:
        # PyTorch Lightningæ ¼å¼
        model_config = checkpoint['hyper_parameters']['config']
        if hasattr(model_config, 'MODEL'):
            vqvae_config = {
                'vocab_size': getattr(model_config.MODEL, 'vocab_size', 4096),
                'embed_dim': getattr(model_config.MODEL, 'embed_dim', 128),
                'beta': getattr(model_config.MODEL, 'beta', 0.25),
                'hierarchical_loss_weight': getattr(model_config.MODEL, 'hierarchical_loss_weight', 0.1),
                'vq_loss_weight': getattr(model_config.MODEL, 'vq_loss_weight', 0.25)
            }
        else:
            vqvae_config = {}
    else:
        vqvae_config = {}
    
    # ä½¿ç”¨é»˜è®¤é…ç½®
    vqvae = MultiScaleGeneVQVAE(**vqvae_config)
    
    # åŠ è½½æƒé‡
    if 'state_dict' in checkpoint:
        # PyTorch Lightningæ ¼å¼
        state_dict = {}
        for key, value in checkpoint['state_dict'].items():
            if key.startswith('model.stage1_vqvae.'):
                new_key = key.replace('model.stage1_vqvae.', '')
                state_dict[new_key] = value
        vqvae.load_state_dict(state_dict, strict=False)
    else:
        vqvae.load_state_dict(checkpoint['model_state_dict'])
    
    vqvae.cuda()
    vqvae.eval()
    
    print(f"âœ… VQVAEæ¨¡å‹åŠ è½½å®Œæˆ")
    
    # 2. å‡†å¤‡æµ‹è¯•æ•°æ®
    dataset_info = DATASETS['PRAD']
    config = AddictDict({
        'data_path': dataset_info['path'],
        'slide_val': dataset_info['val_slides'],
        'slide_test': dataset_info['test_slides'],
        'encoder_name': dataset_info['recommended_encoder'],
        'use_augmented': False,
        'expand_augmented': False,
        'expr_name': 'PRAD',
        'MODEL': AddictDict({'model_name': 'TWO_STAGE_VAR_ST'}),
        'DATA': {
            'normalize': True,
            'test_dataloader': {
                'batch_size': 8,
                'num_workers': 0,
                'pin_memory': True,
                'shuffle': False,
                'persistent_workers': False
            }
        }
    })
    
    data_interface = DataInterface(config)
    data_interface.setup(stage='test')
    dataloader = data_interface.test_dataloader()
    
    # 3. æµ‹è¯•ç›´æ¥ç¼–ç -è§£ç 
    batch = next(iter(dataloader))
    gene_expression = batch['target_genes'].cuda()  # [B, 200]
    
    print(f"\nğŸ“Š æµ‹è¯•æ•°æ®:")
    print(f"   æ‰¹æ¬¡å¤§å°: {gene_expression.shape[0]}")
    print(f"   åŸºå› æ•°é‡: {gene_expression.shape[1]}")
    print(f"   ç›®æ ‡èŒƒå›´: [{gene_expression.min().item():.4f}, {gene_expression.max().item():.4f}]")
    print(f"   ç›®æ ‡å‡å€¼: {gene_expression.mean().item():.4f}")
    print(f"   ç›®æ ‡æ ‡å‡†å·®: {gene_expression.std().item():.4f}")
    
    with torch.no_grad():
        # æµ‹è¯•1: å®Œæ•´å‰å‘ä¼ æ’­ï¼ˆè®­ç»ƒæ—¶çš„æ–¹å¼ï¼‰
        print(f"\nğŸ”„ æµ‹è¯•1: å®Œæ•´å‰å‘ä¼ æ’­ï¼ˆè®­ç»ƒæ–¹å¼ï¼‰")
        full_result = vqvae(gene_expression)
        reconstructed = full_result['final_reconstruction']
        
        print(f"   é‡å»ºèŒƒå›´: [{reconstructed.min().item():.4f}, {reconstructed.max().item():.4f}]")
        print(f"   é‡å»ºå‡å€¼: {reconstructed.mean().item():.4f}")
        print(f"   é‡å»ºæ ‡å‡†å·®: {reconstructed.std().item():.4f}")
        
        # è®¡ç®—é‡å»ºè¯¯å·®
        mse_loss = torch.nn.functional.mse_loss(reconstructed, gene_expression)
        mae_loss = torch.nn.functional.l1_loss(reconstructed, gene_expression)
        
        print(f"   é‡å»ºMSE: {mse_loss.item():.6f}")
        print(f"   é‡å»ºMAE: {mae_loss.item():.6f}")
        
        # æµ‹è¯•2: åˆ†æ­¥ç¼–ç -è§£ç 
        print(f"\nğŸ”„ æµ‹è¯•2: åˆ†æ­¥ç¼–ç -è§£ç ")
        encode_result = vqvae.encode(gene_expression)
        tokens = encode_result['tokens']
        
        print(f"   ç”Ÿæˆçš„tokens:")
        for scale, scale_tokens in tokens.items():
            unique_tokens = torch.unique(scale_tokens)
            print(f"     {scale}: å½¢çŠ¶{scale_tokens.shape}, å”¯ä¸€tokensæ•°é‡{len(unique_tokens)}, èŒƒå›´[{scale_tokens.min().item()}, {scale_tokens.max().item()}]")
        
        # ä»tokensé‡å»º
        decode_result = vqvae.decode_from_tokens(tokens)
        tokens_reconstructed = decode_result['final_reconstruction']
        
        print(f"   ä»tokensé‡å»º:")
        print(f"   é‡å»ºèŒƒå›´: [{tokens_reconstructed.min().item():.4f}, {tokens_reconstructed.max().item():.4f}]")
        print(f"   é‡å»ºå‡å€¼: {tokens_reconstructed.mean().item():.4f}")
        print(f"   é‡å»ºæ ‡å‡†å·®: {tokens_reconstructed.std().item():.4f}")
        
        tokens_mse = torch.nn.functional.mse_loss(tokens_reconstructed, gene_expression)
        tokens_mae = torch.nn.functional.l1_loss(tokens_reconstructed, gene_expression)
        
        print(f"   tokensé‡å»ºMSE: {tokens_mse.item():.6f}")
        print(f"   tokensé‡å»ºMAE: {tokens_mae.item():.6f}")
        
        # æµ‹è¯•3: éªŒè¯ä¸¤ç§æ–¹å¼çš„ä¸€è‡´æ€§
        print(f"\nğŸ”„ æµ‹è¯•3: éªŒè¯é‡å»ºä¸€è‡´æ€§")
        consistency_error = torch.nn.functional.mse_loss(reconstructed, tokens_reconstructed)
        print(f"   å®Œæ•´å‰å‘ vs tokensé‡å»ºçš„MSE: {consistency_error.item():.8f}")
        
        if consistency_error.item() < 1e-5:
            print("   âœ… ä¸¤ç§é‡å»ºæ–¹å¼å®Œå…¨ä¸€è‡´")
        else:
            print("   âŒ ä¸¤ç§é‡å»ºæ–¹å¼ä¸ä¸€è‡´ï¼Œå¯èƒ½æœ‰é—®é¢˜")
            
        # æµ‹è¯•4: ä¸è®­ç»ƒæ—¶çš„val_mseå¯¹æ¯”
        print(f"\nğŸ“ˆ ä¸è®­ç»ƒæŒ‡æ ‡å¯¹æ¯”:")
        print(f"   è®­ç»ƒæ—¶val_mse: 0.5353")
        print(f"   å½“å‰æµ‹è¯•MSE: {mse_loss.item():.6f}")
        
        if abs(mse_loss.item() - 0.5353) < 0.1:
            print("   âœ… é‡å»ºè´¨é‡ä¸è®­ç»ƒæ—¶ä¸€è‡´")
        else:
            print("   âš ï¸ é‡å»ºè´¨é‡ä¸è®­ç»ƒæ—¶æœ‰å·®å¼‚")

def test_vqvae_token_diversity():
    """æµ‹è¯•VQVAEçš„tokenå¤šæ ·æ€§"""
    print(f"\nğŸ² æµ‹è¯•tokenå¤šæ ·æ€§")
    print("=" * 30)
    
    # åŠ è½½æ¨¡å‹ï¼ˆå¤ç”¨ä¸Šé¢çš„ä»£ç ï¼‰
    stage1_ckpt = "logs/PRAD/TWO_STAGE_VAR_ST/stage1-best-epoch=epoch=143-val_mse=val_mse=0.5353.ckpt"
    checkpoint = torch.load(stage1_ckpt, map_location='cpu')
    
    vqvae = MultiScaleGeneVQVAE()
    
    if 'state_dict' in checkpoint:
        state_dict = {}
        for key, value in checkpoint['state_dict'].items():
            if key.startswith('model.stage1_vqvae.'):
                new_key = key.replace('model.stage1_vqvae.', '')
                state_dict[new_key] = value
        vqvae.load_state_dict(state_dict, strict=False)
    
    vqvae.cuda()
    vqvae.eval()
    
    # å‡†å¤‡æ›´å¤šæ•°æ®
    dataset_info = DATASETS['PRAD']
    config = AddictDict({
        'data_path': dataset_info['path'],
        'slide_test': dataset_info['test_slides'],
        'encoder_name': dataset_info['recommended_encoder'],
        'use_augmented': False,
        'expr_name': 'PRAD',
        'MODEL': AddictDict({'model_name': 'TWO_STAGE_VAR_ST'}),
        'DATA': {
            'normalize': True,
            'test_dataloader': {
                'batch_size': 32,
                'num_workers': 0,
                'shuffle': False,
                'persistent_workers': False
            }
        }
    })
    
    data_interface = DataInterface(config)
    data_interface.setup(stage='test')
    dataloader = data_interface.test_dataloader()
    
    all_tokens = {scale: [] for scale in ['global', 'pathway', 'module', 'individual']}
    
    with torch.no_grad():
        for i, batch in enumerate(dataloader):
            if i >= 10:  # æµ‹è¯•10ä¸ªæ‰¹æ¬¡
                break
                
            gene_expression = batch['target_genes'].cuda()
            encode_result = vqvae.encode(gene_expression)
            tokens = encode_result['tokens']
            
            for scale in ['global', 'pathway', 'module', 'individual']:
                all_tokens[scale].append(tokens[scale].cpu())
    
    # åˆ†ætokenåˆ†å¸ƒ
    for scale in ['global', 'pathway', 'module', 'individual']:
        all_scale_tokens = torch.cat(all_tokens[scale], dim=0).flatten()
        unique_tokens, counts = torch.unique(all_scale_tokens, return_counts=True)
        
        print(f"   {scale}å°ºåº¦:")
        print(f"     æ€»tokensæ•°: {len(all_scale_tokens)}")
        print(f"     å”¯ä¸€tokensæ•°: {len(unique_tokens)}/4096")
        print(f"     åˆ©ç”¨ç‡: {len(unique_tokens)/4096:.3f}")
        print(f"     æœ€é¢‘ç¹çš„5ä¸ªtokens: {unique_tokens[:5].tolist()}")

if __name__ == "__main__":
    test_vqvae_direct_reconstruction()
    test_vqvae_token_diversity() 