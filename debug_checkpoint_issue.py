#!/usr/bin/env python3
"""
è°ƒè¯•æ£€æŸ¥ç‚¹æ›´æ–°é—®é¢˜çš„è„šæœ¬
æ£€æŸ¥PyTorch Lightningå¦‚ä½•ç›‘æ§å’Œä¿å­˜æ£€æŸ¥ç‚¹
"""

import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint
import os
from pathlib import Path

def analyze_checkpoint_issue():
    print("ğŸ” åˆ†ææ£€æŸ¥ç‚¹æ›´æ–°é—®é¢˜")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ç°æœ‰æ£€æŸ¥ç‚¹æ–‡ä»¶
    ckpt_dir = "logs/PRAD/TWO_STAGE_VAR_ST/"
    if os.path.exists(ckpt_dir):
        print(f"ğŸ“ æ£€æŸ¥ç‚¹ç›®å½•: {ckpt_dir}")
        ckpt_files = list(Path(ckpt_dir).glob("*.ckpt"))
        
        for ckpt_file in sorted(ckpt_files, key=lambda x: x.stat().st_mtime, reverse=True):
            stat = ckpt_file.stat()
            import time
            time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(stat.st_mtime))
            size_mb = stat.st_size / (1024 * 1024)
            print(f"  ğŸ“„ {ckpt_file.name}")
            print(f"      æ—¶é—´: {time_str}")
            print(f"      å¤§å°: {size_mb:.1f} MB")
            
            # å°è¯•åŠ è½½æ£€æŸ¥ç‚¹å¹¶æ£€æŸ¥æŒ‡æ ‡
            try:
                ckpt = torch.load(ckpt_file, map_location='cpu')
                
                # æ£€æŸ¥ä¿å­˜çš„æŒ‡æ ‡
                if 'epoch' in ckpt:
                    print(f"      Epoch: {ckpt['epoch']}")
                if 'global_step' in ckpt:
                    print(f"      Global Step: {ckpt['global_step']}")
                    
                # å¯»æ‰¾ val_mse ç›¸å…³ä¿¡æ¯
                for key in ckpt.keys():
                    if 'val_mse' in str(key).lower():
                        print(f"      {key}: {ckpt[key]}")
                        
                # æ£€æŸ¥ä¿å­˜çš„æŒ‡æ ‡å†å²
                if 'callbacks' in ckpt:
                    callbacks = ckpt['callbacks']
                    for cb_name, cb_state in callbacks.items():
                        if 'ModelCheckpoint' in cb_name:
                            print(f"      ModelCheckpointçŠ¶æ€:")
                            if hasattr(cb_state, 'monitor') or 'monitor' in cb_state:
                                monitor = cb_state.get('monitor', 'unknown')
                                print(f"        ç›‘æ§æŒ‡æ ‡: {monitor}")
                            if hasattr(cb_state, 'best_model_score') or 'best_model_score' in cb_state:
                                best_score = cb_state.get('best_model_score', 'unknown')
                                print(f"        æœ€ä½³åˆ†æ•°: {best_score}")
                                
            except Exception as e:
                print(f"      âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            
            print()
    else:
        print(f"âŒ æ£€æŸ¥ç‚¹ç›®å½•ä¸å­˜åœ¨: {ckpt_dir}")
    
    print("\nğŸ”§ æ£€æŸ¥ç‚¹æ–‡ä»¶ååˆ†æ:")
    print("æ ¹æ®æ–‡ä»¶ååˆ†æ:")
    print("- stage1-best-epoch=epoch=00-val_mse=val_mse=3.2939.ckpt")
    print("  é—®é¢˜: å‡ºç°äº†é‡å¤çš„å­—æ®µå 'val_mse=val_mse='")
    print("  è¿™å¯èƒ½æ˜¯å› ä¸ºæŒ‡æ ‡åç§°å’Œæ ¼å¼å­—ç¬¦ä¸²ä¸åŒ¹é…")
    
    print("\nğŸ”§ å¯èƒ½çš„åŸå› :")
    print("1. PyTorch Lightningæ²¡æœ‰æ¥æ”¶åˆ°æ­£ç¡®çš„val_mseæŒ‡æ ‡")
    print("2. æŒ‡æ ‡è®°å½•çš„åç§°ä¸ModelCheckpointç›‘æ§çš„åç§°ä¸åŒ¹é…")
    print("3. æ£€æŸ¥ç‚¹æ–‡ä»¶åæ ¼å¼å­—ç¬¦ä¸²æœ‰é—®é¢˜")
    
    print("\nğŸ”§ éªŒè¯å½“å‰è®­ç»ƒçŠ¶æ€:")
    print("ä»è¿›åº¦æ¡çœ‹åˆ°: val_mse=2.250")
    print("ä»æ–‡ä»¶åçœ‹åˆ°: val_mse=3.2939")
    print("2.250 < 3.2939ï¼Œåº”è¯¥è§¦å‘æ£€æŸ¥ç‚¹æ›´æ–°")
    print("ä½†æ˜¯æ–‡ä»¶æ²¡æœ‰æ›´æ–°ï¼Œè¯´æ˜æ£€æŸ¥ç‚¹æœºåˆ¶æœ‰é—®é¢˜")

def test_checkpoint_format():
    print("\nğŸ§ª æµ‹è¯•æ£€æŸ¥ç‚¹æ ¼å¼å­—ç¬¦ä¸²")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿæ£€æŸ¥ç‚¹æ–‡ä»¶åæ ¼å¼
    formats = [
        'stage1-best-epoch={epoch:02d}-val_mse={val_mse:.4f}',  # å½“å‰æ ¼å¼
        'stage1-best-epoch={epoch:02d}-mse={val_mse:.4f}',     # ä¿®å¤æ ¼å¼
        'stage1-best-{epoch:02d}-{val_mse:.4f}',               # ç®€åŒ–æ ¼å¼
    ]
    
    # æ¨¡æ‹ŸæŒ‡æ ‡å€¼
    epoch = 1
    val_mse = 2.250
    
    for fmt in formats:
        try:
            # æµ‹è¯•æ ¼å¼å­—ç¬¦ä¸²
            filename = fmt.format(epoch=epoch, val_mse=val_mse)
            print(f"âœ… æ ¼å¼: {fmt}")
            print(f"   ç»“æœ: {filename}")
        except Exception as e:
            print(f"âŒ æ ¼å¼: {fmt}")
            print(f"   é”™è¯¯: {e}")
        print()

def check_metric_logging():
    print("\nğŸ” æ£€æŸ¥æŒ‡æ ‡è®°å½•æœºåˆ¶")
    print("=" * 60)
    
    print("åœ¨ model_interface.py ä¸­æ£€æŸ¥ val_mse è®°å½•:")
    print("1. _update_metrics å‡½æ•°:")
    print("   - é€šè¿‡ metrics.update() æ›´æ–°æŒ‡æ ‡")
    print("   - é€šè¿‡ self.log() è®°å½•æŒ‡æ ‡")
    print("   - æŒ‡æ ‡åç§°: f'{stage}_{name}' -> 'val_mse'")
    
    print("\n2. validation_step å‡½æ•°:")
    print("   - è°ƒç”¨ _update_metrics('val', logits, target_genes)")
    print("   - åº”è¯¥è®°å½• val_mse æŒ‡æ ‡")
    
    print("\n3. ModelCheckpoint é…ç½®:")
    print("   - monitor='val_mse'")
    print("   - mode='min'")
    print("   - filename='stage1-best-epoch={epoch:02d}-val_mse={val_mse:.4f}'")
    
    print("\nğŸ”§ å¯èƒ½çš„é—®é¢˜:")
    print("1. æŒ‡æ ‡åç§°ä¸åŒ¹é…")
    print("2. æŒ‡æ ‡æ²¡æœ‰æ­£ç¡®è®°å½•åˆ° PyTorch Lightning")
    print("3. æ£€æŸ¥ç‚¹å›è°ƒæ²¡æœ‰æ­£ç¡®é…ç½®")

if __name__ == "__main__":
    analyze_checkpoint_issue()
    test_checkpoint_format()
    check_metric_logging()
    
    print("\nğŸ¯ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
    print("1. æ£€æŸ¥ self.log('val_mse', ...) æ˜¯å¦æ­£ç¡®æ‰§è¡Œ")
    print("2. ä¿®å¤æ£€æŸ¥ç‚¹æ–‡ä»¶åæ ¼å¼ï¼Œé¿å…é‡å¤çš„å­—æ®µå")
    print("3. ç¡®ä¿ ModelCheckpoint.monitor ä¸å®é™…è®°å½•çš„æŒ‡æ ‡åç§°ä¸€è‡´")
    print("4. æ·»åŠ è°ƒè¯•æ—¥å¿—ç¡®è®¤æŒ‡æ ‡å€¼æ˜¯å¦æ­£ç¡®ä¼ é€’ç»™æ£€æŸ¥ç‚¹å›è°ƒ") 