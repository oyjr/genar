#!/usr/bin/env python3
"""
æµ‹è¯•VAR-ST Paddingç­–ç•¥

éªŒè¯ä½¿ç”¨16Ã—16 paddingç­–ç•¥æ˜¯å¦è§£å†³äº†14Ã—14å°ºå¯¸è¿‡å°çš„é—®é¢˜
"""

import sys
import os
sys.path.append('src')

import torch
import torch.nn as nn
from typing import Dict, Any

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from model.VAR.gene_pseudo_image_adapter import GenePseudoImageAdapter
from model.VAR.VAR_ST_Complete import VAR_ST_Complete

def test_gene_adapter_padding():
    """æµ‹è¯•åŸºå› é€‚é…å™¨çš„paddingç­–ç•¥"""
    print("ğŸ§ª æµ‹è¯•åŸºå› é€‚é…å™¨ - Paddingç­–ç•¥")
    print("=" * 60)
    
    # åˆå§‹åŒ–é€‚é…å™¨ï¼ˆ196åŸºå›  â†’ 64Ã—64ï¼Œpaddingç­–ç•¥ï¼‰
    adapter = GenePseudoImageAdapter(
        num_genes=196,
        target_image_size=64,  # ğŸ”§ æ”¹ä¸º64Ã—64ï¼Œè§£å†³VQVAEä¸‹é‡‡æ ·é—®é¢˜
        normalize_method='layer_norm'
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 4
    gene_data = torch.randn(batch_size, 196)
    
    print(f"\nğŸ“Š æµ‹è¯•æ•°æ®:")
    print(f"   - è¾“å…¥åŸºå› : {gene_data.shape} (196ä¸ªåŸºå› )")
    print(f"   - æ•°æ®èŒƒå›´: [{gene_data.min():.3f}, {gene_data.max():.3f}]")
    
    # æµ‹è¯•è½¬æ¢
    try:
        # åŸºå›  â†’ ä¼ªå›¾åƒ
        pseudo_image = adapter.genes_to_pseudo_image(gene_data)
        print(f"\nâœ… è½¬æ¢æˆåŠŸ:")
        print(f"   - ä¼ªå›¾åƒ: {pseudo_image.shape}")
        print(f"   - å›¾åƒèŒƒå›´: [{pseudo_image.min():.3f}, {pseudo_image.max():.3f}]")
        
        # éªŒè¯paddingåŒºåŸŸ
        flattened = pseudo_image.view(batch_size, -1)
        padding_region = flattened[:, 196:]  # å–paddingéƒ¨åˆ†
        is_padding_zero = torch.allclose(padding_region, torch.zeros_like(padding_region), atol=1e-6)
        print(f"   - PaddingåŒºåŸŸä¸ºé›¶: {is_padding_zero}")
        print(f"   - Paddingç»Ÿè®¡: mean={padding_region.mean():.6f}, std={padding_region.std():.6f}")
        
        # ä¼ªå›¾åƒ â†’ åŸºå› 
        reconstructed_genes = adapter.pseudo_image_to_genes(pseudo_image)
        print(f"   - é‡å»ºåŸºå› : {reconstructed_genes.shape}")
        
        # éªŒè¯é‡å»ºå‡†ç¡®æ€§
        reconstruction_error = torch.abs(gene_data - reconstructed_genes)
        max_error = reconstruction_error.max()
        mean_error = reconstruction_error.mean()
        print(f"   - é‡å»ºè¯¯å·®: max={max_error:.2e}, mean={mean_error:.2e}")
        
        if max_error < 1e-5:
            print(f"   âœ… é‡å»ºå‡†ç¡®æ€§éªŒè¯é€šè¿‡")
        else:
            print(f"   âŒ é‡å»ºè¯¯å·®è¿‡å¤§")
            
        return True
        
    except Exception as e:
        print(f"âŒ é€‚é…å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_var_st_complete_padding():
    """æµ‹è¯•å®Œæ•´VAR-STæ¨¡å‹çš„paddingç­–ç•¥"""
    print("\nğŸš€ æµ‹è¯•VAR-ST Complete - Paddingç­–ç•¥")
    print("=" * 60)
    
    try:
        # æ¨¡å‹é…ç½®
        var_config = {
            'depth': 16,
            'embed_dim': 512,
            'num_heads': 8,
            'vocab_size': 1024
        }
        
        vqvae_config = {
            'z_channels': 256,
            'ch': 128,
            'ch_mult': [1, 1, 2, 2, 4],
            'num_res_blocks': 2,
            'attn_resolutions': [16],  # é€‚é…16Ã—16
            'vocab_size': 1024
        }
        
        # åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨64Ã—64 paddingç­–ç•¥ï¼‰
        model = VAR_ST_Complete(
            num_genes=196,
            spatial_size=64,  # ğŸ”§ å…³é”®ï¼šä½¿ç”¨64Ã—64ï¼Œè§£å†³VQVAEä¸‹é‡‡æ ·é—®é¢˜
            histology_feature_dim=512,
            var_config=var_config,
            vqvae_config=vqvae_config
        )
        
        print(f"\nâœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ!")
        print(f"   - å‚æ•°æ€»æ•°: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   - å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 2
        gene_expression = torch.randn(batch_size, 196)
        histology_features = torch.randn(batch_size, 512)
        
        print(f"\nğŸ“Š æµ‹è¯•æ¨ç†:")
        print(f"   - åŸºå› è¡¨è¾¾: {gene_expression.shape}")
        print(f"   - ç»„ç»‡å­¦ç‰¹å¾: {histology_features.shape}")
        
        # æµ‹è¯•æ¨ç†
        model.eval()
        with torch.no_grad():
            outputs = model.forward_training(
                gene_expression=gene_expression,
                histology_features=histology_features
            )
            
        print(f"   - è¾“å‡ºå½¢çŠ¶: {outputs['predictions'].shape}")
        print(f"   - è¾“å‡ºèŒƒå›´: [{outputs['predictions'].min():.3f}, {outputs['predictions'].max():.3f}]")
        print(f"   - æŸå¤±: {outputs['loss'].item():.4f}")
        print(f"   âœ… æ¨ç†æˆåŠŸï¼Œpaddingç­–ç•¥è§£å†³äº†å°ºå¯¸é™åˆ¶é—®é¢˜!")
        
        return True
        
    except Exception as e:
        print(f"âŒ VAR-STæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def show_padding_strategy_benefits():
    """å±•ç¤ºpaddingç­–ç•¥çš„ä¼˜åŠ¿"""
    print("\nğŸ¯ Paddingç­–ç•¥åˆ†æ")
    print("=" * 60)
    
    print("ğŸ“ˆ å¯¹æ¯”åˆ†æ:")
    print("   åŸå§‹æ–¹æ¡ˆ (14Ã—14):")
    print("     * æ€»ä½ç½®: 14Ã—14 = 196")
    print("     * åŸºå› æ•°é‡: 196")
    print("     * ç©ºé—´åˆ©ç”¨ç‡: 100%")
    print("     * âŒ é—®é¢˜: VARå¤šå±‚å·ç§¯åå°ºå¯¸è¿‡å°ï¼Œå¯¼è‡´ç»´åº¦é”™è¯¯")
    print()
    print("   Paddingæ–¹æ¡ˆ (64Ã—64):")
    print("     * æ€»ä½ç½®: 64Ã—64 = 4096")
    print("     * åŸºå› æ•°é‡: 196 + 3900 padding = 4096")
    print("     * ç©ºé—´åˆ©ç”¨ç‡: 4.8%")
    print("     * âœ… ä¼˜åŠ¿: ä¸ºVAR VQVAEæä¾›å……è¶³çš„ä¸‹é‡‡æ ·ç©ºé—´ (64â†’4)")
    print()
    
    print("ğŸ”§ æŠ€æœ¯ä¼˜åŠ¿:")
    print("   âœ… å…¼å®¹æ€§: æ”¯æŒæ ‡å‡†VARæ¶æ„ï¼Œæ— éœ€ä¿®æ”¹æ ¸å¿ƒä»£ç ")
    print("   âœ… ç¨³å®šæ€§: 64Ã—64â†’4Ã—4ç»è¿‡VARéªŒè¯ï¼Œæ”¯æŒ16å€ä¸‹é‡‡æ ·")
    print("   âœ… å¯æ‰©å±•æ€§: å¯ä»¥è½»æ¾æ”¯æŒæ›´å¤§çš„åŸºå› é›†åˆ")
    print("   âœ… ä¿¡æ¯ä¿ç•™: 196åŸºå› ä¿¡æ¯å®Œå…¨ä¿ç•™ï¼Œæ— æŸå¤±")
    print("   âœ… è®¡ç®—æ•ˆç‡: è™½ç„¶å¢åŠ å­˜å‚¨ï¼Œä½†è§£å†³äº†æ ¹æœ¬çš„å°ºå¯¸åŒ¹é…é—®é¢˜")
    print()
    
    print("ğŸ§¬ ç”Ÿç‰©å­¦æ„ä¹‰:")
    print("   âœ… é›¶paddingä¸å½±å“ç”Ÿç‰©å­¦è§£é‡Š")
    print("   âœ… 196åŸºå› çš„ç›¸å¯¹ä½ç½®å…³ç³»ä¿æŒä¸å˜")
    print("   âœ… å¤šå°ºåº¦åˆ†æä¾ç„¶æœ‰æ•ˆ")
    print("   âœ… å¯ä»¥é€šè¿‡æ©ç å¿½ç•¥paddingåŒºåŸŸ")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”¬ VAR-ST Paddingç­–ç•¥éªŒè¯")
    print("=" * 80)
    
    # å±•ç¤ºç­–ç•¥åˆ†æ
    show_padding_strategy_benefits()
    
    # æµ‹è¯•é€‚é…å™¨
    adapter_success = test_gene_adapter_padding()
    
    # æµ‹è¯•å®Œæ•´æ¨¡å‹
    model_success = test_var_st_complete_padding()
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print(f"   - åŸºå› é€‚é…å™¨: {'âœ… é€šè¿‡' if adapter_success else 'âŒ å¤±è´¥'}")
    print(f"   - VAR-STæ¨¡å‹: {'âœ… é€šè¿‡' if model_success else 'âŒ å¤±è´¥'}")
    
    if adapter_success and model_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! Paddingç­–ç•¥æˆåŠŸè§£å†³äº†VARçš„å°ºå¯¸é™åˆ¶é—®é¢˜!")
        print("ğŸ’¡ å»ºè®®: å¯ä»¥å¼€å§‹ä½¿ç”¨16Ã—16é…ç½®è¿›è¡Œè®­ç»ƒ")
    else:
        print("\nğŸ˜ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    return adapter_success and model_success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 