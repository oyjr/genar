#!/usr/bin/env python3
"""
Two-Stage VAR-ST å®Œæ•´æ¨ç†å’Œè¯„ä¼°è„šæœ¬

æ­¤è„šæœ¬å®ç°ï¼š
1. åŠ è½½Stage 1 (VQVAE) å’Œ Stage 2 (VAR) æ£€æŸ¥ç‚¹
2. æ„å»ºå®Œæ•´çš„ä¸¤é˜¶æ®µæ¨¡å‹
3. è¿›è¡Œç«¯åˆ°ç«¯çš„åŸºå› è¡¨è¾¾é¢„æµ‹æ¨ç†
4. è®¡ç®—å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡ (PCC, MSE, MAE, RVDç­‰)
5. ä¿å­˜æ¨ç†ç»“æœå’Œè¯„ä¼°æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
python two_stage_complete_inference.py \
    --stage1_ckpt logs/PRAD/TWO_STAGE_VAR_ST/stage1-best-epoch=epoch=143-val_mse=val_mse=0.5353.ckpt \
    --stage2_ckpt logs/PRAD/TWO_STAGE_VAR_ST/stage2-best-epoch=epoch=03-val_acc=val_accuracy=0.8263.ckpt \
    --dataset PRAD \
    --mode test \
    --save_results
"""

import sys
import os
sys.path.insert(0, 'src')

import torch
import numpy as np
import argparse
from typing import Dict, Tuple, Optional
import matplotlib.pyplot as plt
import pandas as pd
from datetime import datetime
import json

from model.VAR.two_stage_var_st import TwoStageVARST
from model.model_interface import ModelInterface
from dataset.data_interface import DataInterface
from main import DATASETS, ENCODER_FEATURE_DIMS
from addict import Dict as AddictDict


class TwoStageCompleteInference:
    """ä¸¤é˜¶æ®µVAR-STå®Œæ•´æ¨ç†ç±»"""
    
    def __init__(
        self, 
        stage1_ckpt_path: str,
        stage2_ckpt_path: str,
        device: str = 'cuda'
    ):
        """
        åˆå§‹åŒ–ä¸¤é˜¶æ®µæ¨ç†å™¨
        
        Args:
            stage1_ckpt_path: Stage 1 VQVAEæ£€æŸ¥ç‚¹è·¯å¾„
            stage2_ckpt_path: Stage 2 VARæ£€æŸ¥ç‚¹è·¯å¾„  
            device: è®¡ç®—è®¾å¤‡
        """
        self.stage1_ckpt_path = stage1_ckpt_path
        self.stage2_ckpt_path = stage2_ckpt_path
        self.device = device
        self.model = None
        self.config = None
        
        print(f"ğŸš€ åˆå§‹åŒ–ä¸¤é˜¶æ®µVAR-STæ¨ç†å™¨")
        print(f"   - Stage 1 VQVAE: {stage1_ckpt_path}")
        print(f"   - Stage 2 VAR: {stage2_ckpt_path}")
        print(f"   - è®¾å¤‡: {device}")
    
    def load_model(self) -> TwoStageVARST:
        """åŠ è½½å®Œæ•´çš„ä¸¤é˜¶æ®µæ¨¡å‹"""
        print(f"\nğŸ”„ åŠ è½½ä¸¤é˜¶æ®µæ¨¡å‹...")
        
        # 1. ä»Stage 2æ£€æŸ¥ç‚¹è·å–é…ç½®ä¿¡æ¯
        print(f"   æ­¥éª¤1: ä»Stage 2æ£€æŸ¥ç‚¹è·å–é…ç½®...")
        stage2_checkpoint = torch.load(self.stage2_ckpt_path, map_location='cpu')
        
        # ä»hyperparametersè·å–é…ç½®
        if 'hyper_parameters' in stage2_checkpoint and 'config' in stage2_checkpoint['hyper_parameters']:
            self.config = stage2_checkpoint['hyper_parameters']['config']
            model_config = self.config.get('MODEL', {})
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            print("   âš ï¸  æœªæ‰¾åˆ°å®Œæ•´é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
            model_config = {
                'num_genes': 200,
                'histology_feature_dim': 1024,
                'spatial_coord_dim': 2
            }
        
        # 2. åˆ›å»ºæ¨¡å‹å®ä¾‹
        print(f"   æ­¥éª¤2: åˆ›å»ºæ¨¡å‹å®ä¾‹...")
        self.model = TwoStageVARST(
            num_genes=model_config.get('num_genes', 200),
            histology_feature_dim=model_config.get('histology_feature_dim', 1024),
            spatial_coord_dim=model_config.get('spatial_coord_dim', 2),
            current_stage=1,  # å…ˆè®¾ç½®ä¸ºStage 1
            device=self.device
        )
        
        # 3. åŠ è½½Stage 1æƒé‡
        print(f"   æ­¥éª¤3: åŠ è½½Stage 1 VQVAEæƒé‡...")
        stage1_checkpoint = torch.load(self.stage1_ckpt_path, map_location='cpu')
        
        # æå–Stage 1çš„æ¨¡å‹æƒé‡
        stage1_state_dict = {}
        for key, value in stage1_checkpoint['state_dict'].items():
            if key.startswith('model.'):
                # ç§»é™¤Lightningçš„å‰ç¼€
                new_key = key[6:]  # å»æ‰'model.'
                stage1_state_dict[new_key] = value
        
        # åªåŠ è½½Stage 1 VQVAEçš„æƒé‡
        stage1_vqvae_state_dict = {}
        for key, value in stage1_state_dict.items():
            if key.startswith('stage1_vqvae.'):
                new_key = key[13:]  # å»æ‰'stage1_vqvae.'
                stage1_vqvae_state_dict[new_key] = value
        
        self.model.stage1_vqvae.load_state_dict(stage1_vqvae_state_dict, strict=True)
        print(f"     âœ… Stage 1 VQVAEæƒé‡åŠ è½½å®Œæˆ")
        
        # 4. åˆ‡æ¢åˆ°Stage 2å¹¶åŠ è½½æƒé‡
        print(f"   æ­¥éª¤4: åˆ‡æ¢åˆ°Stage 2å¹¶åŠ è½½VARæƒé‡...")
        self.model.current_stage = 2
        self.model._set_vqvae_trainable(False)  # å†»ç»“VQVAE
        
        # åŠ è½½Stage 2æƒé‡
        stage2_state_dict = {}
        for key, value in stage2_checkpoint['state_dict'].items():
            if key.startswith('model.'):
                new_key = key[6:]  # å»æ‰'model.'
                stage2_state_dict[new_key] = value
        
        # åŠ è½½Stage 2 VARçš„æƒé‡
        stage2_var_state_dict = {}
        for key, value in stage2_state_dict.items():
            if key.startswith('stage2_var.'):
                new_key = key[11:]  # å»æ‰'stage2_var.'
                stage2_var_state_dict[new_key] = value
        
        self.model.stage2_var.load_state_dict(stage2_var_state_dict, strict=True)
        
        # åŠ è½½æ¡ä»¶å¤„ç†å™¨æƒé‡
        condition_processor_state_dict = {}
        for key, value in stage2_state_dict.items():
            if key.startswith('condition_processor.'):
                new_key = key[20:]  # å»æ‰'condition_processor.'
                condition_processor_state_dict[new_key] = value
        
        if condition_processor_state_dict:
            self.model.condition_processor.load_state_dict(condition_processor_state_dict, strict=True)
            print(f"     âœ… æ¡ä»¶å¤„ç†å™¨æƒé‡åŠ è½½å®Œæˆ")
        
        print(f"     âœ… Stage 2 VARæƒé‡åŠ è½½å®Œæˆ")
        
        # 5. è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
        self.model = self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… ä¸¤é˜¶æ®µæ¨¡å‹åŠ è½½å®Œæˆï¼")
        print(f"   - æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"   - å¯è®­ç»ƒå‚æ•°é‡: {sum(p.numel() for p in self.model.parameters() if p.requires_grad):,}")
        
        return self.model
    
    def predict_batch(
        self, 
        histology_features: torch.Tensor,
        spatial_coords: torch.Tensor,
        temperature: float = 1.0,
        top_k: Optional[int] = 50,
        top_p: Optional[float] = 0.9
    ) -> Dict[str, torch.Tensor]:
        """
        å¯¹ä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œé¢„æµ‹
        
        Args:
            histology_features: [B, 1024] ç»„ç»‡å­¦ç‰¹å¾
            spatial_coords: [B, 2] ç©ºé—´åæ ‡
            temperature: é‡‡æ ·æ¸©åº¦
            top_k: Top-ké‡‡æ ·
            top_p: Nucleusé‡‡æ ·
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        with torch.no_grad():
            results = self.model.inference(
                histology_features=histology_features,
                spatial_coords=spatial_coords,
                temperature=temperature,
                top_k=top_k,
                top_p=top_p
            )
        return results
    
    def evaluate_on_dataloader(
        self,
        dataloader,
        max_batches: Optional[int] = None,
        temperature: float = 1.0,
        top_k: Optional[int] = 50,
        top_p: Optional[float] = 0.9
    ) -> Dict[str, float]:
        """
        åœ¨æ•°æ®åŠ è½½å™¨ä¸Šè¿›è¡Œè¯„ä¼°
        
        Args:
            dataloader: æ•°æ®åŠ è½½å™¨
            max_batches: æœ€å¤§æ‰¹æ¬¡æ•°ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
            temperature: é‡‡æ ·æ¸©åº¦
            top_k: Top-ké‡‡æ ·
            top_p: Nucleusé‡‡æ ·
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        print(f"\nğŸ§¬ å¼€å§‹æ¨¡å‹è¯„ä¼°...")
        print(f"   - æ•°æ®æ‰¹æ¬¡æ•°: {len(dataloader) if max_batches is None else min(max_batches, len(dataloader))}")
        print(f"   - é‡‡æ ·å‚æ•°: temp={temperature}, top_k={top_k}, top_p={top_p}")
        
        all_predictions = []
        all_targets = []
        
        self.model.eval()
        
        for batch_idx, batch in enumerate(dataloader):
            if max_batches is not None and batch_idx >= max_batches:
                break
                
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            histology_features = batch['img'].to(self.device)      # [B, 1024]
            spatial_coords = batch['positions'].to(self.device)   # [B, 2]
            target_genes = batch['target_genes'].to(self.device)  # [B, 200]
            
            # è¿›è¡Œé¢„æµ‹
            results = self.predict_batch(
                histology_features=histology_features,
                spatial_coords=spatial_coords,
                temperature=temperature,
                top_k=top_k,
                top_p=top_p
            )
            
            # æ”¶é›†ç»“æœ
            predictions = results['predicted_gene_expression']  # [B, 200]
            all_predictions.append(predictions.cpu())
            all_targets.append(target_genes.cpu())
            
            if (batch_idx + 1) % 10 == 0:
                print(f"   å·²å¤„ç† {batch_idx + 1} ä¸ªæ‰¹æ¬¡...")
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_predictions = torch.cat(all_predictions, dim=0)  # [N, 200]
        all_targets = torch.cat(all_targets, dim=0)          # [N, 200]
        
        print(f"   æ€»æ ·æœ¬æ•°: {all_predictions.shape[0]}")
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics = self._calculate_evaluation_metrics(
            all_targets.numpy(), 
            all_predictions.numpy()
        )
        
        return metrics, all_predictions.numpy(), all_targets.numpy()
    
    def _calculate_evaluation_metrics(
        self, 
        y_true: np.ndarray, 
        y_pred: np.ndarray
    ) -> Dict[str, float]:
        """
        è®¡ç®—å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡
        
        Args:
            y_true: [N, 200] çœŸå®åŸºå› è¡¨è¾¾
            y_pred: [N, 200] é¢„æµ‹åŸºå› è¡¨è¾¾
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        from scipy.stats import pearsonr
        
        # åŸºç¡€å›å½’æŒ‡æ ‡
        mse = np.mean((y_true - y_pred) ** 2)
        mae = np.mean(np.abs(y_true - y_pred))
        rmse = np.sqrt(mse)
        
        # è®¡ç®—æ¯ä¸ªåŸºå› çš„çš®å°”é€Šç›¸å…³ç³»æ•°
        gene_correlations = []
        for gene_idx in range(y_true.shape[1]):
            true_gene = y_true[:, gene_idx]
            pred_gene = y_pred[:, gene_idx]
            
            # è·³è¿‡æ–¹å·®ä¸º0çš„åŸºå› 
            if np.var(true_gene) == 0 or np.var(pred_gene) == 0:
                gene_correlations.append(0.0)
            else:
                corr, _ = pearsonr(true_gene, pred_gene)
                gene_correlations.append(corr if not np.isnan(corr) else 0.0)
        
        gene_correlations = np.array(gene_correlations)
        
        # PCCæŒ‡æ ‡
        pcc_mean = np.mean(gene_correlations)
        pcc_top10 = np.mean(np.sort(gene_correlations)[-10:])  # Top 10
        pcc_top50 = np.mean(np.sort(gene_correlations)[-50:])  # Top 50
        pcc_top200 = np.mean(gene_correlations)                # All genes
        
        # RVD (Relative Variance Difference)
        true_var = np.var(y_true, axis=0)
        pred_var = np.var(y_pred, axis=0)
        rvd = np.mean(np.abs(true_var - pred_var) / (true_var + 1e-8))
        
        # RÂ²
        ss_res = np.sum((y_true - y_pred) ** 2)
        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0
        
        metrics = {
            'MSE': mse,
            'MAE': mae,
            'RMSE': rmse,
            'PCC-Mean': pcc_mean,
            'PCC-10': pcc_top10,
            'PCC-50': pcc_top50,
            'PCC-200': pcc_top200,
            'RVD': rvd,
            'R2': r2,
            'correlations': gene_correlations  # ä¿å­˜æ‰€æœ‰åŸºå› çš„ç›¸å…³æ€§
        }
        
        return metrics
    
    def print_evaluation_results(self, metrics: Dict[str, float], prefix: str = ""):
        """æ‰“å°è¯„ä¼°ç»“æœ"""
        print(f"\nğŸ“Š {prefix}è¯„ä¼°ç»“æœ:")
        print("=" * 50)
        print(f"ğŸ”¹ å›å½’æŒ‡æ ‡:")
        print(f"   MSE:  {metrics['MSE']:.6f}")
        print(f"   MAE:  {metrics['MAE']:.6f}")
        print(f"   RMSE: {metrics['RMSE']:.6f}")
        print(f"   RÂ²:   {metrics['R2']:.6f}")
        
        print(f"\nğŸ”¹ ç›¸å…³æ€§æŒ‡æ ‡:")
        print(f"   PCC-Mean: {metrics['PCC-Mean']:.6f}")
        print(f"   PCC-10:   {metrics['PCC-10']:.6f}")
        print(f"   PCC-50:   {metrics['PCC-50']:.6f}")
        print(f"   PCC-200:  {metrics['PCC-200']:.6f}")
        
        print(f"\nğŸ”¹ åˆ†å¸ƒæŒ‡æ ‡:")
        print(f"   RVD: {metrics['RVD']:.6f}")
        
        # ç›¸å…³æ€§åˆ†å¸ƒç»Ÿè®¡
        correlations = metrics['correlations']
        print(f"\nğŸ”¹ åŸºå› ç›¸å…³æ€§åˆ†å¸ƒ:")
        print(f"   æ­£ç›¸å…³ (>0.1): {np.sum(correlations > 0.1)}/200 ({np.sum(correlations > 0.1)/200*100:.1f}%)")
        print(f"   ä¸­ç­‰ç›¸å…³ (>0.3): {np.sum(correlations > 0.3)}/200 ({np.sum(correlations > 0.3)/200*100:.1f}%)")
        print(f"   å¼ºç›¸å…³ (>0.5): {np.sum(correlations > 0.5)}/200 ({np.sum(correlations > 0.5)/200*100:.1f}%)")
    
    def save_results(
        self, 
        metrics: Dict[str, float], 
        predictions: np.ndarray,
        targets: np.ndarray,
        save_dir: str = './inference_results'
    ):
        """ä¿å­˜æ¨ç†ç»“æœ"""
        os.makedirs(save_dir, exist_ok=True)
        
        # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
        metrics_to_save = {}
        for k, v in metrics.items():
            if k != 'correlations':
                # å°†numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
                if isinstance(v, np.floating):
                    metrics_to_save[k] = float(v)
                elif isinstance(v, np.integer):
                    metrics_to_save[k] = int(v)
                else:
                    metrics_to_save[k] = v
        
        with open(os.path.join(save_dir, 'evaluation_metrics.json'), 'w') as f:
            json.dump(metrics_to_save, f, indent=2)
        
        # ä¿å­˜åŸºå› ç›¸å…³æ€§
        np.save(os.path.join(save_dir, 'gene_correlations.npy'), metrics['correlations'])
        
        # ä¿å­˜é¢„æµ‹å’Œç›®æ ‡
        np.save(os.path.join(save_dir, 'predictions.npy'), predictions)
        np.save(os.path.join(save_dir, 'targets.npy'), targets)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with open(os.path.join(save_dir, 'evaluation_report.txt'), 'w') as f:
            f.write("Two-Stage VAR-ST è¯„ä¼°æŠ¥å‘Š\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {timestamp}\n")
            f.write(f"Stage 1 æ£€æŸ¥ç‚¹: {self.stage1_ckpt_path}\n")
            f.write(f"Stage 2 æ£€æŸ¥ç‚¹: {self.stage2_ckpt_path}\n")
            f.write("\nè¯„ä¼°æŒ‡æ ‡:\n")
            for key, value in metrics_to_save.items():
                f.write(f"  {key}: {value:.6f}\n")
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {save_dir}")


def main():
    parser = argparse.ArgumentParser(description='Two-Stage VAR-ST å®Œæ•´æ¨ç†å’Œè¯„ä¼°')
    parser.add_argument('--stage1_ckpt', type=str, required=True,
                       help='Stage 1 VQVAEæ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--stage2_ckpt', type=str, required=True,
                       help='Stage 2 VARæ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--dataset', type=str, required=True,
                       choices=list(DATASETS.keys()),
                       help='æ•°æ®é›†åç§°')
    parser.add_argument('--mode', type=str, default='test',
                       choices=['val', 'test'],
                       help='è¯„ä¼°æ¨¡å¼ï¼šéªŒè¯é›†æˆ–æµ‹è¯•é›†')
    parser.add_argument('--device', type=str, default='cuda',
                       choices=['cuda', 'cpu'], help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--max_batches', type=int, default=None,
                       help='æœ€å¤§æ‰¹æ¬¡æ•°ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰')
    parser.add_argument('--temperature', type=float, default=1.0,
                       help='é‡‡æ ·æ¸©åº¦')
    parser.add_argument('--top_k', type=int, default=50,
                       help='Top-ké‡‡æ ·å‚æ•°')
    parser.add_argument('--top_p', type=float, default=0.9,
                       help='Nucleusé‡‡æ ·å‚æ•°')
    parser.add_argument('--save_results', action='store_true',
                       help='æ˜¯å¦ä¿å­˜è¯¦ç»†ç»“æœ')
    parser.add_argument('--save_dir', type=str, default='./inference_results',
                       help='ç»“æœä¿å­˜ç›®å½•')
    
    args = parser.parse_args()
    
    print("ğŸš€ Two-Stage VAR-ST å®Œæ•´æ¨ç†å’Œè¯„ä¼°")
    print("=" * 60)
    
    # æ£€æŸ¥è®¾å¤‡
    device = args.device
    if device == 'cuda' and not torch.cuda.is_available():
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        device = 'cpu'
    
    try:
        # 1. åˆå§‹åŒ–æ¨ç†å™¨
        inferencer = TwoStageCompleteInference(
            stage1_ckpt_path=args.stage1_ckpt,
            stage2_ckpt_path=args.stage2_ckpt,
            device=device
        )
        
        # 2. åŠ è½½æ¨¡å‹
        model = inferencer.load_model()
        
        # 3. å‡†å¤‡æ•°æ®
        print(f"\nğŸ“Š å‡†å¤‡æ•°æ®...")
        dataset_info = DATASETS[args.dataset]
        
        # æ„å»ºç®€åŒ–é…ç½®
        config = AddictDict({
            'data_path': dataset_info['path'],
            'slide_val': dataset_info['val_slides'],
            'slide_test': dataset_info['test_slides'],
            'encoder_name': dataset_info['recommended_encoder'],
            'use_augmented': False,  # æ¨ç†æ—¶ä¸ä½¿ç”¨æ•°æ®å¢å¼º
            'expand_augmented': False,
            'expr_name': args.dataset,  # æ·»åŠ ç¼ºå¤±çš„å­—æ®µ
            'MODEL': AddictDict({  # ä¿®å¤ï¼šä½¿ç”¨MODELç»“æ„
                'model_name': 'TWO_STAGE_VAR_ST'
            }),
            'DATA': {
                'normalize': True,
                f'{args.mode}_dataloader': {
                    'batch_size': args.batch_size,
                    'num_workers': 4,
                    'pin_memory': True,
                    'shuffle': False,
                    'persistent_workers': True
                }
            }
        })
        
        # åˆ›å»ºæ•°æ®æ¥å£
        data_interface = DataInterface(config)
        data_interface.setup(stage=args.mode)  # æ·»åŠ ï¼šè°ƒç”¨setupæ–¹æ³•
        
        if args.mode == 'val':
            dataloader = data_interface.val_dataloader()
        else:
            dataloader = data_interface.test_dataloader()
        
        print(f"   - æ•°æ®é›†: {args.dataset}")
        print(f"   - æ¨¡å¼: {args.mode}")
        print(f"   - æ‰¹æ¬¡å¤§å°: {args.batch_size}")
        print(f"   - æ€»æ‰¹æ¬¡æ•°: {len(dataloader)}")
        
        # 4. è¿›è¡Œè¯„ä¼°
        metrics, predictions, targets = inferencer.evaluate_on_dataloader(
            dataloader=dataloader,
            max_batches=args.max_batches,
            temperature=args.temperature,
            top_k=args.top_k,
            top_p=args.top_p
        )
        
        # 5. æ‰“å°ç»“æœ
        inferencer.print_evaluation_results(metrics, f"{args.dataset} {args.mode.upper()}")
        
        # 6. ä¿å­˜ç»“æœ
        if args.save_results:
            inferencer.save_results(metrics, predictions, targets, args.save_dir)
        
        print(f"\nâœ… æ¨ç†å’Œè¯„ä¼°å®Œæˆï¼")
        print(f"ğŸ¯ å…³é”®æŒ‡æ ‡:")
        print(f"   - PCC-Mean: {metrics['PCC-Mean']:.4f}")
        print(f"   - MSE: {metrics['MSE']:.4f}")
        print(f"   - MAE: {metrics['MAE']:.4f}")
        
    except Exception as e:
        print(f"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 