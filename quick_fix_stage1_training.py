#!/usr/bin/env python3
"""
å¿«é€Ÿä¿®å¤Stage 1è®­ç»ƒ - è§£å†³Codebook Collapse

æœ€å°åŒ–ä¿®æ”¹ï¼Œæœ€å¤§åŒ–æ•ˆæœçš„æ–¹æ¡ˆï¼š
1. è°ƒæ•´å…³é”®è®­ç»ƒå‚æ•°
2. ä¿®æ”¹ä¸»è®­ç»ƒè„šæœ¬çš„è°ƒç”¨æ–¹å¼
3. ä¸æ”¹å˜ç°æœ‰æ¶æ„ï¼Œåªä¼˜åŒ–è®­ç»ƒç­–ç•¥
"""

import os
import sys

# å¿«é€Ÿä¿®å¤çš„è®­ç»ƒå‘½ä»¤
QUICK_FIX_COMMAND = """
python src/main.py \\
    --dataset PRAD \\
    --model TWO_STAGE_VAR_ST \\
    --training_stage 1 \\
    --epochs 200 \\
    --batch_size 128 \\
    --learning_rate 3e-4 \\
    --gpus 1 \\
    --additional_args '{
        "MODEL": {
            "beta": 1.0,
            "hierarchical_loss_weight": 0.2,
            "vq_loss_weight": 0.5,
            "use_ema_update": true,
            "ema_decay": 0.99,
            "restart_unused_codes": true,
            "restart_interval": 10
        },
        "OPTIMIZER": {
            "name": "AdamW",
            "weight_decay": 1e-5,
            "gradient_clip_val": 1.0
        },
        "SCHEDULER": {
            "name": "cosine_with_warmup",
            "warmup_epochs": 20,
            "min_lr": 1e-5
        }
    }'
"""

def print_quick_fix_guide():
    """æ‰“å°å¿«é€Ÿä¿®å¤æŒ‡å—"""
    print("ğŸš€ Stage 1 Codebook Collapseå¿«é€Ÿä¿®å¤æ–¹æ¡ˆ")
    print("=" * 60)
    
    print("\nğŸ“Š é—®é¢˜è¯Šæ–­ç¡®è®¤:")
    print("   - Globalå°ºåº¦: ä»…2ä¸ªtokens/4096 (åˆ©ç”¨ç‡0.05%)")
    print("   - Pathwayå°ºåº¦: ä»…2ä¸ªtokens/4096 (åˆ©ç”¨ç‡0.05%)")  
    print("   - Moduleå°ºåº¦: ä»…3ä¸ªtokens/4096 (åˆ©ç”¨ç‡0.07%)")
    print("   - Individualå°ºåº¦: ä»…4ä¸ªtokens/4096 (åˆ©ç”¨ç‡0.10%)")
    print("   âŒ è¿™æ˜¯ä¸¥é‡çš„Codebook Collapseï¼")
    
    print("\nğŸ”§ å…³é”®å‚æ•°ä¿®æ”¹:")
    print("   1. Beta: 0.25 â†’ 1.0 (4å€commitment lossæƒé‡)")
    print("   2. Learning Rate: é»˜è®¤ â†’ 3e-4 (æé«˜å­¦ä¹ ç‡)")
    print("   3. Batch Size: 256 â†’ 128 (å¢åŠ æ›´æ–°é¢‘ç‡)")
    print("   4. VQ Loss Weight: 0.25 â†’ 0.5 (å¼ºåŒ–é‡åŒ–å­¦ä¹ )")
    print("   5. æ·»åŠ EMAæ›´æ–°å’Œä»£ç é‡å¯æœºåˆ¶")
    
    print(f"\nğŸš€ æ¨èè®­ç»ƒå‘½ä»¤:")
    print(QUICK_FIX_COMMAND)
    
    print("\nğŸ“ˆ é¢„æœŸæ”¹å–„:")
    print("   - Codebookåˆ©ç”¨ç‡æå‡åˆ°10-30%")
    print("   - Tokenå¤šæ ·æ€§æ˜¾è‘—å¢åŠ ")
    print("   - æ¨ç†ç»“æœå›å½’æ­£å¸¸èŒƒå›´")
    
    print("\nâ° é¢„è®¡è®­ç»ƒæ—¶é—´:")
    print("   - çº¦200 epochsï¼Œæ ¹æ®GPUæ€§èƒ½çº¦4-8å°æ—¶")
    print("   - å»ºè®®æ¯20ä¸ªepochæ£€æŸ¥ä¸€æ¬¡åˆ©ç”¨ç‡")

def create_improved_main_args():
    """åˆ›å»ºæ”¹è¿›çš„ä¸»è®­ç»ƒå‚æ•°"""
    return {
        'dataset': 'PRAD',
        'model': 'TWO_STAGE_VAR_ST',
        'training_stage': 1,
        'epochs': 200,
        'batch_size': 128,
        'learning_rate': 3e-4,
        'gpus': 1,
        
        # ğŸ”§ å…³é”®æ”¹è¿›å‚æ•°
        'model_config_overrides': {
            'vqvae_config': {
                'vocab_size': 4096,
                'embed_dim': 128,
                'beta': 1.0,  # ğŸ”§ å…³é”®ï¼š4å€commitment lossæƒé‡
                'hierarchical_loss_weight': 0.2,  # ğŸ”§ å¢å¼ºåˆ†å±‚å­¦ä¹ 
                'vq_loss_weight': 0.5,  # ğŸ”§ å¼ºåŒ–VQå­¦ä¹ 
            }
        },
        
        'optimizer_config': {
            'name': 'AdamW',
            'lr': 3e-4,  # ğŸ”§ æé«˜å­¦ä¹ ç‡
            'weight_decay': 1e-5,
            'gradient_clip_val': 1.0  # ğŸ”§ æ¢¯åº¦è£å‰ª
        },
        
        'scheduler_config': {
            'name': 'cosine_with_warmup',
            'warmup_epochs': 20,  # ğŸ”§ é•¿é¢„çƒ­
            'min_lr': 1e-5
        }
    }

# ========================================
# é˜¶æ®µæ€§è§£å†³æ–¹æ¡ˆ
# ========================================

def print_staged_solution():
    """æ‰“å°åˆ†é˜¶æ®µè§£å†³æ–¹æ¡ˆ"""
    print("\nğŸ¯ åˆ†é˜¶æ®µè§£å†³æ–¹æ¡ˆè·¯çº¿å›¾")
    print("=" * 50)
    
    print("\nã€é˜¶æ®µ1 - ç«‹å³å®æ–½ã€‘å‚æ•°ä¼˜åŒ– (æ¨è)")
    print("   ä¿®æ”¹å†…å®¹: åªæ”¹è®­ç»ƒå‚æ•°ï¼Œä¸åŠ¨æ¶æ„")
    print("   å®æ–½éš¾åº¦: â­ (Very Easy)")
    print("   é¢„æœŸæ•ˆæœ: â­â­â­ (High Impact)")
    print("   æ—¶é—´æˆæœ¬: 4-8å°æ—¶é‡æ–°è®­ç»ƒ")
    print("   é£é™©: æä½")
    
    print("\nã€é˜¶æ®µ2 - å¦‚æœé˜¶æ®µ1æ•ˆæœä¸ä½³ã€‘æ¶æ„æ”¹è¿›")
    print("   ä¿®æ”¹å†…å®¹: æ›´æ·±ç¼–ç å™¨+EMAæ›´æ–°+ä»£ç é‡å¯")
    print("   å®æ–½éš¾åº¦: â­â­ (Easy)")
    print("   é¢„æœŸæ•ˆæœ: â­â­â­â­ (Very High)")
    print("   æ—¶é—´æˆæœ¬: 1-2å¤©å¼€å‘+é‡æ–°è®­ç»ƒ")
    print("   é£é™©: ä¸­ç­‰")
    
    print("\nã€é˜¶æ®µ3 - å¦‚æœå‰ä¸¤é˜¶æ®µæ— æ•ˆã€‘æ›¿æ¢é‡åŒ–æ–¹æ³•")
    print("   ä¿®æ”¹å†…å®¹: ä½¿ç”¨FSQæˆ–Group Quantization")
    print("   å®æ–½éš¾åº¦: â­â­â­ (Medium)")
    print("   é¢„æœŸæ•ˆæœ: â­â­â­â­â­ (Excellent)")
    print("   æ—¶é—´æˆæœ¬: 3-5å¤©å¼€å‘+é‡æ–°è®­ç»ƒ")
    print("   é£é™©: è¾ƒé«˜(éœ€è¦å¤§å¹…æ”¹åŠ¨)")

def print_monitoring_tips():
    """æ‰“å°ç›‘æ§å»ºè®®"""
    print("\nğŸ“Š è®­ç»ƒç›‘æ§è¦ç‚¹")
    print("=" * 30)
    
    print("å…³é”®æŒ‡æ ‡ç›‘æ§:")
    print("   1. Codebookåˆ©ç”¨ç‡ (æ¯ä¸ªepoch)")
    print("   2. VQ Lossè¶‹åŠ¿ (åº”è¯¥é€æ¸ä¸‹é™)")
    print("   3. Reconstruction Loss (ä¸»è¦æŒ‡æ ‡)")
    print("   4. Tokenåˆ†å¸ƒç†µ (è¶Šé«˜è¶Šå¥½)")
    
    print("\næ—©æœŸåœæ­¢æ¡ä»¶:")
    print("   âœ… åˆ©ç”¨ç‡>10% ä¸”ç¨³å®š")
    print("   âœ… VQ Lossæ”¶æ•›")
    print("   âœ… é‡å»ºè´¨é‡æ»¡æ„")
    
    print("\nå¼‚å¸¸ä¿¡å·:")
    print("   âŒ åˆ©ç”¨ç‡æŒç»­<5%")
    print("   âŒ VQ Lossä¸ä¸‹é™æˆ–ä¸Šå‡")
    print("   âŒ æŸäº›å°ºåº¦tokenså®Œå…¨ç›¸åŒ")

if __name__ == "__main__":
    print_quick_fix_guide()
    print_staged_solution()
    print_monitoring_tips()
    
    print("\nğŸ¯ ç«‹å³è¡ŒåŠ¨å»ºè®®:")
    print("   1. å…ˆå°è¯•é˜¶æ®µ1çš„å‚æ•°ä¼˜åŒ–æ–¹æ¡ˆ")
    print("   2. æ¯20ä¸ªepochæ£€æŸ¥tokenå¤šæ ·æ€§")
    print("   3. å¦‚æœ100ä¸ªepochååˆ©ç”¨ç‡ä»<5%ï¼Œè€ƒè™‘é˜¶æ®µ2")
    print("   4. è®°å½•è®­ç»ƒæ—¥å¿—ï¼Œä¾¿äºåç»­åˆ†æ") 