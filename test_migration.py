#!/usr/bin/env python3
"""
MFBPé¡¹ç›®æ•°æ®ç»“æ„è¿ç§»æµ‹è¯•è„šæœ¬

æµ‹è¯•ä»åŸå§‹HESTæ ¼å¼åˆ°æ–°hest1k_datasetsæ ¼å¼çš„è¿ç§»æ˜¯å¦æˆåŠŸ
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path

# ç¡®ä¿å¯¼å…¥é¡¹ç›®ç›®å½•ä¸‹çš„æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(current_dir, 'src')
sys.path.insert(0, src_dir)

def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¿…è¦çš„æ¨¡å—å¯¼å…¥"""
    print("ğŸ” æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    
    try:
        from dataset import STDataset, DataInterface
        print("âœ… æ•°æ®é›†æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from model import ModelInterface
        print("âœ… æ¨¡å‹æ¥å£å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ¥å£å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from model.MFBP.MFBP import MFBP
        print("âœ… MFBPæ¨¡å‹å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ MFBPæ¨¡å‹å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def test_stdataset_init():
    """æµ‹è¯•STDatasetç±»çš„åˆå§‹åŒ–"""
    print("\nğŸ” æµ‹è¯•STDatasetåˆå§‹åŒ–...")
    
    # æ¨¡æ‹Ÿæ–°çš„æ•°æ®æ ¼å¼
    test_data_path = "/tmp/test_hest1k_datasets/PRAD/"
    test_processed_dir = f"{test_data_path}processed_data"
    test_st_dir = f"{test_data_path}st"
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•å’Œæ–‡ä»¶
    os.makedirs(test_processed_dir, exist_ok=True)
    os.makedirs(test_st_dir, exist_ok=True)
    
    # åˆ›å»ºåŸºå› åˆ—è¡¨æ–‡ä»¶
    gene_list_file = f"{test_processed_dir}/selected_gene_list.txt"
    with open(gene_list_file, 'w') as f:
        for i in range(200):
            f.write(f"GENE_{i:03d}\n")
    
    # åˆ›å»ºslideåˆ—è¡¨æ–‡ä»¶
    slide_list_file = f"{test_processed_dir}/all_slide_lst.txt"
    with open(slide_list_file, 'w') as f:
        slides = ["SPA154", "SPA153", "SPA152", "SPA151", "SPA150"]
        for slide in slides:
            f.write(f"{slide}\n")
    
    try:
        from dataset import STDataset
        
        # æµ‹è¯•åªéªŒè¯æ¨¡å¼çš„åˆå§‹åŒ–ï¼ˆä¸é¢„åŠ è½½è®­ç»ƒæ•°æ®ï¼‰
        dataset = STDataset(
            mode='val',  # ä½¿ç”¨éªŒè¯æ¨¡å¼ï¼Œä¸ä¼šé¢„åŠ è½½æ•°æ®
            data_path=test_data_path,
            expr_name='PRAD',
            slide_val='SPA154,SPA153',
            slide_test='SPA152,SPA151',
            encoder_name='uni',
            use_augmented=False
        )
        
        print("âœ… STDatasetåˆå§‹åŒ–æˆåŠŸ")
        print(f"  - åŸºå› æ•°é‡: {len(dataset.genes)}")
        print(f"  - è®­ç»ƒé›†slides: {dataset.slide_splits['train']}")
        print(f"  - éªŒè¯é›†slides: {dataset.slide_splits['val']}")
        print(f"  - æµ‹è¯•é›†slides: {dataset.slide_splits['test']}")
        print(f"  - å½“å‰æ¨¡å¼æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # æµ‹è¯•å‚æ•°éªŒè¯
        print("  - æµ‹è¯•å‚æ•°éªŒè¯...")
        assert dataset.mode == 'val'
        assert dataset.encoder_name == 'uni'
        assert not dataset.use_augmented
        assert len(dataset.genes) == 200
        
        return True
        
    except Exception as e:
        print(f"âŒ STDatasetåˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_mfbp_model():
    """æµ‹è¯•MFBPæ¨¡å‹"""
    print("\nğŸ” æµ‹è¯•MFBPæ¨¡å‹...")
    
    try:
        from model.MFBP.MFBP import MFBP
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = MFBP(num_genes=200, feature_dim=1024)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        # è®­ç»ƒæ¨¡å¼ï¼šå•ä¸ªspot
        train_input = torch.randn(32, 1024)  # [batch_size, feature_dim]
        train_output = model(train_input)
        
        print("âœ… MFBPæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"  - è®­ç»ƒæ¨¡å¼è¾“å…¥å½¢çŠ¶: {train_input.shape}")
        print(f"  - è®­ç»ƒæ¨¡å¼è¾“å‡ºå½¢çŠ¶: {train_output['logits'].shape}")
        
        # éªŒè¯æ¨¡å¼ï¼šå¤šä¸ªspots
        val_input = torch.randn(1, 100, 1024)  # [1, num_spots, feature_dim]
        val_output = model(val_input)
        
        print(f"  - éªŒè¯æ¨¡å¼è¾“å…¥å½¢çŠ¶: {val_input.shape}")
        print(f"  - éªŒè¯æ¨¡å¼è¾“å‡ºå½¢çŠ¶: {val_output['logits'].shape}")
        
        # æ£€æŸ¥è¾“å‡ºæ ¼å¼
        assert 'logits' in train_output, "è¾“å‡ºåº”åŒ…å«'logits'é”®"
        assert train_output['logits'].shape == (32, 1, 200), f"è®­ç»ƒè¾“å‡ºå½¢çŠ¶é”™è¯¯: {train_output['logits'].shape}"
        assert val_output['logits'].shape == (1, 100, 200), f"éªŒè¯è¾“å‡ºå½¢çŠ¶é”™è¯¯: {val_output['logits'].shape}"
        
        return True
        
    except Exception as e:
        print(f"âŒ MFBPæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_config_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("\nğŸ” æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½...")
    
    try:
        from utils import load_config
        
        config_path = "config/hest/base_config.yaml"
        if not os.path.exists(config_path):
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
        
        config = load_config(config_path)
        
        # æ£€æŸ¥å…³é”®é…ç½®é¡¹
        assert hasattr(config, 'MODEL'), "é…ç½®åº”åŒ…å«MODELéƒ¨åˆ†"
        assert hasattr(config, 'DATA'), "é…ç½®åº”åŒ…å«DATAéƒ¨åˆ†"
        assert hasattr(config, 'TRAINING'), "é…ç½®åº”åŒ…å«TRAININGéƒ¨åˆ†"
        
        print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"  - æ¨¡å‹åç§°: {config.MODEL.model_name}")
        print(f"  - åŸºå› æ•°é‡: {config.MODEL.num_genes}")
        print(f"  - ç‰¹å¾ç»´åº¦: {config.MODEL.feature_dim}")
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_command_line_args():
    """æµ‹è¯•æ–°çš„å‘½ä»¤è¡Œå‚æ•°æ ¼å¼"""
    print("\nğŸ” æµ‹è¯•å‘½ä»¤è¡Œå‚æ•°è§£æ...")
    
    try:
        sys.path.append('src')
        from main import get_parse, validate_args
        
        parser = get_parse()
        
        # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
        test_args = [
            '--config', 'config/hest/base_config.yaml',
            '--expr_name', 'PRAD',
            '--data_path', '/tmp/test_data/',
            '--slide_val', 'SPA154,SPA153',
            '--slide_test', 'SPA152',
            '--encoder_name', 'uni',
            '--use_augmented',
            '--mode', 'train'
        ]
        
        # åˆ›å»ºæµ‹è¯•ç›®å½•
        os.makedirs('/tmp/test_data/st', exist_ok=True)
        os.makedirs('/tmp/test_data/processed_data', exist_ok=True)
        
        args = parser.parse_args(test_args)
        args = validate_args(args)
        
        print("âœ… å‘½ä»¤è¡Œå‚æ•°è§£ææˆåŠŸ")
        print(f"  - è¡¨è¾¾è°±åç§°: {args.expr_name}")
        print(f"  - æ•°æ®è·¯å¾„: {args.data_path}")
        print(f"  - éªŒè¯é›†slides: {args.slide_val}")
        print(f"  - æµ‹è¯•é›†slides: {args.slide_test}")
        print(f"  - ç¼–ç å™¨: {args.encoder_name}")
        print(f"  - ä½¿ç”¨å¢å¼º: {args.use_augmented}")
        return True
        
    except Exception as e:
        print(f"âŒ å‘½ä»¤è¡Œå‚æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_filename_construction():
    """æµ‹è¯•æ–‡ä»¶åæ„å»ºé€»è¾‘"""
    print("\nğŸ” æµ‹è¯•æ–‡ä»¶åæ„å»ºé€»è¾‘...")
    
    try:
        from dataset import STDataset
        
        # æµ‹è¯•æ ‡å‡†åµŒå…¥æ–‡ä»¶å
        test_data_path = "/tmp/test_hest1k_datasets/PRAD/"
        test_processed_dir = f"{test_data_path}processed_data"
        
        # åˆ›å»ºæµ‹è¯•ç›®å½•å’Œå¿…è¦æ–‡ä»¶
        os.makedirs(test_processed_dir, exist_ok=True)
        os.makedirs(f"{test_data_path}st", exist_ok=True)
        
        # åˆ›å»ºåŸºå› åˆ—è¡¨æ–‡ä»¶
        with open(f"{test_processed_dir}/selected_gene_list.txt", 'w') as f:
            for i in range(10):
                f.write(f"GENE_{i:03d}\n")
        
        # åˆ›å»ºslideåˆ—è¡¨æ–‡ä»¶
        with open(f"{test_processed_dir}/all_slide_lst.txt", 'w') as f:
            f.write("TEST001\n")
        
        # æµ‹è¯•æ ‡å‡†åµŒå…¥ï¼ˆuniï¼‰
        dataset_standard = STDataset(
            mode='val',
            data_path=test_data_path,
            expr_name='PRAD',
            slide_val='TEST001',
            slide_test='',
            encoder_name='uni',
            use_augmented=False
        )
        
        # æµ‹è¯•å¢å¼ºåµŒå…¥ï¼ˆuni_augï¼‰
        dataset_augmented = STDataset(
            mode='val',
            data_path=test_data_path,
            expr_name='PRAD',
            slide_val='TEST001',
            slide_test='',
            encoder_name='uni',
            use_augmented=True
        )
        
        # éªŒè¯ç›®å½•è·¯å¾„
        expected_standard_dir = f"{test_processed_dir}/1spot_uni_ebd"
        expected_augmented_dir = f"{test_processed_dir}/1spot_uni_ebd_aug"
        
        assert dataset_standard.emb_dir == expected_standard_dir, f"æ ‡å‡†åµŒå…¥ç›®å½•é”™è¯¯: {dataset_standard.emb_dir}"
        assert dataset_augmented.emb_dir == expected_augmented_dir, f"å¢å¼ºåµŒå…¥ç›®å½•é”™è¯¯: {dataset_augmented.emb_dir}"
        
        print("âœ… æ–‡ä»¶åæ„å»ºé€»è¾‘æµ‹è¯•é€šè¿‡")
        print(f"  - æ ‡å‡†åµŒå…¥ç›®å½•: {dataset_standard.emb_dir}")
        print(f"  - å¢å¼ºåµŒå…¥ç›®å½•: {dataset_augmented.emb_dir}")
        print(f"  - æ ‡å‡†æ–‡ä»¶åæ ¼å¼: TEST001_uni.pt")
        print(f"  - å¢å¼ºæ–‡ä»¶åæ ¼å¼: TEST001_uni_aug.pt")
        
        # æµ‹è¯•CONCHç¼–ç å™¨
        dataset_conch = STDataset(
            mode='val',
            data_path=test_data_path,
            expr_name='PRAD', 
            slide_val='TEST001',
            slide_test='',
            encoder_name='conch',
            use_augmented=True
        )
        
        expected_conch_dir = f"{test_processed_dir}/1spot_conch_ebd_aug"
        assert dataset_conch.emb_dir == expected_conch_dir, f"CONCHå¢å¼ºåµŒå…¥ç›®å½•é”™è¯¯: {dataset_conch.emb_dir}"
        print(f"  - CONCHå¢å¼ºç›®å½•: {dataset_conch.emb_dir}")
        print(f"  - CONCHå¢å¼ºæ–‡ä»¶å: TEST001_conch_aug.pt")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ–‡ä»¶åæ„å»ºé€»è¾‘æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹MFBPé¡¹ç›®æ•°æ®ç»“æ„è¿ç§»æµ‹è¯•\n")
    
    test_results = []
    
    # è¿è¡Œå„ä¸ªæµ‹è¯•
    test_results.append(("æ¨¡å—å¯¼å…¥", test_imports()))
    test_results.append(("STDatasetåˆå§‹åŒ–", test_stdataset_init()))
    test_results.append(("MFBPæ¨¡å‹", test_mfbp_model()))
    test_results.append(("é…ç½®æ–‡ä»¶åŠ è½½", test_config_loading()))
    test_results.append(("å‘½ä»¤è¡Œå‚æ•°", test_command_line_args()))
    test_results.append(("æ–‡ä»¶åæ„å»ºé€»è¾‘", test_filename_construction()))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("="*50)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:20s}: {status}")
        if result:
            passed += 1
    
    print("="*50)
    print(f"æ€»ä½“ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®ç»“æ„è¿ç§»æˆåŠŸï¼")
        print("\nğŸ“‹ æ–°å‘½ä»¤è¡Œæ ¼å¼ç¤ºä¾‹:")
        print("python src/main.py \\")
        print("    --config config/hest/base_config.yaml \\")
        print("    --expr_name PRAD \\")
        print("    --data_path /data/ouyangjiarui/stem/hest1k_datasets/PRAD/ \\")
        print("    --slide_val \"SPA154,SPA153\" \\")
        print("    --slide_test \"SPA152,SPA151\" \\")
        print("    --encoder_name uni \\")
        print("    --use_augmented \\")
        print("    --mode train")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
        return False

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1) 