#!/usr/bin/env python3
"""
VAR-ST æ•´slideæµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„VAR-STæ¨¡å‹
2. å¯¹æµ‹è¯•é›†ä¸­çš„æ¯ä¸ªslideè¿›è¡Œå®Œæ•´æµ‹è¯•
3. é€spoté¢„æµ‹ï¼Œæœ€åæ•´åˆæˆå®Œæ•´çš„slideç»“æœ
4. è®¡ç®—è¯¦ç»†çš„è¯„ä»·æŒ‡æ ‡å’Œå¯è§†åŒ–

ä½¿ç”¨æ–¹æ³•ï¼š
    python test_var_st_full_slide.py --checkpoint_path path/to/checkpoint.ckpt --dataset HEST --model VAR_ST
"""

import os
import sys
import torch
import argparse
import pytorch_lightning as pl
from pathlib import Path
from addict import Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "src"))

from src.main import DEFAULT_CONFIG, DATASETS, MODELS, ENCODER_FEATURE_DIMS
from src.dataset.data_interface import DataInterface
from src.model.model_interface import ModelInterface

def create_test_config(dataset_name='PRAD', model_name='VAR_ST', encoder_name='uni'):
    """
    åˆ›å»ºæµ‹è¯•é…ç½®
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        model_name: æ¨¡å‹åç§°
        encoder_name: ç¼–ç å™¨åç§°
    
    Returns:
        é…ç½®å¯¹è±¡
    """
    config = Dict(DEFAULT_CONFIG.copy())
    
    if dataset_name not in DATASETS:
        raise ValueError(f"æ•°æ®é›† {dataset_name} æœªæ‰¾åˆ°ï¼Œæ”¯æŒçš„æ•°æ®é›†: {list(DATASETS.keys())}")
    
    if model_name not in MODELS:
        raise ValueError(f"æ¨¡å‹ {model_name} æœªæ‰¾åˆ°ï¼Œæ”¯æŒçš„æ¨¡å‹: {list(MODELS.keys())}")
    
    if encoder_name not in ENCODER_FEATURE_DIMS:
        raise ValueError(f"ç¼–ç å™¨ {encoder_name} æœªæ‰¾åˆ°ï¼Œæ”¯æŒçš„ç¼–ç å™¨: {list(ENCODER_FEATURE_DIMS.keys())}")
    
    dataset_info = DATASETS[dataset_name]
    model_info = MODELS[model_name]
    
    # æ›´æ–°é…ç½®
    config.MODEL = Dict(model_info)
    config.MODEL.feature_dim = ENCODER_FEATURE_DIMS[encoder_name]
    
    # è®¾ç½®æ•°æ®é›†å‚æ•°
    config.mode = 'test'
    config.expr_name = dataset_name
    config.data_path = dataset_info['path']
    config.slide_val = dataset_info['val_slides']
    config.slide_test = dataset_info['test_slides']
    config.encoder_name = encoder_name
    config.use_augmented = False  # æµ‹è¯•æ—¶ä¸ç”¨å¢å¼º
    config.expand_augmented = False
    
    # æ·»åŠ é…ç½®è·¯å¾„æ ‡è®°
    config.config = 'built-in-test'
    
    return config

def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    parser = argparse.ArgumentParser(description="VAR-STæ•´slideæµ‹è¯•")
    parser.add_argument('--checkpoint_path', type=str, required=True,
                       help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--dataset', type=str, default='HEST',
                       choices=list(DATASETS.keys()),
                       help='æ•°æ®é›†åç§°')
    parser.add_argument('--model', type=str, default='VAR_ST',
                       choices=list(MODELS.keys()),
                       help='æ¨¡å‹åç§°')
    parser.add_argument('--encoder', type=str, default='uni',
                       choices=list(ENCODER_FEATURE_DIMS.keys()),
                       help='ç¼–ç å™¨åç§°')
    parser.add_argument('--gpu', type=int, default=0,
                       help='ä½¿ç”¨çš„GPU ID')
    parser.add_argument('--output_dir', type=str, default='./test_results',
                       help='ç»“æœè¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not os.path.exists(args.checkpoint_path):
        print(f"âŒ Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {args.checkpoint_path}")
        return
    
    print("ğŸš€ VAR-ST æ•´slideæµ‹è¯•å¯åŠ¨")
    print(f"ğŸ”§ Checkpoint: {args.checkpoint_path}")
    print(f"ğŸ“Š æ•°æ®é›†: {args.dataset}")
    print(f"ğŸ¤– æ¨¡å‹: {args.model}")
    print(f"ğŸ” ç¼–ç å™¨: {args.encoder}")
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ–¥ï¸  GPU: {args.gpu}")
    print("="*60)
    
    # åˆ›å»ºé…ç½®
    try:
        config = create_test_config(args.dataset, args.model, args.encoder)
        print("âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ é…ç½®åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    config.GENERAL.log_path = args.output_dir
    os.makedirs(args.output_dir, exist_ok=True)
    
    # è®¾ç½®è®¾å¤‡
    if torch.cuda.is_available() and args.gpu >= 0:
        device = f"cuda:{args.gpu}"
        print(f"âœ… ä½¿ç”¨GPU: {device}")
    else:
        device = "cpu"
        print("âš ï¸ ä½¿ç”¨CPUè¿è¡Œ")
    
    # åˆå§‹åŒ–æ•°æ®æ¨¡å—
    try:
        print("ğŸ“Š åˆå§‹åŒ–æ•°æ®æ¨¡å—...")
        datamodule = DataInterface(config)
        datamodule.setup('test')
        print("âœ… æ•°æ®æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        
        # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
        test_dataset = datamodule.test_dataloader().dataset
        original_dataset = test_dataset
        while hasattr(original_dataset, 'dataset'):
            original_dataset = original_dataset.dataset
        
        test_slide_ids = original_dataset.get_test_slide_ids()
        print(f"ğŸ“‹ æµ‹è¯•slides: {test_slide_ids}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # åŠ è½½æ¨¡å‹
    try:
        print("ğŸ”§ åŠ è½½æ¨¡å‹...")
        model = ModelInterface.load_from_checkpoint(
            args.checkpoint_path,
            config=config,
            map_location=device
        )
        model = model.to(device)
        model.eval()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # éªŒè¯æ¨¡å‹ç±»å‹
        if not (hasattr(model, 'model_name') and model.model_name == args.model):
            print(f"âš ï¸ è­¦å‘Š: checkpointä¸­çš„æ¨¡å‹å¯èƒ½ä¸æ˜¯{args.model}ç±»å‹")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # è®¾ç½®trainerï¼ˆç”¨äºè®¿é—®datamoduleï¼‰
    trainer = pl.Trainer(
        devices=[args.gpu] if torch.cuda.is_available() and args.gpu >= 0 else 'auto',
        accelerator='gpu' if torch.cuda.is_available() and args.gpu >= 0 else 'cpu',
        logger=False,  # ç¦ç”¨æ—¥å¿—
        enable_checkpointing=False,  # ç¦ç”¨checkpoint
        enable_progress_bar=False  # ç¦ç”¨è¿›åº¦æ¡
    )
    
    # å°†datamoduleç»‘å®šåˆ°trainer
    trainer.datamodule = datamodule
    model.trainer = trainer
    
    # è¿è¡Œæ•´slideæµ‹è¯•
    try:
        print("\nğŸ¯ å¼€å§‹æ•´slideæµ‹è¯•...")
        results = model.run_full_slide_testing()
        
        # è¾“å‡ºæ€»ç»“
        print("\n" + "="*60)
        print("ğŸ‰ æµ‹è¯•å®Œæˆæ€»ç»“")
        print("="*60)
        print(f"âœ… æˆåŠŸæµ‹è¯• {len(results['test_slide_ids'])} ä¸ªslides")
        print(f"ğŸ“Š æ€»spotsæ•°é‡: {results['overall_predictions'].shape[0]}")
        print(f"ğŸ§¬ åŸºå› æ•°é‡: {results['overall_predictions'].shape[1]}")
        print(f"ğŸ¯ æ•´ä½“æ€§èƒ½:")
        
        overall_metrics = results['overall_metrics']
        print(f"   - PCC-10:  {overall_metrics['PCC-10']:.4f}")
        print(f"   - PCC-50:  {overall_metrics['PCC-50']:.4f}")
        print(f"   - PCC-200: {overall_metrics['PCC-200']:.4f}")
        print(f"   - MSE:     {overall_metrics['MSE']:.4f}")
        print(f"   - MAE:     {overall_metrics['MAE']:.4f}")
        print(f"   - RVD:     {overall_metrics['RVD']:.4f}")
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")
        print("ğŸ“ æ–‡ä»¶ç»“æ„:")
        print(f"   - test_results/: å„slideè¯¦ç»†ç»“æœ")
        print(f"   - vis/: å¯è§†åŒ–å›¾è¡¨")
        print(f"   - overall_results.txt: æ•´ä½“è¯„ä¼°æŠ¥å‘Š")
        
        # æ˜¾ç¤ºå„slideç»“æœæ‘˜è¦
        print(f"\nğŸ“‹ å„Slideç»“æœæ‘˜è¦:")
        for slide_id, slide_result in results['slide_results'].items():
            metrics = slide_result['metrics']
            num_spots = slide_result['num_spots']
            print(f"   {slide_id}: {num_spots} spots, PCC-10={metrics['PCC-10']:.4f}, MSE={metrics['MSE']:.4f}")
        
    except Exception as e:
        print(f"âŒ æ•´slideæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\nğŸŠ VAR-STæ•´slideæµ‹è¯•æˆåŠŸå®Œæˆ!")

if __name__ == "__main__":
    main() 