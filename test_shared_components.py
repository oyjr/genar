"""
å…±äº«ç»„ä»¶æµ‹è¯•è„šæœ¬

æµ‹è¯•ä»¥ä¸‹ç»„ä»¶ï¼š
1. SharedVectorQuantizer: å…±äº«é‡åŒ–å™¨
2. MultiScaleEncoder: å¤šå°ºåº¦ç¼–ç å™¨
3. MultiScaleDecoder: å¤šå°ºåº¦è§£ç å™¨
4. ResidualReconstructor: æ®‹å·®é‡å»ºå™¨
5. MultiScaleDecomposer: å¤šå°ºåº¦åˆ†è§£å™¨

éªŒè¯æ•°æ®æµå’Œå½¢çŠ¶å˜åŒ–çš„æ­£ç¡®æ€§
"""

import sys
import os
sys.path.append('src')

import torch
import torch.nn.functional as F
import numpy as np
from model.VAR.shared_components import (
    SharedVectorQuantizer,
    GlobalEncoder, PathwayEncoder, ModuleEncoder, IndividualEncoder,
    GlobalDecoder, PathwayDecoder, ModuleDecoder, IndividualDecoder,
    ResidualReconstructor,
    MultiScaleDecomposer
)


def test_shared_vector_quantizer():
    """æµ‹è¯•å…±äº«å‘é‡é‡åŒ–å™¨"""
    print("ğŸ”§ æµ‹è¯• SharedVectorQuantizer...")
    
    vq = SharedVectorQuantizer(vocab_size=4096, embed_dim=128, beta=0.25)
    
    # æµ‹è¯•ä¸åŒè¾“å…¥å½¢çŠ¶
    test_cases = [
        torch.randn(4, 128),          # [B, embed_dim]
        torch.randn(4, 1, 128),       # [B, 1, embed_dim] 
        torch.randn(4, 8, 128),       # [B, 8, embed_dim]
        torch.randn(4, 32, 128),      # [B, 32, embed_dim]
        torch.randn(4, 200, 128),     # [B, 200, embed_dim]
    ]
    
    expected_token_shapes = [
        (4,),           # [B]
        (4, 1),         # [B, 1]
        (4, 8),         # [B, 8]
        (4, 32),        # [B, 32]
        (4, 200),       # [B, 200]
    ]
    
    for i, (x, expected_shape) in enumerate(zip(test_cases, expected_token_shapes)):
        tokens, quantized, vq_loss = vq(x)
        
        # éªŒè¯å½¢çŠ¶
        assert tokens.shape == expected_shape, f"æ¡ˆä¾‹{i+1}: tokenså½¢çŠ¶é”™è¯¯ {tokens.shape} != {expected_shape}"
        assert quantized.shape == x.shape, f"æ¡ˆä¾‹{i+1}: quantizedå½¢çŠ¶é”™è¯¯ {quantized.shape} != {x.shape}"
        assert isinstance(vq_loss, torch.Tensor) and vq_loss.dim() == 0, f"æ¡ˆä¾‹{i+1}: vq_lossåº”è¯¥æ˜¯æ ‡é‡"
        
        # éªŒè¯tokenèŒƒå›´
        assert tokens.min() >= 0, f"æ¡ˆä¾‹{i+1}: tokensæœ€å°å€¼åº”è¯¥>=0"
        assert tokens.max() < 4096, f"æ¡ˆä¾‹{i+1}: tokensæœ€å¤§å€¼åº”è¯¥<4096"
        
        # æµ‹è¯•è§£ç 
        decoded = vq.decode(tokens)
        assert decoded.shape == quantized.shape, f"æ¡ˆä¾‹{i+1}: è§£ç å½¢çŠ¶é”™è¯¯"
        
        print(f"   âœ… æ¡ˆä¾‹{i+1}: {x.shape} â†’ tokens{tokens.shape}, quantized{quantized.shape}, loss={vq_loss.item():.4f}")
    
    print("   âœ… SharedVectorQuantizeræµ‹è¯•é€šè¿‡ï¼")


def test_multi_scale_decomposer():
    """æµ‹è¯•å¤šå°ºåº¦åˆ†è§£å™¨"""
    print("\nğŸ”§ æµ‹è¯• MultiScaleDecomposer...")
    
    decomposer = MultiScaleDecomposer()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    B = 4
    gene_expression = torch.randn(B, 200)
    
    # å¤šå°ºåº¦åˆ†è§£
    decomposed = decomposer(gene_expression)
    
    # éªŒè¯è¾“å‡º
    expected_shapes = {
        'global': (B, 1),
        'pathway': (B, 8),
        'module': (B, 32),
        'individual': (B, 200)
    }
    
    for key, expected_shape in expected_shapes.items():
        assert key in decomposed, f"ç¼ºå°‘{key}åˆ†è§£ç»“æœ"
        actual_shape = decomposed[key].shape
        assert actual_shape == expected_shape, f"{key}å½¢çŠ¶é”™è¯¯: {actual_shape} != {expected_shape}"
        print(f"   âœ… {key}: {actual_shape}")
    
    # éªŒè¯globalå±‚æ˜¯æ•´ä½“å¹³å‡
    expected_global = gene_expression.mean(dim=1, keepdim=True)
    torch.testing.assert_close(decomposed['global'], expected_global, rtol=1e-5, atol=1e-6)
    
    print("   âœ… MultiScaleDecomposeræµ‹è¯•é€šè¿‡ï¼")


def test_multi_scale_encoders():
    """æµ‹è¯•å¤šå°ºåº¦ç¼–ç å™¨"""
    print("\nğŸ”§ æµ‹è¯• MultiScale Encoders...")
    
    encoders = {
        'global': GlobalEncoder(embed_dim=128),
        'pathway': PathwayEncoder(embed_dim=128),
        'module': ModuleEncoder(embed_dim=128),
        'individual': IndividualEncoder(embed_dim=128)
    }
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    B = 4
    inputs = {
        'global': torch.randn(B, 1),
        'pathway': torch.randn(B, 8), 
        'module': torch.randn(B, 32),
        'individual': torch.randn(B, 200)
    }
    
    expected_output_shapes = {
        'global': (B, 1, 128),
        'pathway': (B, 8, 128),
        'module': (B, 32, 128),
        'individual': (B, 200, 128)
    }
    
    for name, encoder in encoders.items():
        input_tensor = inputs[name]
        encoded = encoder(input_tensor)
        expected_shape = expected_output_shapes[name]
        
        assert encoded.shape == expected_shape, f"{name}ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶é”™è¯¯: {encoded.shape} != {expected_shape}"
        print(f"   âœ… {name}ç¼–ç å™¨: {input_tensor.shape} â†’ {encoded.shape}")
    
    print("   âœ… MultiScale Encodersæµ‹è¯•é€šè¿‡ï¼")


def test_multi_scale_decoders():
    """æµ‹è¯•å¤šå°ºåº¦è§£ç å™¨"""
    print("\nğŸ”§ æµ‹è¯• MultiScale Decoders...")
    
    decoders = {
        'global': GlobalDecoder(embed_dim=128),
        'pathway': PathwayDecoder(embed_dim=128),
        'module': ModuleDecoder(embed_dim=128),
        'individual': IndividualDecoder(embed_dim=128)
    }
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥ (é‡åŒ–åçš„ç‰¹å¾)
    B = 4
    inputs = {
        'global': torch.randn(B, 1, 128),
        'pathway': torch.randn(B, 8, 128),
        'module': torch.randn(B, 32, 128),
        'individual': torch.randn(B, 200, 128)
    }
    
    expected_output_shapes = {
        'global': (B, 1),
        'pathway': (B, 8),
        'module': (B, 32),
        'individual': (B, 200)
    }
    
    for name, decoder in decoders.items():
        input_tensor = inputs[name]
        decoded = decoder(input_tensor)
        expected_shape = expected_output_shapes[name]
        
        assert decoded.shape == expected_shape, f"{name}è§£ç å™¨è¾“å‡ºå½¢çŠ¶é”™è¯¯: {decoded.shape} != {expected_shape}"
        print(f"   âœ… {name}è§£ç å™¨: {input_tensor.shape} â†’ {decoded.shape}")
    
    print("   âœ… MultiScale Decodersæµ‹è¯•é€šè¿‡ï¼")


def test_residual_reconstructor():
    """æµ‹è¯•æ®‹å·®é‡å»ºå™¨"""
    print("\nğŸ”§ æµ‹è¯• ResidualReconstructor...")
    
    reconstructor = ResidualReconstructor()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    B = 4
    global_recon = torch.randn(B, 1)
    pathway_recon = torch.randn(B, 8)
    module_recon = torch.randn(B, 32)
    individual_recon = torch.randn(B, 200)
    
    # æ®‹å·®é‡å»º
    result = reconstructor(global_recon, pathway_recon, module_recon, individual_recon)
    
    # éªŒè¯è¾“å‡º
    expected_keys = [
        'global_broadcast', 'pathway_broadcast', 'module_broadcast',
        'individual_contribution', 'cumulative_without_individual', 'final_reconstruction'
    ]
    
    for key in expected_keys:
        assert key in result, f"ç¼ºå°‘è¾“å‡ºé”®: {key}"
        assert result[key].shape == (B, 200), f"{key}å½¢çŠ¶é”™è¯¯: {result[key].shape} != {(B, 200)}"
    
    # éªŒè¯é‡å»ºé€»è¾‘
    expected_final = (result['global_broadcast'] + 
                     result['pathway_broadcast'] + 
                     result['module_broadcast'] + 
                     result['individual_contribution'])
    
    torch.testing.assert_close(result['final_reconstruction'], expected_final, rtol=1e-5, atol=1e-6)
    
    # éªŒè¯å¹¿æ’­é€»è¾‘
    expected_global_broadcast = global_recon.expand(B, 200)
    torch.testing.assert_close(result['global_broadcast'], expected_global_broadcast, rtol=1e-5, atol=1e-6)
    
    expected_pathway_broadcast = pathway_recon.repeat_interleave(25, dim=1)
    torch.testing.assert_close(result['pathway_broadcast'], expected_pathway_broadcast, rtol=1e-5, atol=1e-6)
    
    print(f"   âœ… æ®‹å·®é‡å»º: å„å±‚å½¢çŠ¶ {[v.shape for v in result.values()]}")
    print("   âœ… ResidualReconstructoræµ‹è¯•é€šè¿‡ï¼")


def test_complete_pipeline():
    """æµ‹è¯•å®Œæ•´çš„æ•°æ®æµpipeline"""
    print("\nğŸ”§ æµ‹è¯•å®Œæ•´æ•°æ®æµPipeline...")
    
    # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
    decomposer = MultiScaleDecomposer()
    vq = SharedVectorQuantizer(vocab_size=4096, embed_dim=128, beta=0.25)
    
    encoders = {
        'global': GlobalEncoder(embed_dim=128),
        'pathway': PathwayEncoder(embed_dim=128),
        'module': ModuleEncoder(embed_dim=128),
        'individual': IndividualEncoder(embed_dim=128)
    }
    
    decoders = {
        'global': GlobalDecoder(embed_dim=128),
        'pathway': PathwayDecoder(embed_dim=128),
        'module': ModuleDecoder(embed_dim=128),
        'individual': IndividualDecoder(embed_dim=128)
    }
    
    reconstructor = ResidualReconstructor()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    B = 4
    gene_expression = torch.randn(B, 200)
    
    print(f"   è¾“å…¥åŸºå› è¡¨è¾¾: {gene_expression.shape}")
    
    # Step 1: å¤šå°ºåº¦åˆ†è§£
    decomposed = decomposer(gene_expression)
    print(f"   å¤šå°ºåº¦åˆ†è§£: {[f'{k}:{v.shape}' for k, v in decomposed.items()]}")
    
    # Step 2: å¤šå°ºåº¦ç¼–ç 
    encoded = {}
    for scale in ['global', 'pathway', 'module', 'individual']:
        encoded[scale] = encoders[scale](decomposed[scale])
    print(f"   å¤šå°ºåº¦ç¼–ç : {[f'{k}:{v.shape}' for k, v in encoded.items()]}")
    
    # Step 3: å…±äº«é‡åŒ–
    quantized = {}
    tokens = {}
    vq_losses = []
    
    for scale in ['global', 'pathway', 'module', 'individual']:
        scale_tokens, scale_quantized, scale_vq_loss = vq(encoded[scale])
        tokens[scale] = scale_tokens
        quantized[scale] = scale_quantized
        vq_losses.append(scale_vq_loss)
    
    total_vq_loss = sum(vq_losses)
    print(f"   å…±äº«é‡åŒ–: tokens{[f'{k}:{v.shape}' for k, v in tokens.items()]}")
    print(f"   VQæŸå¤±: {[f'{loss.item():.4f}' for loss in vq_losses]}, æ€»è®¡: {total_vq_loss.item():.4f}")
    
    # Step 4: å¤šå°ºåº¦è§£ç 
    decoded = {}
    for scale in ['global', 'pathway', 'module', 'individual']:
        decoded[scale] = decoders[scale](quantized[scale])
    print(f"   å¤šå°ºåº¦è§£ç : {[f'{k}:{v.shape}' for k, v in decoded.items()]}")
    
    # Step 5: æ®‹å·®é‡å»º
    reconstruction_result = reconstructor(
        decoded['global'], decoded['pathway'], 
        decoded['module'], decoded['individual']
    )
    
    final_reconstruction = reconstruction_result['final_reconstruction']
    print(f"   æœ€ç»ˆé‡å»º: {final_reconstruction.shape}")
    
    # è®¡ç®—é‡å»ºè¯¯å·®
    reconstruction_loss = F.mse_loss(final_reconstruction, gene_expression)
    print(f"   é‡å»ºMSEæŸå¤±: {reconstruction_loss.item():.4f}")
    
    # éªŒè¯æ‰€æœ‰tokenéƒ½åœ¨æ­£ç¡®èŒƒå›´å†…
    all_tokens = torch.cat([tokens[scale].flatten() for scale in tokens.keys()])
    assert all_tokens.min() >= 0, f"Tokenæœ€å°å€¼ {all_tokens.min()} < 0"
    assert all_tokens.max() < 4096, f"Tokenæœ€å¤§å€¼ {all_tokens.max()} >= 4096"
    
    print(f"   æ‰€æœ‰tokensèŒƒå›´: [{all_tokens.min()}, {all_tokens.max()}]")
    print("   âœ… å®Œæ•´Pipelineæµ‹è¯•é€šè¿‡ï¼")
    
    return {
        'input': gene_expression,
        'decomposed': decomposed,
        'encoded': encoded,
        'tokens': tokens,
        'quantized': quantized,
        'decoded': decoded,
        'reconstructed': final_reconstruction,
        'reconstruction_loss': reconstruction_loss,
        'vq_loss': total_vq_loss
    }


def test_var_compatibility():
    """æµ‹è¯•ä¸VARåŸå§‹è®¾è®¡çš„å…¼å®¹æ€§"""
    print("\nğŸ”§ æµ‹è¯•VARå…¼å®¹æ€§...")
    
    # éªŒè¯å…³é”®å‚æ•°ä¸VARä¸€è‡´
    vq = SharedVectorQuantizer(vocab_size=4096, embed_dim=128)
    
    # æµ‹è¯•ä¸åŒbatch size
    for batch_size in [1, 4, 16, 32]:
        # æµ‹è¯•æ‰€æœ‰å¯èƒ½çš„sequenceé•¿åº¦
        test_sequences = [
            torch.randn(batch_size, 1, 128),    # Global
            torch.randn(batch_size, 8, 128),    # Pathway  
            torch.randn(batch_size, 32, 128),   # Module
            torch.randn(batch_size, 200, 128),  # Individual
            torch.randn(batch_size, 241, 128),  # å®Œæ•´åºåˆ— 1+8+32+200
        ]
        
        for i, seq in enumerate(test_sequences):
            tokens, quantized, vq_loss = vq(seq)
            
            # éªŒè¯tokensèŒƒå›´
            assert tokens.min() >= 0 and tokens.max() < 4096, f"Batch{batch_size}åºåˆ—{i}: tokensèŒƒå›´é”™è¯¯"
            
            # éªŒè¯å½¢çŠ¶ä¸€è‡´æ€§
            assert quantized.shape == seq.shape, f"Batch{batch_size}åºåˆ—{i}: é‡åŒ–å½¢çŠ¶ä¸ä¸€è‡´"
            
        print(f"   âœ… Batch size {batch_size}: æ‰€æœ‰åºåˆ—é•¿åº¦æµ‹è¯•é€šè¿‡")
    
    print("   âœ… VARå…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼")


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•å…±äº«ç»„ä»¶...")
    
    try:
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        test_shared_vector_quantizer()
        test_multi_scale_decomposer()
        test_multi_scale_encoders()
        test_multi_scale_decoders()
        test_residual_reconstructor()
        
        # å®Œæ•´æµç¨‹æµ‹è¯•
        pipeline_result = test_complete_pipeline()
        
        # VARå…¼å®¹æ€§æµ‹è¯•
        test_var_compatibility()
        
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print(f"ğŸ“Š Pipelineç»“æœæ‘˜è¦:")
        print(f"   - è¾“å…¥ç»´åº¦: {pipeline_result['input'].shape}")
        print(f"   - é‡å»ºæŸå¤±: {pipeline_result['reconstruction_loss'].item():.4f}")
        print(f"   - VQæŸå¤±: {pipeline_result['vq_loss'].item():.4f}")
        print(f"   - Tokenæ•°é‡: {sum(t.numel() for t in pipeline_result['tokens'].values())}")
        
        print(f"\nâœ… Step 1 å…±äº«ç»„ä»¶æ¨¡å—åˆ›å»ºå®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 